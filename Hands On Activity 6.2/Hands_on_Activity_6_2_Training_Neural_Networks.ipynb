{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Technological Institute of the Philippines | Quezon City - Computer Engineering\n",
        "--- | ---\n",
        "Course Code: | CPE 019\n",
        "Code Title: | Emerging Technologies 2 in CpE\n",
        "2nd Semester | AY 2023-2024\n",
        "<hr> | <hr>\n",
        "<u>**ACTIVITY NO.** | **Hands On Activity 6.2: Training Neural Networks**\n",
        "**Name** | Gamundoy, Jon Aviv Cloydd S.\n",
        "**Section** | CPE32S3\n",
        "**Date Performed**: | 3/28/2024\n",
        "**Date Submitted**: | 4/01/2024\n",
        "**Instructor**: | Engr. Roman M. Richard\n",
        "\n",
        "<hr>"
      ],
      "metadata": {
        "id": "qI5ZA6MjioEg"
      },
      "id": "qI5ZA6MjioEg"
    },
    {
      "cell_type": "markdown",
      "id": "union-alcohol",
      "metadata": {
        "id": "union-alcohol"
      },
      "source": [
        "# Activity 1.2 : Training Neural Networks\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "floppy-teens",
      "metadata": {
        "id": "floppy-teens"
      },
      "source": [
        "#### Objective(s):\n",
        "\n",
        "This activity aims to demonstrate how to train neural networks using keras"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "engaged-modem",
      "metadata": {
        "id": "engaged-modem"
      },
      "source": [
        "#### Intended Learning Outcomes (ILOs):\n",
        "* Demonstrate how to build and train neural networks\n",
        "* Demonstrate how to evaluate and plot the model using training and validation loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "structured-april",
      "metadata": {
        "id": "structured-april"
      },
      "source": [
        "#### Resources:\n",
        "* Jupyter Notebook\n",
        "\n",
        "CI Pima Diabetes Dataset\n",
        "\n",
        "* pima-indians-diabetes.csv\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cutting-fountain",
      "metadata": {
        "id": "cutting-fountain"
      },
      "source": [
        "#### Procedures"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "entertaining-therapist",
      "metadata": {
        "id": "entertaining-therapist"
      },
      "source": [
        "Load the necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "differential-native",
      "metadata": {
        "id": "differential-native"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score, roc_curve, accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "other-married",
      "metadata": {
        "id": "other-married"
      },
      "outputs": [],
      "source": [
        "## Import Keras objects for Deep Learning\n",
        "\n",
        "from keras.models  import Sequential\n",
        "from keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
        "from keras.optimizers import Adam, SGD, RMSprop"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mexican-newsletter",
      "metadata": {
        "id": "mexican-newsletter"
      },
      "source": [
        "Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "studied-twelve",
      "metadata": {
        "id": "studied-twelve"
      },
      "outputs": [],
      "source": [
        "\n",
        "filepath = \"pima-indians-diabetes.csv\"\n",
        "names = [\"times_pregnant\", \"glucose_tolerance_test\", \"blood_pressure\", \"skin_thickness\", \"insulin\",\n",
        "         \"bmi\", \"pedigree_function\", \"age\", \"has_diabetes\"]\n",
        "diabetes_df = pd.read_csv(filepath, names=names)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "photographic-carnival",
      "metadata": {
        "id": "photographic-carnival"
      },
      "source": [
        "Check the top 5 samples of the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "undefined-inventory",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "undefined-inventory",
        "outputId": "2904336b-a2ea-42c3-d35a-137f0b08f312"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(768, 9)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     times_pregnant  glucose_tolerance_test  blood_pressure  skin_thickness  \\\n",
              "24               11                     143              94              33   \n",
              "553               1                      88              62              24   \n",
              "455              14                     175              62              30   \n",
              "607               1                      92              62              25   \n",
              "45                0                     180              66              39   \n",
              "\n",
              "     insulin   bmi  pedigree_function  age  has_diabetes  \n",
              "24       146  36.6              0.254   51             1  \n",
              "553       44  29.9              0.422   23             0  \n",
              "455        0  33.6              0.212   38             1  \n",
              "607       41  19.5              0.482   25             0  \n",
              "45         0  42.0              1.893   25             1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e66fd5d1-f19b-4391-94b8-582b09b1a4ee\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>times_pregnant</th>\n",
              "      <th>glucose_tolerance_test</th>\n",
              "      <th>blood_pressure</th>\n",
              "      <th>skin_thickness</th>\n",
              "      <th>insulin</th>\n",
              "      <th>bmi</th>\n",
              "      <th>pedigree_function</th>\n",
              "      <th>age</th>\n",
              "      <th>has_diabetes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>11</td>\n",
              "      <td>143</td>\n",
              "      <td>94</td>\n",
              "      <td>33</td>\n",
              "      <td>146</td>\n",
              "      <td>36.6</td>\n",
              "      <td>0.254</td>\n",
              "      <td>51</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>553</th>\n",
              "      <td>1</td>\n",
              "      <td>88</td>\n",
              "      <td>62</td>\n",
              "      <td>24</td>\n",
              "      <td>44</td>\n",
              "      <td>29.9</td>\n",
              "      <td>0.422</td>\n",
              "      <td>23</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>455</th>\n",
              "      <td>14</td>\n",
              "      <td>175</td>\n",
              "      <td>62</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.212</td>\n",
              "      <td>38</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>607</th>\n",
              "      <td>1</td>\n",
              "      <td>92</td>\n",
              "      <td>62</td>\n",
              "      <td>25</td>\n",
              "      <td>41</td>\n",
              "      <td>19.5</td>\n",
              "      <td>0.482</td>\n",
              "      <td>25</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>0</td>\n",
              "      <td>180</td>\n",
              "      <td>66</td>\n",
              "      <td>39</td>\n",
              "      <td>0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>1.893</td>\n",
              "      <td>25</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e66fd5d1-f19b-4391-94b8-582b09b1a4ee')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e66fd5d1-f19b-4391-94b8-582b09b1a4ee button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e66fd5d1-f19b-4391-94b8-582b09b1a4ee');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d4f5499c-9820-46b8-8e36-62f5bb7cf649\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d4f5499c-9820-46b8-8e36-62f5bb7cf649')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d4f5499c-9820-46b8-8e36-62f5bb7cf649 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"diabetes_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"times_pregnant\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6,\n        \"min\": 0,\n        \"max\": 14,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          1,\n          0,\n          11\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"glucose_tolerance_test\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 44,\n        \"min\": 88,\n        \"max\": 180,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          88,\n          180,\n          175\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"blood_pressure\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 13,\n        \"min\": 62,\n        \"max\": 94,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          94,\n          62,\n          66\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"skin_thickness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6,\n        \"min\": 24,\n        \"max\": 39,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          24,\n          39,\n          30\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"insulin\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 59,\n        \"min\": 0,\n        \"max\": 146,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          44,\n          41,\n          146\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bmi\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8.424191355851315,\n        \"min\": 19.5,\n        \"max\": 42.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          29.9,\n          42.0,\n          33.6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pedigree_function\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7024747682301479,\n        \"min\": 0.212,\n        \"max\": 1.893,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.422,\n          1.893,\n          0.212\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 11,\n        \"min\": 23,\n        \"max\": 51,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          23,\n          25,\n          51\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"has_diabetes\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "\n",
        "print(diabetes_df.shape)\n",
        "diabetes_df.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "systematic-motorcycle",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "systematic-motorcycle",
        "outputId": "391c29dd-dc58-424d-a63d-3a23ce6d21a9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "times_pregnant              int64\n",
              "glucose_tolerance_test      int64\n",
              "blood_pressure              int64\n",
              "skin_thickness              int64\n",
              "insulin                     int64\n",
              "bmi                       float64\n",
              "pedigree_function         float64\n",
              "age                         int64\n",
              "has_diabetes                int64\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "diabetes_df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "collected-lafayette",
      "metadata": {
        "id": "collected-lafayette"
      },
      "outputs": [],
      "source": [
        "X = diabetes_df.iloc[:, :-1].values\n",
        "y = diabetes_df[\"has_diabetes\"].values"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "acquired-parallel",
      "metadata": {
        "id": "acquired-parallel"
      },
      "source": [
        "Split the data to Train, and Test (75%, 25%)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rational-hollow",
      "metadata": {
        "id": "rational-hollow"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=11111)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "acceptable-equity",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acceptable-equity",
        "outputId": "c7e2be83-cebe-4ab9-8886-481b610daa8f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.3489583333333333, 0.6510416666666666)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "np.mean(y), np.mean(1-y)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "thick-reconstruction",
      "metadata": {
        "id": "thick-reconstruction"
      },
      "source": [
        "Build a single hidden layer neural network using 12 nodes.\n",
        "Use the sequential model with single layer network and input shape to 8.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dramatic-zealand",
      "metadata": {
        "id": "dramatic-zealand"
      },
      "source": [
        "Normalize the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "painted-mathematics",
      "metadata": {
        "id": "painted-mathematics"
      },
      "outputs": [],
      "source": [
        "normalizer = StandardScaler()\n",
        "X_train_norm = normalizer.fit_transform(X_train)\n",
        "X_test_norm = normalizer.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "previous-electricity",
      "metadata": {
        "id": "previous-electricity"
      },
      "source": [
        "Define the model:\n",
        "* Input size is 8-dimensional\n",
        "* 1 hidden layer, 12 hidden nodes, sigmoid activation\n",
        "* Final layer with one node and sigmoid activation (standard for binary classification)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "found-bowling",
      "metadata": {
        "id": "found-bowling"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "model  = Sequential([\n",
        "    Dense(12, input_shape=(8,), activation=\"sigmoid\"),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "level-terminal",
      "metadata": {
        "id": "level-terminal"
      },
      "source": [
        "View the model summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "correct-kingdom",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "correct-kingdom",
        "outputId": "9098bf78-de53-40e6-de43-e79693f48311"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_44 (Dense)            (None, 12)                108       \n",
            "                                                                 \n",
            " dense_45 (Dense)            (None, 1)                 13        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 121 (484.00 Byte)\n",
            "Trainable params: 121 (484.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "herbal-anderson",
      "metadata": {
        "id": "herbal-anderson"
      },
      "source": [
        "Train the model\n",
        "* Compile the model with optimizer, loss function and metrics\n",
        "* Use the fit function to return the run history.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "happy-prompt",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "happy-prompt",
        "outputId": "709b8584-0eb7-4678-f984-5bd2f16566f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "18/18 [==============================] - 1s 13ms/step - loss: 0.8517 - accuracy: 0.3455 - val_loss: 0.8056 - val_accuracy: 0.3594\n",
            "Epoch 2/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.7891 - accuracy: 0.3455 - val_loss: 0.7561 - val_accuracy: 0.3542\n",
            "Epoch 3/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7444 - accuracy: 0.3247 - val_loss: 0.7211 - val_accuracy: 0.3750\n",
            "Epoch 4/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.7128 - accuracy: 0.3594 - val_loss: 0.6968 - val_accuracy: 0.5000\n",
            "Epoch 5/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6903 - accuracy: 0.5729 - val_loss: 0.6795 - val_accuracy: 0.5885\n",
            "Epoch 6/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6742 - accuracy: 0.6493 - val_loss: 0.6671 - val_accuracy: 0.6302\n",
            "Epoch 7/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6622 - accuracy: 0.6510 - val_loss: 0.6579 - val_accuracy: 0.6302\n",
            "Epoch 8/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6534 - accuracy: 0.6545 - val_loss: 0.6511 - val_accuracy: 0.6406\n",
            "Epoch 9/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6465 - accuracy: 0.6562 - val_loss: 0.6458 - val_accuracy: 0.6406\n",
            "Epoch 10/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6412 - accuracy: 0.6562 - val_loss: 0.6417 - val_accuracy: 0.6406\n",
            "Epoch 11/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6368 - accuracy: 0.6562 - val_loss: 0.6382 - val_accuracy: 0.6406\n",
            "Epoch 12/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6332 - accuracy: 0.6545 - val_loss: 0.6352 - val_accuracy: 0.6406\n",
            "Epoch 13/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6300 - accuracy: 0.6545 - val_loss: 0.6326 - val_accuracy: 0.6406\n",
            "Epoch 14/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6273 - accuracy: 0.6545 - val_loss: 0.6303 - val_accuracy: 0.6406\n",
            "Epoch 15/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6247 - accuracy: 0.6545 - val_loss: 0.6281 - val_accuracy: 0.6406\n",
            "Epoch 16/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6224 - accuracy: 0.6545 - val_loss: 0.6260 - val_accuracy: 0.6406\n",
            "Epoch 17/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6202 - accuracy: 0.6545 - val_loss: 0.6240 - val_accuracy: 0.6406\n",
            "Epoch 18/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6181 - accuracy: 0.6545 - val_loss: 0.6222 - val_accuracy: 0.6406\n",
            "Epoch 19/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6161 - accuracy: 0.6545 - val_loss: 0.6203 - val_accuracy: 0.6406\n",
            "Epoch 20/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6141 - accuracy: 0.6545 - val_loss: 0.6185 - val_accuracy: 0.6406\n",
            "Epoch 21/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6123 - accuracy: 0.6545 - val_loss: 0.6167 - val_accuracy: 0.6406\n",
            "Epoch 22/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6104 - accuracy: 0.6545 - val_loss: 0.6150 - val_accuracy: 0.6406\n",
            "Epoch 23/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6086 - accuracy: 0.6545 - val_loss: 0.6133 - val_accuracy: 0.6406\n",
            "Epoch 24/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6070 - accuracy: 0.6562 - val_loss: 0.6116 - val_accuracy: 0.6406\n",
            "Epoch 25/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6052 - accuracy: 0.6562 - val_loss: 0.6099 - val_accuracy: 0.6406\n",
            "Epoch 26/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6035 - accuracy: 0.6562 - val_loss: 0.6082 - val_accuracy: 0.6406\n",
            "Epoch 27/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6018 - accuracy: 0.6562 - val_loss: 0.6066 - val_accuracy: 0.6406\n",
            "Epoch 28/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6001 - accuracy: 0.6545 - val_loss: 0.6050 - val_accuracy: 0.6406\n",
            "Epoch 29/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5985 - accuracy: 0.6545 - val_loss: 0.6034 - val_accuracy: 0.6406\n",
            "Epoch 30/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5969 - accuracy: 0.6580 - val_loss: 0.6018 - val_accuracy: 0.6406\n",
            "Epoch 31/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5954 - accuracy: 0.6597 - val_loss: 0.6003 - val_accuracy: 0.6458\n",
            "Epoch 32/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5938 - accuracy: 0.6597 - val_loss: 0.5987 - val_accuracy: 0.6458\n",
            "Epoch 33/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5923 - accuracy: 0.6597 - val_loss: 0.5972 - val_accuracy: 0.6510\n",
            "Epoch 34/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5906 - accuracy: 0.6580 - val_loss: 0.5957 - val_accuracy: 0.6510\n",
            "Epoch 35/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5892 - accuracy: 0.6597 - val_loss: 0.5942 - val_accuracy: 0.6510\n",
            "Epoch 36/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5876 - accuracy: 0.6580 - val_loss: 0.5928 - val_accuracy: 0.6510\n",
            "Epoch 37/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5862 - accuracy: 0.6597 - val_loss: 0.5913 - val_accuracy: 0.6510\n",
            "Epoch 38/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5847 - accuracy: 0.6597 - val_loss: 0.5899 - val_accuracy: 0.6562\n",
            "Epoch 39/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5834 - accuracy: 0.6597 - val_loss: 0.5885 - val_accuracy: 0.6562\n",
            "Epoch 40/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5820 - accuracy: 0.6597 - val_loss: 0.5871 - val_accuracy: 0.6615\n",
            "Epoch 41/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5805 - accuracy: 0.6632 - val_loss: 0.5857 - val_accuracy: 0.6615\n",
            "Epoch 42/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5790 - accuracy: 0.6632 - val_loss: 0.5843 - val_accuracy: 0.6562\n",
            "Epoch 43/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5777 - accuracy: 0.6684 - val_loss: 0.5830 - val_accuracy: 0.6562\n",
            "Epoch 44/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5763 - accuracy: 0.6667 - val_loss: 0.5816 - val_accuracy: 0.6615\n",
            "Epoch 45/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5749 - accuracy: 0.6667 - val_loss: 0.5803 - val_accuracy: 0.6615\n",
            "Epoch 46/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5736 - accuracy: 0.6684 - val_loss: 0.5790 - val_accuracy: 0.6615\n",
            "Epoch 47/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5723 - accuracy: 0.6719 - val_loss: 0.5777 - val_accuracy: 0.6771\n",
            "Epoch 48/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5710 - accuracy: 0.6719 - val_loss: 0.5765 - val_accuracy: 0.6771\n",
            "Epoch 49/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5697 - accuracy: 0.6719 - val_loss: 0.5752 - val_accuracy: 0.6771\n",
            "Epoch 50/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5684 - accuracy: 0.6719 - val_loss: 0.5740 - val_accuracy: 0.6823\n",
            "Epoch 51/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5671 - accuracy: 0.6753 - val_loss: 0.5728 - val_accuracy: 0.6979\n",
            "Epoch 52/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5659 - accuracy: 0.6736 - val_loss: 0.5716 - val_accuracy: 0.6979\n",
            "Epoch 53/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5646 - accuracy: 0.6736 - val_loss: 0.5704 - val_accuracy: 0.7031\n",
            "Epoch 54/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5634 - accuracy: 0.6719 - val_loss: 0.5692 - val_accuracy: 0.7031\n",
            "Epoch 55/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5622 - accuracy: 0.6719 - val_loss: 0.5680 - val_accuracy: 0.7135\n",
            "Epoch 56/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5611 - accuracy: 0.6753 - val_loss: 0.5669 - val_accuracy: 0.7188\n",
            "Epoch 57/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5598 - accuracy: 0.6736 - val_loss: 0.5657 - val_accuracy: 0.7188\n",
            "Epoch 58/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5586 - accuracy: 0.6840 - val_loss: 0.5646 - val_accuracy: 0.7188\n",
            "Epoch 59/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5575 - accuracy: 0.6892 - val_loss: 0.5635 - val_accuracy: 0.7188\n",
            "Epoch 60/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5564 - accuracy: 0.6927 - val_loss: 0.5624 - val_accuracy: 0.7240\n",
            "Epoch 61/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5553 - accuracy: 0.6962 - val_loss: 0.5613 - val_accuracy: 0.7240\n",
            "Epoch 62/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5541 - accuracy: 0.6997 - val_loss: 0.5603 - val_accuracy: 0.7240\n",
            "Epoch 63/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5530 - accuracy: 0.6997 - val_loss: 0.5592 - val_accuracy: 0.7188\n",
            "Epoch 64/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5519 - accuracy: 0.6997 - val_loss: 0.5582 - val_accuracy: 0.7240\n",
            "Epoch 65/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5508 - accuracy: 0.7014 - val_loss: 0.5572 - val_accuracy: 0.7240\n",
            "Epoch 66/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5498 - accuracy: 0.7031 - val_loss: 0.5561 - val_accuracy: 0.7240\n",
            "Epoch 67/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5487 - accuracy: 0.7083 - val_loss: 0.5552 - val_accuracy: 0.7240\n",
            "Epoch 68/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5476 - accuracy: 0.7083 - val_loss: 0.5542 - val_accuracy: 0.7240\n",
            "Epoch 69/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5466 - accuracy: 0.7135 - val_loss: 0.5532 - val_accuracy: 0.7240\n",
            "Epoch 70/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5456 - accuracy: 0.7188 - val_loss: 0.5522 - val_accuracy: 0.7240\n",
            "Epoch 71/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5446 - accuracy: 0.7188 - val_loss: 0.5513 - val_accuracy: 0.7240\n",
            "Epoch 72/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5436 - accuracy: 0.7188 - val_loss: 0.5504 - val_accuracy: 0.7240\n",
            "Epoch 73/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5426 - accuracy: 0.7205 - val_loss: 0.5494 - val_accuracy: 0.7240\n",
            "Epoch 74/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5416 - accuracy: 0.7188 - val_loss: 0.5485 - val_accuracy: 0.7292\n",
            "Epoch 75/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5406 - accuracy: 0.7205 - val_loss: 0.5476 - val_accuracy: 0.7292\n",
            "Epoch 76/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5397 - accuracy: 0.7240 - val_loss: 0.5467 - val_accuracy: 0.7344\n",
            "Epoch 77/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5387 - accuracy: 0.7240 - val_loss: 0.5459 - val_accuracy: 0.7396\n",
            "Epoch 78/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5378 - accuracy: 0.7257 - val_loss: 0.5450 - val_accuracy: 0.7396\n",
            "Epoch 79/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5369 - accuracy: 0.7240 - val_loss: 0.5441 - val_accuracy: 0.7396\n",
            "Epoch 80/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5360 - accuracy: 0.7222 - val_loss: 0.5433 - val_accuracy: 0.7396\n",
            "Epoch 81/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5351 - accuracy: 0.7222 - val_loss: 0.5425 - val_accuracy: 0.7396\n",
            "Epoch 82/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5342 - accuracy: 0.7205 - val_loss: 0.5417 - val_accuracy: 0.7396\n",
            "Epoch 83/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5333 - accuracy: 0.7205 - val_loss: 0.5409 - val_accuracy: 0.7396\n",
            "Epoch 84/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5325 - accuracy: 0.7240 - val_loss: 0.5401 - val_accuracy: 0.7396\n",
            "Epoch 85/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5316 - accuracy: 0.7205 - val_loss: 0.5393 - val_accuracy: 0.7396\n",
            "Epoch 86/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5307 - accuracy: 0.7222 - val_loss: 0.5385 - val_accuracy: 0.7396\n",
            "Epoch 87/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5299 - accuracy: 0.7222 - val_loss: 0.5378 - val_accuracy: 0.7396\n",
            "Epoch 88/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5290 - accuracy: 0.7222 - val_loss: 0.5370 - val_accuracy: 0.7344\n",
            "Epoch 89/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5282 - accuracy: 0.7240 - val_loss: 0.5363 - val_accuracy: 0.7396\n",
            "Epoch 90/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5275 - accuracy: 0.7240 - val_loss: 0.5356 - val_accuracy: 0.7396\n",
            "Epoch 91/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5266 - accuracy: 0.7257 - val_loss: 0.5348 - val_accuracy: 0.7396\n",
            "Epoch 92/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5259 - accuracy: 0.7274 - val_loss: 0.5341 - val_accuracy: 0.7448\n",
            "Epoch 93/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5250 - accuracy: 0.7274 - val_loss: 0.5334 - val_accuracy: 0.7500\n",
            "Epoch 94/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5242 - accuracy: 0.7292 - val_loss: 0.5327 - val_accuracy: 0.7500\n",
            "Epoch 95/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5236 - accuracy: 0.7274 - val_loss: 0.5321 - val_accuracy: 0.7552\n",
            "Epoch 96/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5228 - accuracy: 0.7326 - val_loss: 0.5314 - val_accuracy: 0.7604\n",
            "Epoch 97/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5220 - accuracy: 0.7326 - val_loss: 0.5308 - val_accuracy: 0.7552\n",
            "Epoch 98/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5214 - accuracy: 0.7309 - val_loss: 0.5301 - val_accuracy: 0.7552\n",
            "Epoch 99/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5205 - accuracy: 0.7309 - val_loss: 0.5295 - val_accuracy: 0.7604\n",
            "Epoch 100/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5199 - accuracy: 0.7309 - val_loss: 0.5288 - val_accuracy: 0.7604\n",
            "Epoch 101/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5191 - accuracy: 0.7292 - val_loss: 0.5282 - val_accuracy: 0.7604\n",
            "Epoch 102/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5184 - accuracy: 0.7292 - val_loss: 0.5276 - val_accuracy: 0.7656\n",
            "Epoch 103/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5177 - accuracy: 0.7309 - val_loss: 0.5270 - val_accuracy: 0.7656\n",
            "Epoch 104/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5171 - accuracy: 0.7344 - val_loss: 0.5264 - val_accuracy: 0.7656\n",
            "Epoch 105/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5164 - accuracy: 0.7361 - val_loss: 0.5258 - val_accuracy: 0.7656\n",
            "Epoch 106/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5157 - accuracy: 0.7309 - val_loss: 0.5253 - val_accuracy: 0.7604\n",
            "Epoch 107/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5152 - accuracy: 0.7344 - val_loss: 0.5247 - val_accuracy: 0.7604\n",
            "Epoch 108/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5144 - accuracy: 0.7344 - val_loss: 0.5242 - val_accuracy: 0.7604\n",
            "Epoch 109/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5138 - accuracy: 0.7344 - val_loss: 0.5236 - val_accuracy: 0.7552\n",
            "Epoch 110/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5131 - accuracy: 0.7326 - val_loss: 0.5231 - val_accuracy: 0.7552\n",
            "Epoch 111/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5124 - accuracy: 0.7361 - val_loss: 0.5225 - val_accuracy: 0.7552\n",
            "Epoch 112/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5119 - accuracy: 0.7378 - val_loss: 0.5220 - val_accuracy: 0.7552\n",
            "Epoch 113/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5113 - accuracy: 0.7378 - val_loss: 0.5215 - val_accuracy: 0.7500\n",
            "Epoch 114/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5107 - accuracy: 0.7378 - val_loss: 0.5210 - val_accuracy: 0.7500\n",
            "Epoch 115/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5101 - accuracy: 0.7396 - val_loss: 0.5205 - val_accuracy: 0.7500\n",
            "Epoch 116/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5095 - accuracy: 0.7396 - val_loss: 0.5200 - val_accuracy: 0.7500\n",
            "Epoch 117/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5089 - accuracy: 0.7431 - val_loss: 0.5195 - val_accuracy: 0.7500\n",
            "Epoch 118/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5083 - accuracy: 0.7413 - val_loss: 0.5191 - val_accuracy: 0.7500\n",
            "Epoch 119/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5077 - accuracy: 0.7413 - val_loss: 0.5186 - val_accuracy: 0.7500\n",
            "Epoch 120/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.5072 - accuracy: 0.7431 - val_loss: 0.5181 - val_accuracy: 0.7552\n",
            "Epoch 121/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5067 - accuracy: 0.7431 - val_loss: 0.5177 - val_accuracy: 0.7552\n",
            "Epoch 122/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5061 - accuracy: 0.7448 - val_loss: 0.5172 - val_accuracy: 0.7552\n",
            "Epoch 123/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5056 - accuracy: 0.7448 - val_loss: 0.5168 - val_accuracy: 0.7552\n",
            "Epoch 124/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5051 - accuracy: 0.7465 - val_loss: 0.5164 - val_accuracy: 0.7552\n",
            "Epoch 125/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5045 - accuracy: 0.7448 - val_loss: 0.5159 - val_accuracy: 0.7604\n",
            "Epoch 126/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5040 - accuracy: 0.7465 - val_loss: 0.5155 - val_accuracy: 0.7656\n",
            "Epoch 127/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5035 - accuracy: 0.7465 - val_loss: 0.5151 - val_accuracy: 0.7656\n",
            "Epoch 128/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5029 - accuracy: 0.7465 - val_loss: 0.5147 - val_accuracy: 0.7656\n",
            "Epoch 129/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.5024 - accuracy: 0.7500 - val_loss: 0.5143 - val_accuracy: 0.7708\n",
            "Epoch 130/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5019 - accuracy: 0.7483 - val_loss: 0.5139 - val_accuracy: 0.7708\n",
            "Epoch 131/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5015 - accuracy: 0.7465 - val_loss: 0.5135 - val_accuracy: 0.7708\n",
            "Epoch 132/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5009 - accuracy: 0.7500 - val_loss: 0.5131 - val_accuracy: 0.7708\n",
            "Epoch 133/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5005 - accuracy: 0.7483 - val_loss: 0.5127 - val_accuracy: 0.7708\n",
            "Epoch 134/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5000 - accuracy: 0.7517 - val_loss: 0.5124 - val_accuracy: 0.7708\n",
            "Epoch 135/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4995 - accuracy: 0.7500 - val_loss: 0.5120 - val_accuracy: 0.7656\n",
            "Epoch 136/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4991 - accuracy: 0.7500 - val_loss: 0.5116 - val_accuracy: 0.7604\n",
            "Epoch 137/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4986 - accuracy: 0.7517 - val_loss: 0.5113 - val_accuracy: 0.7604\n",
            "Epoch 138/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4982 - accuracy: 0.7517 - val_loss: 0.5109 - val_accuracy: 0.7552\n",
            "Epoch 139/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4977 - accuracy: 0.7517 - val_loss: 0.5106 - val_accuracy: 0.7552\n",
            "Epoch 140/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4973 - accuracy: 0.7517 - val_loss: 0.5102 - val_accuracy: 0.7552\n",
            "Epoch 141/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4969 - accuracy: 0.7517 - val_loss: 0.5099 - val_accuracy: 0.7552\n",
            "Epoch 142/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4964 - accuracy: 0.7535 - val_loss: 0.5096 - val_accuracy: 0.7552\n",
            "Epoch 143/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4960 - accuracy: 0.7535 - val_loss: 0.5093 - val_accuracy: 0.7552\n",
            "Epoch 144/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4956 - accuracy: 0.7535 - val_loss: 0.5089 - val_accuracy: 0.7552\n",
            "Epoch 145/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4951 - accuracy: 0.7552 - val_loss: 0.5086 - val_accuracy: 0.7604\n",
            "Epoch 146/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4947 - accuracy: 0.7552 - val_loss: 0.5083 - val_accuracy: 0.7604\n",
            "Epoch 147/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4943 - accuracy: 0.7569 - val_loss: 0.5080 - val_accuracy: 0.7656\n",
            "Epoch 148/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4940 - accuracy: 0.7552 - val_loss: 0.5077 - val_accuracy: 0.7656\n",
            "Epoch 149/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4936 - accuracy: 0.7500 - val_loss: 0.5074 - val_accuracy: 0.7656\n",
            "Epoch 150/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4932 - accuracy: 0.7535 - val_loss: 0.5071 - val_accuracy: 0.7656\n",
            "Epoch 151/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4928 - accuracy: 0.7517 - val_loss: 0.5068 - val_accuracy: 0.7656\n",
            "Epoch 152/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4925 - accuracy: 0.7517 - val_loss: 0.5066 - val_accuracy: 0.7656\n",
            "Epoch 153/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4922 - accuracy: 0.7517 - val_loss: 0.5063 - val_accuracy: 0.7656\n",
            "Epoch 154/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4917 - accuracy: 0.7517 - val_loss: 0.5060 - val_accuracy: 0.7656\n",
            "Epoch 155/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4913 - accuracy: 0.7587 - val_loss: 0.5057 - val_accuracy: 0.7656\n",
            "Epoch 156/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4910 - accuracy: 0.7569 - val_loss: 0.5055 - val_accuracy: 0.7656\n",
            "Epoch 157/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4906 - accuracy: 0.7535 - val_loss: 0.5052 - val_accuracy: 0.7656\n",
            "Epoch 158/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4903 - accuracy: 0.7569 - val_loss: 0.5050 - val_accuracy: 0.7708\n",
            "Epoch 159/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4899 - accuracy: 0.7569 - val_loss: 0.5047 - val_accuracy: 0.7708\n",
            "Epoch 160/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4896 - accuracy: 0.7552 - val_loss: 0.5045 - val_accuracy: 0.7708\n",
            "Epoch 161/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4892 - accuracy: 0.7569 - val_loss: 0.5042 - val_accuracy: 0.7708\n",
            "Epoch 162/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4889 - accuracy: 0.7569 - val_loss: 0.5040 - val_accuracy: 0.7708\n",
            "Epoch 163/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4885 - accuracy: 0.7552 - val_loss: 0.5037 - val_accuracy: 0.7708\n",
            "Epoch 164/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4882 - accuracy: 0.7552 - val_loss: 0.5035 - val_accuracy: 0.7708\n",
            "Epoch 165/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4879 - accuracy: 0.7569 - val_loss: 0.5033 - val_accuracy: 0.7708\n",
            "Epoch 166/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4876 - accuracy: 0.7569 - val_loss: 0.5031 - val_accuracy: 0.7708\n",
            "Epoch 167/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4873 - accuracy: 0.7569 - val_loss: 0.5028 - val_accuracy: 0.7708\n",
            "Epoch 168/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4870 - accuracy: 0.7587 - val_loss: 0.5026 - val_accuracy: 0.7708\n",
            "Epoch 169/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4866 - accuracy: 0.7569 - val_loss: 0.5024 - val_accuracy: 0.7708\n",
            "Epoch 170/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4864 - accuracy: 0.7569 - val_loss: 0.5022 - val_accuracy: 0.7708\n",
            "Epoch 171/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4861 - accuracy: 0.7587 - val_loss: 0.5020 - val_accuracy: 0.7604\n",
            "Epoch 172/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4857 - accuracy: 0.7587 - val_loss: 0.5018 - val_accuracy: 0.7604\n",
            "Epoch 173/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4854 - accuracy: 0.7587 - val_loss: 0.5016 - val_accuracy: 0.7604\n",
            "Epoch 174/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4852 - accuracy: 0.7587 - val_loss: 0.5014 - val_accuracy: 0.7604\n",
            "Epoch 175/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4849 - accuracy: 0.7587 - val_loss: 0.5012 - val_accuracy: 0.7552\n",
            "Epoch 176/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4846 - accuracy: 0.7587 - val_loss: 0.5010 - val_accuracy: 0.7552\n",
            "Epoch 177/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4843 - accuracy: 0.7587 - val_loss: 0.5008 - val_accuracy: 0.7500\n",
            "Epoch 178/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4840 - accuracy: 0.7569 - val_loss: 0.5006 - val_accuracy: 0.7500\n",
            "Epoch 179/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4838 - accuracy: 0.7587 - val_loss: 0.5004 - val_accuracy: 0.7500\n",
            "Epoch 180/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4835 - accuracy: 0.7569 - val_loss: 0.5002 - val_accuracy: 0.7500\n",
            "Epoch 181/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4832 - accuracy: 0.7587 - val_loss: 0.5000 - val_accuracy: 0.7500\n",
            "Epoch 182/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4830 - accuracy: 0.7604 - val_loss: 0.4999 - val_accuracy: 0.7500\n",
            "Epoch 183/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4828 - accuracy: 0.7587 - val_loss: 0.4997 - val_accuracy: 0.7500\n",
            "Epoch 184/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4824 - accuracy: 0.7587 - val_loss: 0.4995 - val_accuracy: 0.7500\n",
            "Epoch 185/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4822 - accuracy: 0.7587 - val_loss: 0.4994 - val_accuracy: 0.7500\n",
            "Epoch 186/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4819 - accuracy: 0.7604 - val_loss: 0.4992 - val_accuracy: 0.7500\n",
            "Epoch 187/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4817 - accuracy: 0.7587 - val_loss: 0.4990 - val_accuracy: 0.7500\n",
            "Epoch 188/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4814 - accuracy: 0.7622 - val_loss: 0.4989 - val_accuracy: 0.7448\n",
            "Epoch 189/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4812 - accuracy: 0.7622 - val_loss: 0.4987 - val_accuracy: 0.7448\n",
            "Epoch 190/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4809 - accuracy: 0.7622 - val_loss: 0.4985 - val_accuracy: 0.7500\n",
            "Epoch 191/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4807 - accuracy: 0.7622 - val_loss: 0.4984 - val_accuracy: 0.7500\n",
            "Epoch 192/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4804 - accuracy: 0.7622 - val_loss: 0.4982 - val_accuracy: 0.7500\n",
            "Epoch 193/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4802 - accuracy: 0.7622 - val_loss: 0.4981 - val_accuracy: 0.7500\n",
            "Epoch 194/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4801 - accuracy: 0.7604 - val_loss: 0.4979 - val_accuracy: 0.7500\n",
            "Epoch 195/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4798 - accuracy: 0.7622 - val_loss: 0.4978 - val_accuracy: 0.7448\n",
            "Epoch 196/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4796 - accuracy: 0.7622 - val_loss: 0.4977 - val_accuracy: 0.7448\n",
            "Epoch 197/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4793 - accuracy: 0.7604 - val_loss: 0.4975 - val_accuracy: 0.7448\n",
            "Epoch 198/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4791 - accuracy: 0.7622 - val_loss: 0.4974 - val_accuracy: 0.7448\n",
            "Epoch 199/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4789 - accuracy: 0.7622 - val_loss: 0.4972 - val_accuracy: 0.7448\n",
            "Epoch 200/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4787 - accuracy: 0.7622 - val_loss: 0.4971 - val_accuracy: 0.7448\n"
          ]
        }
      ],
      "source": [
        "\n",
        "model.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "run_hist_1 = model.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=200)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "unsigned-nevada",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unsigned-nevada",
        "outputId": "bd573749-9415-4c5c-ba25-ed8e31ff998b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 0s 2ms/step\n",
            "6/6 [==============================] - 0s 3ms/step\n"
          ]
        }
      ],
      "source": [
        "## Like we did for the Random Forest, we generate two kinds of predictions\n",
        "#  One is a hard decision, the other is a probabilitistic score.\n",
        "\n",
        "y_pred_class_nn_1 = (model.predict(X_test_norm) > 0.5).astype(\"int32\")\n",
        "y_pred_prob_nn_1 = model.predict(X_test_norm)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Author's note: `.predict_classes()` has been omitted from TensorFlow starting from version 2.6. The following has been used to remedy this: `(model.predict(x_test) > 0.5).astype(\"int32\")`\n",
        "\n",
        "[Source 1](https://stackoverflow.com/questions/68836551/keras-attributeerror-sequential-object-has-no-attribute-predict-classes)\n",
        "\n",
        "[Source 2](https://stackoverflow.com/questions/51382524/what-is-the-difference-between-predict-and-predict-class-functions-in-keras)"
      ],
      "metadata": {
        "id": "__KWBhoSiL9S"
      },
      "id": "__KWBhoSiL9S"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tough-catering",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tough-catering",
        "outputId": "e3e6ba3d-b5b1-48a6-b239-4381a0f124c1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ],
      "source": [
        "# Let's check out the outputs to get a feel for how keras apis work.\n",
        "y_pred_class_nn_1[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "combined-zimbabwe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "combined-zimbabwe",
        "outputId": "3bc784ff-c112-4a8b-c866-95cc1f8cabd5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.47061905],\n",
              "       [0.6784095 ],\n",
              "       [0.30403063],\n",
              "       [0.31542656],\n",
              "       [0.17722523],\n",
              "       [0.50674564],\n",
              "       [0.08729361],\n",
              "       [0.36328804],\n",
              "       [0.7782391 ],\n",
              "       [0.2397484 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ],
      "source": [
        "y_pred_prob_nn_1[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "going-estonia",
      "metadata": {
        "id": "going-estonia"
      },
      "source": [
        "Create the plot_roc function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "supposed-moderator",
      "metadata": {
        "id": "supposed-moderator"
      },
      "outputs": [],
      "source": [
        "def plot_roc(y_test, y_pred, model_name):\n",
        "    fpr, tpr, thr = roc_curve(y_test, y_pred)\n",
        "    fig, ax = plt.subplots(figsize=(6, 6))\n",
        "    ax.plot(fpr, tpr, 'k-')\n",
        "    ax.plot([0, 1], [0, 1], 'k--', linewidth=.5)  # roc curve for random model\n",
        "    ax.grid(True)\n",
        "    ax.set(title='ROC Curve for {} on PIMA diabetes problem'.format(model_name),\n",
        "           xlim=[-0.01, 1.01], ylim=[-0.01, 1.01])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "second-festival",
      "metadata": {
        "id": "second-festival"
      },
      "source": [
        "Evaluate the model performance and plot the ROC CURVE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eleven-nebraska",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 580
        },
        "id": "eleven-nebraska",
        "outputId": "3c746cf7-a171-404f-8804-00e2576cb10b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy is 0.745\n",
            "roc-auc is 0.820\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_1)))\n",
        "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_1)))\n",
        "\n",
        "plot_roc(y_test, y_pred_prob_nn_1, 'NN')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "invalid-nevada",
      "metadata": {
        "id": "invalid-nevada"
      },
      "source": [
        " Plot the training loss and the validation loss over the different epochs and see how it looks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hidden-physics",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hidden-physics",
        "outputId": "2e9bfbf0-4373-4536-b6b4-b0e5ccd91746"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ],
      "source": [
        "run_hist_1.history.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "banned-spider",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "banned-spider",
        "outputId": "273ff604-e8e4-435e-c11e-057a88ef330b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fcb876f1630>"
            ]
          },
          "metadata": {},
          "execution_count": 136
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.plot(run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
        "ax.plot(run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
        "ax.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "superb-circus",
      "metadata": {
        "id": "superb-circus"
      },
      "source": [
        "What is your interpretation about the result of the train and validation loss?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "german-cherry",
      "metadata": {
        "id": "german-cherry"
      },
      "source": [
        "# Answer:\n",
        "\n",
        "Based on the graph, we can say that the training data has reached a higher accuracy than the validation data due to their loss. The training data has achieved approximately 0.45 loss by the 200 epoch while the validation data only managed to reach approximately 0.50 loss in the same epoch.\n",
        "\n",
        "We can also say that the model is learning since the loss of both training and validation datasets decreases as the epoch number increases. Although at a certain point, roughly 100 epochs, we can say that the model slowly struggles to learn or 'reached a limit' as the loss does not get any lower for the validation dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "involved-slovak",
      "metadata": {
        "id": "involved-slovak"
      },
      "source": [
        "#### Supplementary Activity"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pending-publisher",
      "metadata": {
        "id": "pending-publisher"
      },
      "source": [
        "* Build a model with two hidden layers, each with 6 nodes\n",
        "* Use the \"relu\" activation function for the hidden layers, and \"sigmoid\" for the final layer\n",
        "* Use a learning rate of .003 and train for 1500 epochs\n",
        "* Graph the trajectory of the loss functions, accuracy on both train and test set\n",
        "* Plot the roc curve for the predictions\n",
        "* Use different learning rates, numbers of epochs, and network structures.\n",
        "* Plot the results of training and validation loss using different learning rates, number of epocgs and network structures\n",
        "* Interpret your result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Building the model (2 hidden layers with 6 nodes (relu) each | 1 output layer with 1 node (sigmoid))\n",
        "model_supp  = Sequential([\n",
        "    Dense(6, input_shape=(8,), activation=\"relu\"),\n",
        "    Dense(6, activation=\"relu\"),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])"
      ],
      "metadata": {
        "id": "uc4FpeoNnCC5"
      },
      "id": "uc4FpeoNnCC5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Veiew the model summary\n",
        "model_supp.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4VP3Qv7inZVF",
        "outputId": "2a20106f-3351-4e11-e59f-333c1d2ae756"
      },
      "id": "4VP3Qv7inZVF",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_2 (Dense)             (None, 6)                 54        \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 6)                 42        \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 7         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 103 (412.00 Byte)\n",
            "Trainable params: 103 (412.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the modle and use a learning rate of 0.003\n",
        "model_supp.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Fit the model and train for 1,500 epochs\n",
        "run_hist_supp = model_supp.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1500)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cgqU8TMUn_HA",
        "outputId": "0199aeaa-ac3a-4655-f7a7-196d6b180249"
      },
      "id": "cgqU8TMUn_HA",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1500\n",
            "18/18 [==============================] - 2s 30ms/step - loss: 0.7231 - accuracy: 0.5694 - val_loss: 0.7073 - val_accuracy: 0.6042\n",
            "Epoch 2/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.7127 - accuracy: 0.6042 - val_loss: 0.6980 - val_accuracy: 0.6406\n",
            "Epoch 3/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.7033 - accuracy: 0.6111 - val_loss: 0.6896 - val_accuracy: 0.6510\n",
            "Epoch 4/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.6948 - accuracy: 0.6250 - val_loss: 0.6820 - val_accuracy: 0.6615\n",
            "Epoch 5/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6870 - accuracy: 0.6337 - val_loss: 0.6752 - val_accuracy: 0.6719\n",
            "Epoch 6/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.6798 - accuracy: 0.6441 - val_loss: 0.6689 - val_accuracy: 0.6771\n",
            "Epoch 7/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.6731 - accuracy: 0.6493 - val_loss: 0.6629 - val_accuracy: 0.6823\n",
            "Epoch 8/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6669 - accuracy: 0.6597 - val_loss: 0.6572 - val_accuracy: 0.6875\n",
            "Epoch 9/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6610 - accuracy: 0.6684 - val_loss: 0.6518 - val_accuracy: 0.7031\n",
            "Epoch 10/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.6554 - accuracy: 0.6788 - val_loss: 0.6466 - val_accuracy: 0.7083\n",
            "Epoch 11/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.6503 - accuracy: 0.6806 - val_loss: 0.6416 - val_accuracy: 0.7135\n",
            "Epoch 12/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.6452 - accuracy: 0.6858 - val_loss: 0.6367 - val_accuracy: 0.7188\n",
            "Epoch 13/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6406 - accuracy: 0.6910 - val_loss: 0.6321 - val_accuracy: 0.7188\n",
            "Epoch 14/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.6362 - accuracy: 0.6927 - val_loss: 0.6277 - val_accuracy: 0.7188\n",
            "Epoch 15/1500\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.6320 - accuracy: 0.6944 - val_loss: 0.6235 - val_accuracy: 0.7240\n",
            "Epoch 16/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6279 - accuracy: 0.6962 - val_loss: 0.6193 - val_accuracy: 0.7240\n",
            "Epoch 17/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6240 - accuracy: 0.6927 - val_loss: 0.6152 - val_accuracy: 0.7240\n",
            "Epoch 18/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6200 - accuracy: 0.6944 - val_loss: 0.6112 - val_accuracy: 0.7240\n",
            "Epoch 19/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6162 - accuracy: 0.6979 - val_loss: 0.6073 - val_accuracy: 0.7240\n",
            "Epoch 20/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6125 - accuracy: 0.7014 - val_loss: 0.6035 - val_accuracy: 0.7188\n",
            "Epoch 21/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6088 - accuracy: 0.7031 - val_loss: 0.5999 - val_accuracy: 0.7188\n",
            "Epoch 22/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6052 - accuracy: 0.7049 - val_loss: 0.5964 - val_accuracy: 0.7188\n",
            "Epoch 23/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6018 - accuracy: 0.7101 - val_loss: 0.5929 - val_accuracy: 0.7188\n",
            "Epoch 24/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5983 - accuracy: 0.7135 - val_loss: 0.5897 - val_accuracy: 0.7188\n",
            "Epoch 25/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5948 - accuracy: 0.7135 - val_loss: 0.5864 - val_accuracy: 0.7344\n",
            "Epoch 26/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5915 - accuracy: 0.7153 - val_loss: 0.5832 - val_accuracy: 0.7344\n",
            "Epoch 27/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5883 - accuracy: 0.7153 - val_loss: 0.5802 - val_accuracy: 0.7344\n",
            "Epoch 28/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5850 - accuracy: 0.7153 - val_loss: 0.5771 - val_accuracy: 0.7344\n",
            "Epoch 29/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5820 - accuracy: 0.7170 - val_loss: 0.5741 - val_accuracy: 0.7344\n",
            "Epoch 30/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5788 - accuracy: 0.7188 - val_loss: 0.5712 - val_accuracy: 0.7344\n",
            "Epoch 31/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5756 - accuracy: 0.7188 - val_loss: 0.5681 - val_accuracy: 0.7344\n",
            "Epoch 32/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5725 - accuracy: 0.7222 - val_loss: 0.5650 - val_accuracy: 0.7396\n",
            "Epoch 33/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5692 - accuracy: 0.7222 - val_loss: 0.5622 - val_accuracy: 0.7448\n",
            "Epoch 34/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5662 - accuracy: 0.7240 - val_loss: 0.5592 - val_accuracy: 0.7500\n",
            "Epoch 35/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5630 - accuracy: 0.7222 - val_loss: 0.5564 - val_accuracy: 0.7500\n",
            "Epoch 36/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5600 - accuracy: 0.7205 - val_loss: 0.5537 - val_accuracy: 0.7552\n",
            "Epoch 37/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5571 - accuracy: 0.7222 - val_loss: 0.5509 - val_accuracy: 0.7708\n",
            "Epoch 38/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5541 - accuracy: 0.7240 - val_loss: 0.5483 - val_accuracy: 0.7708\n",
            "Epoch 39/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5513 - accuracy: 0.7240 - val_loss: 0.5458 - val_accuracy: 0.7708\n",
            "Epoch 40/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5484 - accuracy: 0.7222 - val_loss: 0.5434 - val_accuracy: 0.7708\n",
            "Epoch 41/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5455 - accuracy: 0.7326 - val_loss: 0.5411 - val_accuracy: 0.7656\n",
            "Epoch 42/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5427 - accuracy: 0.7326 - val_loss: 0.5389 - val_accuracy: 0.7656\n",
            "Epoch 43/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5400 - accuracy: 0.7326 - val_loss: 0.5367 - val_accuracy: 0.7656\n",
            "Epoch 44/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5375 - accuracy: 0.7274 - val_loss: 0.5345 - val_accuracy: 0.7604\n",
            "Epoch 45/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5347 - accuracy: 0.7292 - val_loss: 0.5325 - val_accuracy: 0.7604\n",
            "Epoch 46/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5320 - accuracy: 0.7292 - val_loss: 0.5307 - val_accuracy: 0.7552\n",
            "Epoch 47/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5296 - accuracy: 0.7326 - val_loss: 0.5289 - val_accuracy: 0.7552\n",
            "Epoch 48/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5271 - accuracy: 0.7309 - val_loss: 0.5272 - val_accuracy: 0.7552\n",
            "Epoch 49/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5247 - accuracy: 0.7378 - val_loss: 0.5256 - val_accuracy: 0.7604\n",
            "Epoch 50/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5225 - accuracy: 0.7361 - val_loss: 0.5241 - val_accuracy: 0.7604\n",
            "Epoch 51/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5200 - accuracy: 0.7361 - val_loss: 0.5224 - val_accuracy: 0.7604\n",
            "Epoch 52/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5176 - accuracy: 0.7378 - val_loss: 0.5210 - val_accuracy: 0.7604\n",
            "Epoch 53/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5153 - accuracy: 0.7361 - val_loss: 0.5197 - val_accuracy: 0.7604\n",
            "Epoch 54/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5131 - accuracy: 0.7396 - val_loss: 0.5183 - val_accuracy: 0.7604\n",
            "Epoch 55/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5110 - accuracy: 0.7378 - val_loss: 0.5171 - val_accuracy: 0.7604\n",
            "Epoch 56/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5090 - accuracy: 0.7413 - val_loss: 0.5160 - val_accuracy: 0.7604\n",
            "Epoch 57/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5071 - accuracy: 0.7396 - val_loss: 0.5149 - val_accuracy: 0.7604\n",
            "Epoch 58/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5051 - accuracy: 0.7378 - val_loss: 0.5138 - val_accuracy: 0.7708\n",
            "Epoch 59/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5033 - accuracy: 0.7413 - val_loss: 0.5128 - val_accuracy: 0.7760\n",
            "Epoch 60/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5014 - accuracy: 0.7378 - val_loss: 0.5119 - val_accuracy: 0.7812\n",
            "Epoch 61/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4996 - accuracy: 0.7396 - val_loss: 0.5109 - val_accuracy: 0.7812\n",
            "Epoch 62/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4979 - accuracy: 0.7413 - val_loss: 0.5100 - val_accuracy: 0.7760\n",
            "Epoch 63/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4963 - accuracy: 0.7431 - val_loss: 0.5093 - val_accuracy: 0.7760\n",
            "Epoch 64/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4945 - accuracy: 0.7448 - val_loss: 0.5085 - val_accuracy: 0.7760\n",
            "Epoch 65/1500\n",
            "18/18 [==============================] - 0s 20ms/step - loss: 0.4931 - accuracy: 0.7448 - val_loss: 0.5078 - val_accuracy: 0.7760\n",
            "Epoch 66/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4917 - accuracy: 0.7465 - val_loss: 0.5070 - val_accuracy: 0.7760\n",
            "Epoch 67/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4903 - accuracy: 0.7500 - val_loss: 0.5062 - val_accuracy: 0.7760\n",
            "Epoch 68/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4890 - accuracy: 0.7517 - val_loss: 0.5055 - val_accuracy: 0.7760\n",
            "Epoch 69/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4876 - accuracy: 0.7535 - val_loss: 0.5047 - val_accuracy: 0.7760\n",
            "Epoch 70/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4864 - accuracy: 0.7552 - val_loss: 0.5042 - val_accuracy: 0.7760\n",
            "Epoch 71/1500\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.4852 - accuracy: 0.7552 - val_loss: 0.5036 - val_accuracy: 0.7760\n",
            "Epoch 72/1500\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.4841 - accuracy: 0.7552 - val_loss: 0.5029 - val_accuracy: 0.7760\n",
            "Epoch 73/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4830 - accuracy: 0.7587 - val_loss: 0.5024 - val_accuracy: 0.7865\n",
            "Epoch 74/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4820 - accuracy: 0.7569 - val_loss: 0.5018 - val_accuracy: 0.7865\n",
            "Epoch 75/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4809 - accuracy: 0.7569 - val_loss: 0.5013 - val_accuracy: 0.7865\n",
            "Epoch 76/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4800 - accuracy: 0.7552 - val_loss: 0.5008 - val_accuracy: 0.7865\n",
            "Epoch 77/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4790 - accuracy: 0.7569 - val_loss: 0.5004 - val_accuracy: 0.7865\n",
            "Epoch 78/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4782 - accuracy: 0.7552 - val_loss: 0.4999 - val_accuracy: 0.7917\n",
            "Epoch 79/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4772 - accuracy: 0.7552 - val_loss: 0.4995 - val_accuracy: 0.7917\n",
            "Epoch 80/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4762 - accuracy: 0.7552 - val_loss: 0.4991 - val_accuracy: 0.7917\n",
            "Epoch 81/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4755 - accuracy: 0.7569 - val_loss: 0.4986 - val_accuracy: 0.7865\n",
            "Epoch 82/1500\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.4746 - accuracy: 0.7569 - val_loss: 0.4981 - val_accuracy: 0.7865\n",
            "Epoch 83/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4736 - accuracy: 0.7604 - val_loss: 0.4977 - val_accuracy: 0.7865\n",
            "Epoch 84/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4728 - accuracy: 0.7639 - val_loss: 0.4972 - val_accuracy: 0.7865\n",
            "Epoch 85/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4718 - accuracy: 0.7639 - val_loss: 0.4968 - val_accuracy: 0.7865\n",
            "Epoch 86/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4712 - accuracy: 0.7604 - val_loss: 0.4963 - val_accuracy: 0.7865\n",
            "Epoch 87/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4702 - accuracy: 0.7587 - val_loss: 0.4959 - val_accuracy: 0.7917\n",
            "Epoch 88/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4694 - accuracy: 0.7569 - val_loss: 0.4953 - val_accuracy: 0.7917\n",
            "Epoch 89/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4685 - accuracy: 0.7604 - val_loss: 0.4949 - val_accuracy: 0.7917\n",
            "Epoch 90/1500\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.4676 - accuracy: 0.7622 - val_loss: 0.4945 - val_accuracy: 0.7917\n",
            "Epoch 91/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4667 - accuracy: 0.7622 - val_loss: 0.4942 - val_accuracy: 0.7865\n",
            "Epoch 92/1500\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.4661 - accuracy: 0.7639 - val_loss: 0.4939 - val_accuracy: 0.7812\n",
            "Epoch 93/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4652 - accuracy: 0.7639 - val_loss: 0.4936 - val_accuracy: 0.7812\n",
            "Epoch 94/1500\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 0.4647 - accuracy: 0.7622 - val_loss: 0.4933 - val_accuracy: 0.7812\n",
            "Epoch 95/1500\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.4638 - accuracy: 0.7639 - val_loss: 0.4930 - val_accuracy: 0.7812\n",
            "Epoch 96/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4633 - accuracy: 0.7639 - val_loss: 0.4928 - val_accuracy: 0.7812\n",
            "Epoch 97/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4626 - accuracy: 0.7656 - val_loss: 0.4926 - val_accuracy: 0.7812\n",
            "Epoch 98/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4620 - accuracy: 0.7656 - val_loss: 0.4925 - val_accuracy: 0.7812\n",
            "Epoch 99/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4614 - accuracy: 0.7674 - val_loss: 0.4923 - val_accuracy: 0.7812\n",
            "Epoch 100/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4608 - accuracy: 0.7674 - val_loss: 0.4920 - val_accuracy: 0.7812\n",
            "Epoch 101/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4602 - accuracy: 0.7674 - val_loss: 0.4918 - val_accuracy: 0.7760\n",
            "Epoch 102/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4596 - accuracy: 0.7656 - val_loss: 0.4917 - val_accuracy: 0.7760\n",
            "Epoch 103/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4591 - accuracy: 0.7674 - val_loss: 0.4915 - val_accuracy: 0.7812\n",
            "Epoch 104/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4586 - accuracy: 0.7674 - val_loss: 0.4913 - val_accuracy: 0.7812\n",
            "Epoch 105/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4579 - accuracy: 0.7674 - val_loss: 0.4912 - val_accuracy: 0.7812\n",
            "Epoch 106/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4576 - accuracy: 0.7656 - val_loss: 0.4911 - val_accuracy: 0.7812\n",
            "Epoch 107/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4571 - accuracy: 0.7691 - val_loss: 0.4912 - val_accuracy: 0.7812\n",
            "Epoch 108/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4566 - accuracy: 0.7674 - val_loss: 0.4911 - val_accuracy: 0.7812\n",
            "Epoch 109/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4560 - accuracy: 0.7674 - val_loss: 0.4910 - val_accuracy: 0.7812\n",
            "Epoch 110/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4555 - accuracy: 0.7708 - val_loss: 0.4910 - val_accuracy: 0.7812\n",
            "Epoch 111/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4553 - accuracy: 0.7674 - val_loss: 0.4909 - val_accuracy: 0.7812\n",
            "Epoch 112/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4548 - accuracy: 0.7691 - val_loss: 0.4906 - val_accuracy: 0.7812\n",
            "Epoch 113/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4542 - accuracy: 0.7726 - val_loss: 0.4905 - val_accuracy: 0.7812\n",
            "Epoch 114/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4538 - accuracy: 0.7708 - val_loss: 0.4904 - val_accuracy: 0.7812\n",
            "Epoch 115/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4534 - accuracy: 0.7691 - val_loss: 0.4904 - val_accuracy: 0.7760\n",
            "Epoch 116/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4530 - accuracy: 0.7674 - val_loss: 0.4903 - val_accuracy: 0.7760\n",
            "Epoch 117/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4527 - accuracy: 0.7726 - val_loss: 0.4903 - val_accuracy: 0.7708\n",
            "Epoch 118/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4524 - accuracy: 0.7708 - val_loss: 0.4903 - val_accuracy: 0.7656\n",
            "Epoch 119/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4521 - accuracy: 0.7708 - val_loss: 0.4902 - val_accuracy: 0.7656\n",
            "Epoch 120/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4515 - accuracy: 0.7726 - val_loss: 0.4902 - val_accuracy: 0.7656\n",
            "Epoch 121/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4513 - accuracy: 0.7726 - val_loss: 0.4902 - val_accuracy: 0.7656\n",
            "Epoch 122/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4511 - accuracy: 0.7743 - val_loss: 0.4901 - val_accuracy: 0.7656\n",
            "Epoch 123/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4508 - accuracy: 0.7743 - val_loss: 0.4902 - val_accuracy: 0.7708\n",
            "Epoch 124/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.7726 - val_loss: 0.4902 - val_accuracy: 0.7708\n",
            "Epoch 125/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4502 - accuracy: 0.7743 - val_loss: 0.4903 - val_accuracy: 0.7708\n",
            "Epoch 126/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4499 - accuracy: 0.7743 - val_loss: 0.4902 - val_accuracy: 0.7708\n",
            "Epoch 127/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4495 - accuracy: 0.7726 - val_loss: 0.4901 - val_accuracy: 0.7708\n",
            "Epoch 128/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4492 - accuracy: 0.7760 - val_loss: 0.4900 - val_accuracy: 0.7656\n",
            "Epoch 129/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4490 - accuracy: 0.7743 - val_loss: 0.4900 - val_accuracy: 0.7656\n",
            "Epoch 130/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4486 - accuracy: 0.7760 - val_loss: 0.4900 - val_accuracy: 0.7656\n",
            "Epoch 131/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4484 - accuracy: 0.7743 - val_loss: 0.4900 - val_accuracy: 0.7656\n",
            "Epoch 132/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4482 - accuracy: 0.7743 - val_loss: 0.4901 - val_accuracy: 0.7656\n",
            "Epoch 133/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4481 - accuracy: 0.7778 - val_loss: 0.4901 - val_accuracy: 0.7604\n",
            "Epoch 134/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4478 - accuracy: 0.7778 - val_loss: 0.4901 - val_accuracy: 0.7604\n",
            "Epoch 135/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4475 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7604\n",
            "Epoch 136/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4473 - accuracy: 0.7760 - val_loss: 0.4901 - val_accuracy: 0.7604\n",
            "Epoch 137/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4471 - accuracy: 0.7760 - val_loss: 0.4902 - val_accuracy: 0.7604\n",
            "Epoch 138/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4468 - accuracy: 0.7760 - val_loss: 0.4903 - val_accuracy: 0.7604\n",
            "Epoch 139/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4466 - accuracy: 0.7760 - val_loss: 0.4904 - val_accuracy: 0.7604\n",
            "Epoch 140/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4465 - accuracy: 0.7760 - val_loss: 0.4905 - val_accuracy: 0.7604\n",
            "Epoch 141/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4462 - accuracy: 0.7743 - val_loss: 0.4906 - val_accuracy: 0.7604\n",
            "Epoch 142/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4461 - accuracy: 0.7743 - val_loss: 0.4907 - val_accuracy: 0.7604\n",
            "Epoch 143/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4460 - accuracy: 0.7743 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
            "Epoch 144/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4457 - accuracy: 0.7743 - val_loss: 0.4909 - val_accuracy: 0.7552\n",
            "Epoch 145/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4455 - accuracy: 0.7743 - val_loss: 0.4909 - val_accuracy: 0.7500\n",
            "Epoch 146/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4454 - accuracy: 0.7743 - val_loss: 0.4910 - val_accuracy: 0.7500\n",
            "Epoch 147/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4453 - accuracy: 0.7743 - val_loss: 0.4911 - val_accuracy: 0.7500\n",
            "Epoch 148/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4450 - accuracy: 0.7743 - val_loss: 0.4913 - val_accuracy: 0.7500\n",
            "Epoch 149/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4449 - accuracy: 0.7743 - val_loss: 0.4914 - val_accuracy: 0.7552\n",
            "Epoch 150/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4447 - accuracy: 0.7743 - val_loss: 0.4916 - val_accuracy: 0.7552\n",
            "Epoch 151/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4445 - accuracy: 0.7743 - val_loss: 0.4917 - val_accuracy: 0.7500\n",
            "Epoch 152/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4443 - accuracy: 0.7726 - val_loss: 0.4917 - val_accuracy: 0.7500\n",
            "Epoch 153/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4442 - accuracy: 0.7726 - val_loss: 0.4918 - val_accuracy: 0.7500\n",
            "Epoch 154/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4440 - accuracy: 0.7743 - val_loss: 0.4919 - val_accuracy: 0.7500\n",
            "Epoch 155/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4439 - accuracy: 0.7726 - val_loss: 0.4920 - val_accuracy: 0.7500\n",
            "Epoch 156/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4437 - accuracy: 0.7743 - val_loss: 0.4920 - val_accuracy: 0.7500\n",
            "Epoch 157/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4436 - accuracy: 0.7726 - val_loss: 0.4921 - val_accuracy: 0.7500\n",
            "Epoch 158/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4435 - accuracy: 0.7726 - val_loss: 0.4922 - val_accuracy: 0.7500\n",
            "Epoch 159/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4432 - accuracy: 0.7726 - val_loss: 0.4923 - val_accuracy: 0.7500\n",
            "Epoch 160/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4433 - accuracy: 0.7726 - val_loss: 0.4923 - val_accuracy: 0.7500\n",
            "Epoch 161/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4430 - accuracy: 0.7743 - val_loss: 0.4924 - val_accuracy: 0.7500\n",
            "Epoch 162/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4429 - accuracy: 0.7726 - val_loss: 0.4925 - val_accuracy: 0.7500\n",
            "Epoch 163/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4427 - accuracy: 0.7726 - val_loss: 0.4925 - val_accuracy: 0.7500\n",
            "Epoch 164/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4426 - accuracy: 0.7726 - val_loss: 0.4926 - val_accuracy: 0.7500\n",
            "Epoch 165/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4425 - accuracy: 0.7726 - val_loss: 0.4928 - val_accuracy: 0.7500\n",
            "Epoch 166/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4423 - accuracy: 0.7743 - val_loss: 0.4928 - val_accuracy: 0.7500\n",
            "Epoch 167/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4421 - accuracy: 0.7726 - val_loss: 0.4929 - val_accuracy: 0.7448\n",
            "Epoch 168/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4421 - accuracy: 0.7726 - val_loss: 0.4929 - val_accuracy: 0.7448\n",
            "Epoch 169/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4420 - accuracy: 0.7743 - val_loss: 0.4930 - val_accuracy: 0.7448\n",
            "Epoch 170/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4417 - accuracy: 0.7760 - val_loss: 0.4931 - val_accuracy: 0.7448\n",
            "Epoch 171/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4416 - accuracy: 0.7743 - val_loss: 0.4932 - val_accuracy: 0.7448\n",
            "Epoch 172/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4415 - accuracy: 0.7743 - val_loss: 0.4932 - val_accuracy: 0.7448\n",
            "Epoch 173/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4414 - accuracy: 0.7760 - val_loss: 0.4933 - val_accuracy: 0.7448\n",
            "Epoch 174/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4413 - accuracy: 0.7743 - val_loss: 0.4933 - val_accuracy: 0.7448\n",
            "Epoch 175/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4411 - accuracy: 0.7743 - val_loss: 0.4934 - val_accuracy: 0.7448\n",
            "Epoch 176/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4411 - accuracy: 0.7743 - val_loss: 0.4935 - val_accuracy: 0.7448\n",
            "Epoch 177/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4411 - accuracy: 0.7760 - val_loss: 0.4935 - val_accuracy: 0.7448\n",
            "Epoch 178/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4407 - accuracy: 0.7760 - val_loss: 0.4935 - val_accuracy: 0.7448\n",
            "Epoch 179/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4407 - accuracy: 0.7778 - val_loss: 0.4936 - val_accuracy: 0.7448\n",
            "Epoch 180/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4407 - accuracy: 0.7760 - val_loss: 0.4936 - val_accuracy: 0.7448\n",
            "Epoch 181/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4405 - accuracy: 0.7760 - val_loss: 0.4936 - val_accuracy: 0.7448\n",
            "Epoch 182/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4404 - accuracy: 0.7760 - val_loss: 0.4937 - val_accuracy: 0.7448\n",
            "Epoch 183/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4403 - accuracy: 0.7795 - val_loss: 0.4937 - val_accuracy: 0.7448\n",
            "Epoch 184/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4403 - accuracy: 0.7795 - val_loss: 0.4937 - val_accuracy: 0.7448\n",
            "Epoch 185/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4403 - accuracy: 0.7760 - val_loss: 0.4939 - val_accuracy: 0.7448\n",
            "Epoch 186/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4400 - accuracy: 0.7778 - val_loss: 0.4939 - val_accuracy: 0.7448\n",
            "Epoch 187/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4400 - accuracy: 0.7760 - val_loss: 0.4940 - val_accuracy: 0.7448\n",
            "Epoch 188/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4397 - accuracy: 0.7812 - val_loss: 0.4940 - val_accuracy: 0.7448\n",
            "Epoch 189/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4397 - accuracy: 0.7760 - val_loss: 0.4941 - val_accuracy: 0.7448\n",
            "Epoch 190/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4395 - accuracy: 0.7795 - val_loss: 0.4941 - val_accuracy: 0.7448\n",
            "Epoch 191/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4395 - accuracy: 0.7778 - val_loss: 0.4941 - val_accuracy: 0.7448\n",
            "Epoch 192/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4394 - accuracy: 0.7795 - val_loss: 0.4942 - val_accuracy: 0.7500\n",
            "Epoch 193/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4393 - accuracy: 0.7795 - val_loss: 0.4943 - val_accuracy: 0.7500\n",
            "Epoch 194/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4391 - accuracy: 0.7795 - val_loss: 0.4943 - val_accuracy: 0.7500\n",
            "Epoch 195/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4390 - accuracy: 0.7795 - val_loss: 0.4944 - val_accuracy: 0.7500\n",
            "Epoch 196/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4389 - accuracy: 0.7778 - val_loss: 0.4945 - val_accuracy: 0.7500\n",
            "Epoch 197/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4389 - accuracy: 0.7795 - val_loss: 0.4945 - val_accuracy: 0.7500\n",
            "Epoch 198/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4389 - accuracy: 0.7795 - val_loss: 0.4946 - val_accuracy: 0.7500\n",
            "Epoch 199/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4387 - accuracy: 0.7795 - val_loss: 0.4945 - val_accuracy: 0.7500\n",
            "Epoch 200/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4386 - accuracy: 0.7760 - val_loss: 0.4946 - val_accuracy: 0.7500\n",
            "Epoch 201/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4385 - accuracy: 0.7812 - val_loss: 0.4946 - val_accuracy: 0.7500\n",
            "Epoch 202/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4384 - accuracy: 0.7778 - val_loss: 0.4947 - val_accuracy: 0.7500\n",
            "Epoch 203/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4383 - accuracy: 0.7778 - val_loss: 0.4948 - val_accuracy: 0.7500\n",
            "Epoch 204/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4382 - accuracy: 0.7743 - val_loss: 0.4947 - val_accuracy: 0.7500\n",
            "Epoch 205/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4381 - accuracy: 0.7795 - val_loss: 0.4948 - val_accuracy: 0.7500\n",
            "Epoch 206/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4379 - accuracy: 0.7795 - val_loss: 0.4948 - val_accuracy: 0.7500\n",
            "Epoch 207/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4380 - accuracy: 0.7795 - val_loss: 0.4948 - val_accuracy: 0.7500\n",
            "Epoch 208/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4379 - accuracy: 0.7778 - val_loss: 0.4948 - val_accuracy: 0.7500\n",
            "Epoch 209/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4378 - accuracy: 0.7795 - val_loss: 0.4948 - val_accuracy: 0.7500\n",
            "Epoch 210/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4376 - accuracy: 0.7795 - val_loss: 0.4949 - val_accuracy: 0.7500\n",
            "Epoch 211/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4376 - accuracy: 0.7778 - val_loss: 0.4949 - val_accuracy: 0.7500\n",
            "Epoch 212/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4375 - accuracy: 0.7778 - val_loss: 0.4950 - val_accuracy: 0.7500\n",
            "Epoch 213/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4374 - accuracy: 0.7812 - val_loss: 0.4950 - val_accuracy: 0.7500\n",
            "Epoch 214/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4374 - accuracy: 0.7812 - val_loss: 0.4950 - val_accuracy: 0.7552\n",
            "Epoch 215/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4371 - accuracy: 0.7778 - val_loss: 0.4950 - val_accuracy: 0.7552\n",
            "Epoch 216/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4371 - accuracy: 0.7778 - val_loss: 0.4951 - val_accuracy: 0.7552\n",
            "Epoch 217/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4371 - accuracy: 0.7795 - val_loss: 0.4951 - val_accuracy: 0.7552\n",
            "Epoch 218/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4370 - accuracy: 0.7778 - val_loss: 0.4951 - val_accuracy: 0.7552\n",
            "Epoch 219/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4370 - accuracy: 0.7812 - val_loss: 0.4952 - val_accuracy: 0.7552\n",
            "Epoch 220/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4369 - accuracy: 0.7812 - val_loss: 0.4953 - val_accuracy: 0.7552\n",
            "Epoch 221/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4367 - accuracy: 0.7812 - val_loss: 0.4954 - val_accuracy: 0.7552\n",
            "Epoch 222/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4367 - accuracy: 0.7812 - val_loss: 0.4954 - val_accuracy: 0.7552\n",
            "Epoch 223/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4366 - accuracy: 0.7830 - val_loss: 0.4954 - val_accuracy: 0.7552\n",
            "Epoch 224/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4365 - accuracy: 0.7812 - val_loss: 0.4954 - val_accuracy: 0.7552\n",
            "Epoch 225/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4364 - accuracy: 0.7795 - val_loss: 0.4954 - val_accuracy: 0.7552\n",
            "Epoch 226/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4364 - accuracy: 0.7812 - val_loss: 0.4955 - val_accuracy: 0.7604\n",
            "Epoch 227/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4363 - accuracy: 0.7812 - val_loss: 0.4955 - val_accuracy: 0.7604\n",
            "Epoch 228/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4361 - accuracy: 0.7795 - val_loss: 0.4955 - val_accuracy: 0.7604\n",
            "Epoch 229/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4361 - accuracy: 0.7812 - val_loss: 0.4955 - val_accuracy: 0.7604\n",
            "Epoch 230/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4360 - accuracy: 0.7830 - val_loss: 0.4956 - val_accuracy: 0.7604\n",
            "Epoch 231/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4358 - accuracy: 0.7812 - val_loss: 0.4957 - val_accuracy: 0.7604\n",
            "Epoch 232/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4359 - accuracy: 0.7795 - val_loss: 0.4956 - val_accuracy: 0.7604\n",
            "Epoch 233/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4358 - accuracy: 0.7812 - val_loss: 0.4957 - val_accuracy: 0.7604\n",
            "Epoch 234/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4356 - accuracy: 0.7830 - val_loss: 0.4957 - val_accuracy: 0.7604\n",
            "Epoch 235/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4355 - accuracy: 0.7812 - val_loss: 0.4956 - val_accuracy: 0.7604\n",
            "Epoch 236/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4354 - accuracy: 0.7795 - val_loss: 0.4956 - val_accuracy: 0.7604\n",
            "Epoch 237/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4353 - accuracy: 0.7830 - val_loss: 0.4956 - val_accuracy: 0.7604\n",
            "Epoch 238/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4353 - accuracy: 0.7812 - val_loss: 0.4957 - val_accuracy: 0.7604\n",
            "Epoch 239/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4351 - accuracy: 0.7830 - val_loss: 0.4958 - val_accuracy: 0.7604\n",
            "Epoch 240/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4350 - accuracy: 0.7830 - val_loss: 0.4958 - val_accuracy: 0.7604\n",
            "Epoch 241/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4350 - accuracy: 0.7795 - val_loss: 0.4959 - val_accuracy: 0.7604\n",
            "Epoch 242/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4349 - accuracy: 0.7795 - val_loss: 0.4958 - val_accuracy: 0.7604\n",
            "Epoch 243/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4349 - accuracy: 0.7812 - val_loss: 0.4960 - val_accuracy: 0.7604\n",
            "Epoch 244/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4348 - accuracy: 0.7830 - val_loss: 0.4959 - val_accuracy: 0.7604\n",
            "Epoch 245/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4348 - accuracy: 0.7830 - val_loss: 0.4961 - val_accuracy: 0.7604\n",
            "Epoch 246/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4346 - accuracy: 0.7847 - val_loss: 0.4961 - val_accuracy: 0.7604\n",
            "Epoch 247/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4345 - accuracy: 0.7882 - val_loss: 0.4961 - val_accuracy: 0.7604\n",
            "Epoch 248/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4346 - accuracy: 0.7865 - val_loss: 0.4960 - val_accuracy: 0.7604\n",
            "Epoch 249/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4344 - accuracy: 0.7830 - val_loss: 0.4960 - val_accuracy: 0.7604\n",
            "Epoch 250/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4343 - accuracy: 0.7847 - val_loss: 0.4960 - val_accuracy: 0.7604\n",
            "Epoch 251/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4342 - accuracy: 0.7847 - val_loss: 0.4960 - val_accuracy: 0.7604\n",
            "Epoch 252/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4341 - accuracy: 0.7865 - val_loss: 0.4961 - val_accuracy: 0.7604\n",
            "Epoch 253/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4341 - accuracy: 0.7865 - val_loss: 0.4962 - val_accuracy: 0.7604\n",
            "Epoch 254/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4339 - accuracy: 0.7865 - val_loss: 0.4962 - val_accuracy: 0.7604\n",
            "Epoch 255/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4339 - accuracy: 0.7847 - val_loss: 0.4962 - val_accuracy: 0.7604\n",
            "Epoch 256/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4339 - accuracy: 0.7882 - val_loss: 0.4963 - val_accuracy: 0.7604\n",
            "Epoch 257/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4338 - accuracy: 0.7882 - val_loss: 0.4963 - val_accuracy: 0.7604\n",
            "Epoch 258/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4337 - accuracy: 0.7865 - val_loss: 0.4964 - val_accuracy: 0.7604\n",
            "Epoch 259/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4335 - accuracy: 0.7865 - val_loss: 0.4965 - val_accuracy: 0.7604\n",
            "Epoch 260/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4335 - accuracy: 0.7865 - val_loss: 0.4965 - val_accuracy: 0.7604\n",
            "Epoch 261/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4335 - accuracy: 0.7865 - val_loss: 0.4965 - val_accuracy: 0.7604\n",
            "Epoch 262/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4334 - accuracy: 0.7865 - val_loss: 0.4965 - val_accuracy: 0.7604\n",
            "Epoch 263/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4332 - accuracy: 0.7865 - val_loss: 0.4965 - val_accuracy: 0.7604\n",
            "Epoch 264/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4335 - accuracy: 0.7847 - val_loss: 0.4966 - val_accuracy: 0.7604\n",
            "Epoch 265/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4333 - accuracy: 0.7865 - val_loss: 0.4966 - val_accuracy: 0.7604\n",
            "Epoch 266/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4331 - accuracy: 0.7865 - val_loss: 0.4966 - val_accuracy: 0.7604\n",
            "Epoch 267/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4331 - accuracy: 0.7899 - val_loss: 0.4967 - val_accuracy: 0.7604\n",
            "Epoch 268/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4329 - accuracy: 0.7830 - val_loss: 0.4967 - val_accuracy: 0.7604\n",
            "Epoch 269/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4330 - accuracy: 0.7847 - val_loss: 0.4967 - val_accuracy: 0.7604\n",
            "Epoch 270/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4328 - accuracy: 0.7865 - val_loss: 0.4966 - val_accuracy: 0.7604\n",
            "Epoch 271/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4327 - accuracy: 0.7830 - val_loss: 0.4967 - val_accuracy: 0.7604\n",
            "Epoch 272/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4326 - accuracy: 0.7847 - val_loss: 0.4968 - val_accuracy: 0.7604\n",
            "Epoch 273/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4326 - accuracy: 0.7847 - val_loss: 0.4968 - val_accuracy: 0.7604\n",
            "Epoch 274/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4324 - accuracy: 0.7847 - val_loss: 0.4969 - val_accuracy: 0.7604\n",
            "Epoch 275/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4325 - accuracy: 0.7847 - val_loss: 0.4970 - val_accuracy: 0.7604\n",
            "Epoch 276/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4325 - accuracy: 0.7865 - val_loss: 0.4971 - val_accuracy: 0.7604\n",
            "Epoch 277/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4322 - accuracy: 0.7865 - val_loss: 0.4971 - val_accuracy: 0.7604\n",
            "Epoch 278/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4322 - accuracy: 0.7865 - val_loss: 0.4971 - val_accuracy: 0.7604\n",
            "Epoch 279/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4322 - accuracy: 0.7847 - val_loss: 0.4972 - val_accuracy: 0.7604\n",
            "Epoch 280/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4321 - accuracy: 0.7865 - val_loss: 0.4973 - val_accuracy: 0.7604\n",
            "Epoch 281/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4321 - accuracy: 0.7865 - val_loss: 0.4972 - val_accuracy: 0.7604\n",
            "Epoch 282/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4320 - accuracy: 0.7882 - val_loss: 0.4973 - val_accuracy: 0.7604\n",
            "Epoch 283/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4318 - accuracy: 0.7865 - val_loss: 0.4974 - val_accuracy: 0.7604\n",
            "Epoch 284/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4317 - accuracy: 0.7882 - val_loss: 0.4974 - val_accuracy: 0.7604\n",
            "Epoch 285/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4317 - accuracy: 0.7899 - val_loss: 0.4974 - val_accuracy: 0.7604\n",
            "Epoch 286/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4316 - accuracy: 0.7882 - val_loss: 0.4975 - val_accuracy: 0.7604\n",
            "Epoch 287/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4316 - accuracy: 0.7882 - val_loss: 0.4975 - val_accuracy: 0.7604\n",
            "Epoch 288/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4316 - accuracy: 0.7847 - val_loss: 0.4976 - val_accuracy: 0.7604\n",
            "Epoch 289/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4315 - accuracy: 0.7882 - val_loss: 0.4976 - val_accuracy: 0.7604\n",
            "Epoch 290/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4316 - accuracy: 0.7882 - val_loss: 0.4976 - val_accuracy: 0.7604\n",
            "Epoch 291/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4314 - accuracy: 0.7865 - val_loss: 0.4977 - val_accuracy: 0.7604\n",
            "Epoch 292/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4312 - accuracy: 0.7917 - val_loss: 0.4977 - val_accuracy: 0.7604\n",
            "Epoch 293/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4313 - accuracy: 0.7899 - val_loss: 0.4977 - val_accuracy: 0.7604\n",
            "Epoch 294/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4313 - accuracy: 0.7917 - val_loss: 0.4976 - val_accuracy: 0.7604\n",
            "Epoch 295/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4312 - accuracy: 0.7934 - val_loss: 0.4976 - val_accuracy: 0.7604\n",
            "Epoch 296/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4311 - accuracy: 0.7917 - val_loss: 0.4976 - val_accuracy: 0.7604\n",
            "Epoch 297/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4310 - accuracy: 0.7917 - val_loss: 0.4976 - val_accuracy: 0.7604\n",
            "Epoch 298/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4308 - accuracy: 0.7882 - val_loss: 0.4977 - val_accuracy: 0.7604\n",
            "Epoch 299/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4308 - accuracy: 0.7917 - val_loss: 0.4977 - val_accuracy: 0.7604\n",
            "Epoch 300/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4308 - accuracy: 0.7882 - val_loss: 0.4979 - val_accuracy: 0.7604\n",
            "Epoch 301/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4307 - accuracy: 0.7899 - val_loss: 0.4979 - val_accuracy: 0.7604\n",
            "Epoch 302/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4306 - accuracy: 0.7899 - val_loss: 0.4980 - val_accuracy: 0.7604\n",
            "Epoch 303/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4306 - accuracy: 0.7899 - val_loss: 0.4982 - val_accuracy: 0.7604\n",
            "Epoch 304/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4305 - accuracy: 0.7882 - val_loss: 0.4984 - val_accuracy: 0.7604\n",
            "Epoch 305/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4305 - accuracy: 0.7865 - val_loss: 0.4985 - val_accuracy: 0.7604\n",
            "Epoch 306/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4304 - accuracy: 0.7899 - val_loss: 0.4986 - val_accuracy: 0.7604\n",
            "Epoch 307/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4303 - accuracy: 0.7882 - val_loss: 0.4985 - val_accuracy: 0.7604\n",
            "Epoch 308/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4302 - accuracy: 0.7917 - val_loss: 0.4987 - val_accuracy: 0.7604\n",
            "Epoch 309/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4302 - accuracy: 0.7917 - val_loss: 0.4986 - val_accuracy: 0.7604\n",
            "Epoch 310/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4301 - accuracy: 0.7899 - val_loss: 0.4987 - val_accuracy: 0.7604\n",
            "Epoch 311/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4301 - accuracy: 0.7899 - val_loss: 0.4987 - val_accuracy: 0.7604\n",
            "Epoch 312/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4300 - accuracy: 0.7882 - val_loss: 0.4988 - val_accuracy: 0.7604\n",
            "Epoch 313/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4297 - accuracy: 0.7917 - val_loss: 0.4988 - val_accuracy: 0.7604\n",
            "Epoch 314/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4297 - accuracy: 0.7882 - val_loss: 0.4989 - val_accuracy: 0.7604\n",
            "Epoch 315/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4297 - accuracy: 0.7865 - val_loss: 0.4991 - val_accuracy: 0.7604\n",
            "Epoch 316/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4295 - accuracy: 0.7865 - val_loss: 0.4991 - val_accuracy: 0.7604\n",
            "Epoch 317/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4295 - accuracy: 0.7899 - val_loss: 0.4992 - val_accuracy: 0.7604\n",
            "Epoch 318/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4294 - accuracy: 0.7882 - val_loss: 0.4993 - val_accuracy: 0.7604\n",
            "Epoch 319/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4294 - accuracy: 0.7899 - val_loss: 0.4993 - val_accuracy: 0.7604\n",
            "Epoch 320/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4292 - accuracy: 0.7882 - val_loss: 0.4993 - val_accuracy: 0.7604\n",
            "Epoch 321/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4292 - accuracy: 0.7882 - val_loss: 0.4993 - val_accuracy: 0.7604\n",
            "Epoch 322/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4291 - accuracy: 0.7899 - val_loss: 0.4994 - val_accuracy: 0.7604\n",
            "Epoch 323/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4290 - accuracy: 0.7865 - val_loss: 0.4995 - val_accuracy: 0.7604\n",
            "Epoch 324/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4289 - accuracy: 0.7865 - val_loss: 0.4996 - val_accuracy: 0.7604\n",
            "Epoch 325/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4290 - accuracy: 0.7882 - val_loss: 0.4996 - val_accuracy: 0.7604\n",
            "Epoch 326/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4289 - accuracy: 0.7865 - val_loss: 0.4997 - val_accuracy: 0.7604\n",
            "Epoch 327/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4290 - accuracy: 0.7882 - val_loss: 0.4998 - val_accuracy: 0.7604\n",
            "Epoch 328/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4289 - accuracy: 0.7865 - val_loss: 0.4998 - val_accuracy: 0.7604\n",
            "Epoch 329/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4287 - accuracy: 0.7865 - val_loss: 0.5000 - val_accuracy: 0.7604\n",
            "Epoch 330/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4286 - accuracy: 0.7882 - val_loss: 0.5000 - val_accuracy: 0.7604\n",
            "Epoch 331/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4286 - accuracy: 0.7847 - val_loss: 0.5001 - val_accuracy: 0.7604\n",
            "Epoch 332/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4284 - accuracy: 0.7865 - val_loss: 0.5002 - val_accuracy: 0.7604\n",
            "Epoch 333/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4284 - accuracy: 0.7865 - val_loss: 0.5003 - val_accuracy: 0.7604\n",
            "Epoch 334/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4284 - accuracy: 0.7865 - val_loss: 0.5003 - val_accuracy: 0.7604\n",
            "Epoch 335/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4283 - accuracy: 0.7882 - val_loss: 0.5005 - val_accuracy: 0.7604\n",
            "Epoch 336/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4283 - accuracy: 0.7865 - val_loss: 0.5005 - val_accuracy: 0.7604\n",
            "Epoch 337/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4282 - accuracy: 0.7865 - val_loss: 0.5006 - val_accuracy: 0.7604\n",
            "Epoch 338/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4281 - accuracy: 0.7847 - val_loss: 0.5006 - val_accuracy: 0.7604\n",
            "Epoch 339/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4281 - accuracy: 0.7865 - val_loss: 0.5007 - val_accuracy: 0.7604\n",
            "Epoch 340/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4280 - accuracy: 0.7865 - val_loss: 0.5008 - val_accuracy: 0.7604\n",
            "Epoch 341/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4280 - accuracy: 0.7882 - val_loss: 0.5009 - val_accuracy: 0.7604\n",
            "Epoch 342/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.7899 - val_loss: 0.5009 - val_accuracy: 0.7604\n",
            "Epoch 343/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.7865 - val_loss: 0.5010 - val_accuracy: 0.7604\n",
            "Epoch 344/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4279 - accuracy: 0.7847 - val_loss: 0.5011 - val_accuracy: 0.7604\n",
            "Epoch 345/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4279 - accuracy: 0.7882 - val_loss: 0.5012 - val_accuracy: 0.7604\n",
            "Epoch 346/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4277 - accuracy: 0.7882 - val_loss: 0.5011 - val_accuracy: 0.7604\n",
            "Epoch 347/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4276 - accuracy: 0.7865 - val_loss: 0.5011 - val_accuracy: 0.7604\n",
            "Epoch 348/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4276 - accuracy: 0.7899 - val_loss: 0.5012 - val_accuracy: 0.7604\n",
            "Epoch 349/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4275 - accuracy: 0.7865 - val_loss: 0.5012 - val_accuracy: 0.7604\n",
            "Epoch 350/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4274 - accuracy: 0.7882 - val_loss: 0.5014 - val_accuracy: 0.7604\n",
            "Epoch 351/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4274 - accuracy: 0.7865 - val_loss: 0.5013 - val_accuracy: 0.7604\n",
            "Epoch 352/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4274 - accuracy: 0.7899 - val_loss: 0.5013 - val_accuracy: 0.7604\n",
            "Epoch 353/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4272 - accuracy: 0.7899 - val_loss: 0.5014 - val_accuracy: 0.7604\n",
            "Epoch 354/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4273 - accuracy: 0.7899 - val_loss: 0.5015 - val_accuracy: 0.7604\n",
            "Epoch 355/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4271 - accuracy: 0.7865 - val_loss: 0.5015 - val_accuracy: 0.7604\n",
            "Epoch 356/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4271 - accuracy: 0.7899 - val_loss: 0.5015 - val_accuracy: 0.7604\n",
            "Epoch 357/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4270 - accuracy: 0.7899 - val_loss: 0.5017 - val_accuracy: 0.7604\n",
            "Epoch 358/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4269 - accuracy: 0.7899 - val_loss: 0.5016 - val_accuracy: 0.7604\n",
            "Epoch 359/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4269 - accuracy: 0.7917 - val_loss: 0.5017 - val_accuracy: 0.7604\n",
            "Epoch 360/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4269 - accuracy: 0.7882 - val_loss: 0.5017 - val_accuracy: 0.7604\n",
            "Epoch 361/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4268 - accuracy: 0.7899 - val_loss: 0.5018 - val_accuracy: 0.7604\n",
            "Epoch 362/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4268 - accuracy: 0.7899 - val_loss: 0.5017 - val_accuracy: 0.7604\n",
            "Epoch 363/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4266 - accuracy: 0.7934 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
            "Epoch 364/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4267 - accuracy: 0.7917 - val_loss: 0.5018 - val_accuracy: 0.7604\n",
            "Epoch 365/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4268 - accuracy: 0.7899 - val_loss: 0.5018 - val_accuracy: 0.7604\n",
            "Epoch 366/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4267 - accuracy: 0.7917 - val_loss: 0.5018 - val_accuracy: 0.7604\n",
            "Epoch 367/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4267 - accuracy: 0.7917 - val_loss: 0.5017 - val_accuracy: 0.7604\n",
            "Epoch 368/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4265 - accuracy: 0.7882 - val_loss: 0.5017 - val_accuracy: 0.7604\n",
            "Epoch 369/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4264 - accuracy: 0.7917 - val_loss: 0.5018 - val_accuracy: 0.7604\n",
            "Epoch 370/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4264 - accuracy: 0.7917 - val_loss: 0.5018 - val_accuracy: 0.7604\n",
            "Epoch 371/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4264 - accuracy: 0.7951 - val_loss: 0.5018 - val_accuracy: 0.7604\n",
            "Epoch 372/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4263 - accuracy: 0.7951 - val_loss: 0.5018 - val_accuracy: 0.7604\n",
            "Epoch 373/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4264 - accuracy: 0.7917 - val_loss: 0.5018 - val_accuracy: 0.7604\n",
            "Epoch 374/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4262 - accuracy: 0.7917 - val_loss: 0.5017 - val_accuracy: 0.7604\n",
            "Epoch 375/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4261 - accuracy: 0.7934 - val_loss: 0.5017 - val_accuracy: 0.7604\n",
            "Epoch 376/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4262 - accuracy: 0.7951 - val_loss: 0.5017 - val_accuracy: 0.7604\n",
            "Epoch 377/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4261 - accuracy: 0.7951 - val_loss: 0.5018 - val_accuracy: 0.7604\n",
            "Epoch 378/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4262 - accuracy: 0.7951 - val_loss: 0.5018 - val_accuracy: 0.7604\n",
            "Epoch 379/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4260 - accuracy: 0.7934 - val_loss: 0.5018 - val_accuracy: 0.7604\n",
            "Epoch 380/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4260 - accuracy: 0.7951 - val_loss: 0.5018 - val_accuracy: 0.7604\n",
            "Epoch 381/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4258 - accuracy: 0.7951 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
            "Epoch 382/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4258 - accuracy: 0.7951 - val_loss: 0.5018 - val_accuracy: 0.7604\n",
            "Epoch 383/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4258 - accuracy: 0.7951 - val_loss: 0.5018 - val_accuracy: 0.7604\n",
            "Epoch 384/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4258 - accuracy: 0.7951 - val_loss: 0.5018 - val_accuracy: 0.7604\n",
            "Epoch 385/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4257 - accuracy: 0.7951 - val_loss: 0.5017 - val_accuracy: 0.7604\n",
            "Epoch 386/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4257 - accuracy: 0.7951 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
            "Epoch 387/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4256 - accuracy: 0.7934 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
            "Epoch 388/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4255 - accuracy: 0.7951 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
            "Epoch 389/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4255 - accuracy: 0.7951 - val_loss: 0.5018 - val_accuracy: 0.7604\n",
            "Epoch 390/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4254 - accuracy: 0.7934 - val_loss: 0.5018 - val_accuracy: 0.7604\n",
            "Epoch 391/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4255 - accuracy: 0.7969 - val_loss: 0.5019 - val_accuracy: 0.7656\n",
            "Epoch 392/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4253 - accuracy: 0.7951 - val_loss: 0.5018 - val_accuracy: 0.7604\n",
            "Epoch 393/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4253 - accuracy: 0.7951 - val_loss: 0.5018 - val_accuracy: 0.7604\n",
            "Epoch 394/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4253 - accuracy: 0.7951 - val_loss: 0.5017 - val_accuracy: 0.7604\n",
            "Epoch 395/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4253 - accuracy: 0.7934 - val_loss: 0.5018 - val_accuracy: 0.7604\n",
            "Epoch 396/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4252 - accuracy: 0.7951 - val_loss: 0.5017 - val_accuracy: 0.7604\n",
            "Epoch 397/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4250 - accuracy: 0.7951 - val_loss: 0.5017 - val_accuracy: 0.7604\n",
            "Epoch 398/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4251 - accuracy: 0.7934 - val_loss: 0.5018 - val_accuracy: 0.7604\n",
            "Epoch 399/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4250 - accuracy: 0.7951 - val_loss: 0.5018 - val_accuracy: 0.7604\n",
            "Epoch 400/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4251 - accuracy: 0.7951 - val_loss: 0.5017 - val_accuracy: 0.7604\n",
            "Epoch 401/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4250 - accuracy: 0.7951 - val_loss: 0.5016 - val_accuracy: 0.7604\n",
            "Epoch 402/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4248 - accuracy: 0.7934 - val_loss: 0.5016 - val_accuracy: 0.7604\n",
            "Epoch 403/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4248 - accuracy: 0.7951 - val_loss: 0.5017 - val_accuracy: 0.7656\n",
            "Epoch 404/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4248 - accuracy: 0.7951 - val_loss: 0.5017 - val_accuracy: 0.7656\n",
            "Epoch 405/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4247 - accuracy: 0.7951 - val_loss: 0.5017 - val_accuracy: 0.7656\n",
            "Epoch 406/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4247 - accuracy: 0.7934 - val_loss: 0.5017 - val_accuracy: 0.7656\n",
            "Epoch 407/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4246 - accuracy: 0.7934 - val_loss: 0.5018 - val_accuracy: 0.7656\n",
            "Epoch 408/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4246 - accuracy: 0.7951 - val_loss: 0.5017 - val_accuracy: 0.7656\n",
            "Epoch 409/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4246 - accuracy: 0.7951 - val_loss: 0.5017 - val_accuracy: 0.7656\n",
            "Epoch 410/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4244 - accuracy: 0.7934 - val_loss: 0.5018 - val_accuracy: 0.7656\n",
            "Epoch 411/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4244 - accuracy: 0.7934 - val_loss: 0.5019 - val_accuracy: 0.7708\n",
            "Epoch 412/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4244 - accuracy: 0.7934 - val_loss: 0.5019 - val_accuracy: 0.7760\n",
            "Epoch 413/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4244 - accuracy: 0.7934 - val_loss: 0.5020 - val_accuracy: 0.7760\n",
            "Epoch 414/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4242 - accuracy: 0.7934 - val_loss: 0.5019 - val_accuracy: 0.7708\n",
            "Epoch 415/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4242 - accuracy: 0.7934 - val_loss: 0.5017 - val_accuracy: 0.7656\n",
            "Epoch 416/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4242 - accuracy: 0.7934 - val_loss: 0.5017 - val_accuracy: 0.7656\n",
            "Epoch 417/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4241 - accuracy: 0.7934 - val_loss: 0.5017 - val_accuracy: 0.7708\n",
            "Epoch 418/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4241 - accuracy: 0.7951 - val_loss: 0.5016 - val_accuracy: 0.7656\n",
            "Epoch 419/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4241 - accuracy: 0.7951 - val_loss: 0.5016 - val_accuracy: 0.7656\n",
            "Epoch 420/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4240 - accuracy: 0.7934 - val_loss: 0.5015 - val_accuracy: 0.7656\n",
            "Epoch 421/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4240 - accuracy: 0.7951 - val_loss: 0.5015 - val_accuracy: 0.7656\n",
            "Epoch 422/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4240 - accuracy: 0.7969 - val_loss: 0.5016 - val_accuracy: 0.7708\n",
            "Epoch 423/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4238 - accuracy: 0.7934 - val_loss: 0.5017 - val_accuracy: 0.7708\n",
            "Epoch 424/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4237 - accuracy: 0.7934 - val_loss: 0.5017 - val_accuracy: 0.7708\n",
            "Epoch 425/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4239 - accuracy: 0.7934 - val_loss: 0.5017 - val_accuracy: 0.7708\n",
            "Epoch 426/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4238 - accuracy: 0.7951 - val_loss: 0.5017 - val_accuracy: 0.7708\n",
            "Epoch 427/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4239 - accuracy: 0.7951 - val_loss: 0.5017 - val_accuracy: 0.7708\n",
            "Epoch 428/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4237 - accuracy: 0.7951 - val_loss: 0.5018 - val_accuracy: 0.7708\n",
            "Epoch 429/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4238 - accuracy: 0.7951 - val_loss: 0.5018 - val_accuracy: 0.7760\n",
            "Epoch 430/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4236 - accuracy: 0.7934 - val_loss: 0.5018 - val_accuracy: 0.7760\n",
            "Epoch 431/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4236 - accuracy: 0.7934 - val_loss: 0.5018 - val_accuracy: 0.7760\n",
            "Epoch 432/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4235 - accuracy: 0.7986 - val_loss: 0.5017 - val_accuracy: 0.7708\n",
            "Epoch 433/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4235 - accuracy: 0.7969 - val_loss: 0.5016 - val_accuracy: 0.7708\n",
            "Epoch 434/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4236 - accuracy: 0.7951 - val_loss: 0.5017 - val_accuracy: 0.7708\n",
            "Epoch 435/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4235 - accuracy: 0.7951 - val_loss: 0.5017 - val_accuracy: 0.7708\n",
            "Epoch 436/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4234 - accuracy: 0.7934 - val_loss: 0.5017 - val_accuracy: 0.7708\n",
            "Epoch 437/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4235 - accuracy: 0.7934 - val_loss: 0.5016 - val_accuracy: 0.7708\n",
            "Epoch 438/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4234 - accuracy: 0.7951 - val_loss: 0.5017 - val_accuracy: 0.7708\n",
            "Epoch 439/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4233 - accuracy: 0.7951 - val_loss: 0.5017 - val_accuracy: 0.7708\n",
            "Epoch 440/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4235 - accuracy: 0.7986 - val_loss: 0.5016 - val_accuracy: 0.7708\n",
            "Epoch 441/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4233 - accuracy: 0.7986 - val_loss: 0.5017 - val_accuracy: 0.7708\n",
            "Epoch 442/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4233 - accuracy: 0.7969 - val_loss: 0.5017 - val_accuracy: 0.7708\n",
            "Epoch 443/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4232 - accuracy: 0.7951 - val_loss: 0.5017 - val_accuracy: 0.7708\n",
            "Epoch 444/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4232 - accuracy: 0.7951 - val_loss: 0.5017 - val_accuracy: 0.7708\n",
            "Epoch 445/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4231 - accuracy: 0.7969 - val_loss: 0.5017 - val_accuracy: 0.7708\n",
            "Epoch 446/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4230 - accuracy: 0.7951 - val_loss: 0.5018 - val_accuracy: 0.7708\n",
            "Epoch 447/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4232 - accuracy: 0.7951 - val_loss: 0.5018 - val_accuracy: 0.7708\n",
            "Epoch 448/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4231 - accuracy: 0.7934 - val_loss: 0.5018 - val_accuracy: 0.7708\n",
            "Epoch 449/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4229 - accuracy: 0.7951 - val_loss: 0.5018 - val_accuracy: 0.7708\n",
            "Epoch 450/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4230 - accuracy: 0.7951 - val_loss: 0.5019 - val_accuracy: 0.7708\n",
            "Epoch 451/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4231 - accuracy: 0.7986 - val_loss: 0.5019 - val_accuracy: 0.7708\n",
            "Epoch 452/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4228 - accuracy: 0.8003 - val_loss: 0.5019 - val_accuracy: 0.7708\n",
            "Epoch 453/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4228 - accuracy: 0.8003 - val_loss: 0.5020 - val_accuracy: 0.7708\n",
            "Epoch 454/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4227 - accuracy: 0.7986 - val_loss: 0.5020 - val_accuracy: 0.7708\n",
            "Epoch 455/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4229 - accuracy: 0.7969 - val_loss: 0.5019 - val_accuracy: 0.7708\n",
            "Epoch 456/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4228 - accuracy: 0.8003 - val_loss: 0.5020 - val_accuracy: 0.7708\n",
            "Epoch 457/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4228 - accuracy: 0.7986 - val_loss: 0.5020 - val_accuracy: 0.7708\n",
            "Epoch 458/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4227 - accuracy: 0.7969 - val_loss: 0.5019 - val_accuracy: 0.7708\n",
            "Epoch 459/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4227 - accuracy: 0.7986 - val_loss: 0.5019 - val_accuracy: 0.7708\n",
            "Epoch 460/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4227 - accuracy: 0.7969 - val_loss: 0.5020 - val_accuracy: 0.7708\n",
            "Epoch 461/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4226 - accuracy: 0.8021 - val_loss: 0.5022 - val_accuracy: 0.7708\n",
            "Epoch 462/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4226 - accuracy: 0.8003 - val_loss: 0.5022 - val_accuracy: 0.7760\n",
            "Epoch 463/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4225 - accuracy: 0.8003 - val_loss: 0.5021 - val_accuracy: 0.7708\n",
            "Epoch 464/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4226 - accuracy: 0.8003 - val_loss: 0.5021 - val_accuracy: 0.7708\n",
            "Epoch 465/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4225 - accuracy: 0.7986 - val_loss: 0.5020 - val_accuracy: 0.7708\n",
            "Epoch 466/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4224 - accuracy: 0.7969 - val_loss: 0.5019 - val_accuracy: 0.7708\n",
            "Epoch 467/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4226 - accuracy: 0.8003 - val_loss: 0.5019 - val_accuracy: 0.7708\n",
            "Epoch 468/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4224 - accuracy: 0.7986 - val_loss: 0.5019 - val_accuracy: 0.7708\n",
            "Epoch 469/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4226 - accuracy: 0.7986 - val_loss: 0.5019 - val_accuracy: 0.7708\n",
            "Epoch 470/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4223 - accuracy: 0.8003 - val_loss: 0.5020 - val_accuracy: 0.7708\n",
            "Epoch 471/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4223 - accuracy: 0.7986 - val_loss: 0.5021 - val_accuracy: 0.7708\n",
            "Epoch 472/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4222 - accuracy: 0.8003 - val_loss: 0.5021 - val_accuracy: 0.7708\n",
            "Epoch 473/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4222 - accuracy: 0.7969 - val_loss: 0.5020 - val_accuracy: 0.7708\n",
            "Epoch 474/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4224 - accuracy: 0.8003 - val_loss: 0.5020 - val_accuracy: 0.7708\n",
            "Epoch 475/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4221 - accuracy: 0.7986 - val_loss: 0.5020 - val_accuracy: 0.7708\n",
            "Epoch 476/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4223 - accuracy: 0.8038 - val_loss: 0.5019 - val_accuracy: 0.7708\n",
            "Epoch 477/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4221 - accuracy: 0.8003 - val_loss: 0.5019 - val_accuracy: 0.7708\n",
            "Epoch 478/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4222 - accuracy: 0.8003 - val_loss: 0.5019 - val_accuracy: 0.7708\n",
            "Epoch 479/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4221 - accuracy: 0.8038 - val_loss: 0.5020 - val_accuracy: 0.7760\n",
            "Epoch 480/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4221 - accuracy: 0.8003 - val_loss: 0.5020 - val_accuracy: 0.7708\n",
            "Epoch 481/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4221 - accuracy: 0.8003 - val_loss: 0.5020 - val_accuracy: 0.7708\n",
            "Epoch 482/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4221 - accuracy: 0.8038 - val_loss: 0.5020 - val_accuracy: 0.7708\n",
            "Epoch 483/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4220 - accuracy: 0.8003 - val_loss: 0.5019 - val_accuracy: 0.7708\n",
            "Epoch 484/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4221 - accuracy: 0.8021 - val_loss: 0.5020 - val_accuracy: 0.7760\n",
            "Epoch 485/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4219 - accuracy: 0.8021 - val_loss: 0.5021 - val_accuracy: 0.7760\n",
            "Epoch 486/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4219 - accuracy: 0.8003 - val_loss: 0.5020 - val_accuracy: 0.7760\n",
            "Epoch 487/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4220 - accuracy: 0.7969 - val_loss: 0.5020 - val_accuracy: 0.7760\n",
            "Epoch 488/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4220 - accuracy: 0.8003 - val_loss: 0.5019 - val_accuracy: 0.7708\n",
            "Epoch 489/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4218 - accuracy: 0.8003 - val_loss: 0.5020 - val_accuracy: 0.7708\n",
            "Epoch 490/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4218 - accuracy: 0.8003 - val_loss: 0.5020 - val_accuracy: 0.7708\n",
            "Epoch 491/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4218 - accuracy: 0.8021 - val_loss: 0.5021 - val_accuracy: 0.7760\n",
            "Epoch 492/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4217 - accuracy: 0.8021 - val_loss: 0.5022 - val_accuracy: 0.7708\n",
            "Epoch 493/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4217 - accuracy: 0.8021 - val_loss: 0.5023 - val_accuracy: 0.7708\n",
            "Epoch 494/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4215 - accuracy: 0.8003 - val_loss: 0.5023 - val_accuracy: 0.7708\n",
            "Epoch 495/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4217 - accuracy: 0.8003 - val_loss: 0.5023 - val_accuracy: 0.7656\n",
            "Epoch 496/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4215 - accuracy: 0.8038 - val_loss: 0.5023 - val_accuracy: 0.7656\n",
            "Epoch 497/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4215 - accuracy: 0.8021 - val_loss: 0.5025 - val_accuracy: 0.7708\n",
            "Epoch 498/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4215 - accuracy: 0.8038 - val_loss: 0.5025 - val_accuracy: 0.7708\n",
            "Epoch 499/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4216 - accuracy: 0.8056 - val_loss: 0.5026 - val_accuracy: 0.7708\n",
            "Epoch 500/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4213 - accuracy: 0.8038 - val_loss: 0.5026 - val_accuracy: 0.7708\n",
            "Epoch 501/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4213 - accuracy: 0.8038 - val_loss: 0.5028 - val_accuracy: 0.7708\n",
            "Epoch 502/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4213 - accuracy: 0.8038 - val_loss: 0.5027 - val_accuracy: 0.7708\n",
            "Epoch 503/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4211 - accuracy: 0.8021 - val_loss: 0.5027 - val_accuracy: 0.7708\n",
            "Epoch 504/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4212 - accuracy: 0.8021 - val_loss: 0.5028 - val_accuracy: 0.7708\n",
            "Epoch 505/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4212 - accuracy: 0.8038 - val_loss: 0.5027 - val_accuracy: 0.7656\n",
            "Epoch 506/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4210 - accuracy: 0.8056 - val_loss: 0.5028 - val_accuracy: 0.7656\n",
            "Epoch 507/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4212 - accuracy: 0.8038 - val_loss: 0.5028 - val_accuracy: 0.7656\n",
            "Epoch 508/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4210 - accuracy: 0.8038 - val_loss: 0.5029 - val_accuracy: 0.7656\n",
            "Epoch 509/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4210 - accuracy: 0.8038 - val_loss: 0.5029 - val_accuracy: 0.7656\n",
            "Epoch 510/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4209 - accuracy: 0.8021 - val_loss: 0.5027 - val_accuracy: 0.7656\n",
            "Epoch 511/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4209 - accuracy: 0.8038 - val_loss: 0.5027 - val_accuracy: 0.7656\n",
            "Epoch 512/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4210 - accuracy: 0.8038 - val_loss: 0.5027 - val_accuracy: 0.7656\n",
            "Epoch 513/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4209 - accuracy: 0.8021 - val_loss: 0.5027 - val_accuracy: 0.7656\n",
            "Epoch 514/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4209 - accuracy: 0.8038 - val_loss: 0.5028 - val_accuracy: 0.7656\n",
            "Epoch 515/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4206 - accuracy: 0.8056 - val_loss: 0.5028 - val_accuracy: 0.7656\n",
            "Epoch 516/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4208 - accuracy: 0.8021 - val_loss: 0.5028 - val_accuracy: 0.7656\n",
            "Epoch 517/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4206 - accuracy: 0.8038 - val_loss: 0.5028 - val_accuracy: 0.7656\n",
            "Epoch 518/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4205 - accuracy: 0.8038 - val_loss: 0.5029 - val_accuracy: 0.7656\n",
            "Epoch 519/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4205 - accuracy: 0.8038 - val_loss: 0.5028 - val_accuracy: 0.7656\n",
            "Epoch 520/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4207 - accuracy: 0.8038 - val_loss: 0.5028 - val_accuracy: 0.7656\n",
            "Epoch 521/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4205 - accuracy: 0.8021 - val_loss: 0.5028 - val_accuracy: 0.7656\n",
            "Epoch 522/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4204 - accuracy: 0.8038 - val_loss: 0.5028 - val_accuracy: 0.7656\n",
            "Epoch 523/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4205 - accuracy: 0.8038 - val_loss: 0.5029 - val_accuracy: 0.7656\n",
            "Epoch 524/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4203 - accuracy: 0.8038 - val_loss: 0.5028 - val_accuracy: 0.7656\n",
            "Epoch 525/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4205 - accuracy: 0.8038 - val_loss: 0.5029 - val_accuracy: 0.7656\n",
            "Epoch 526/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4203 - accuracy: 0.8038 - val_loss: 0.5029 - val_accuracy: 0.7656\n",
            "Epoch 527/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4202 - accuracy: 0.8038 - val_loss: 0.5030 - val_accuracy: 0.7656\n",
            "Epoch 528/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4203 - accuracy: 0.8038 - val_loss: 0.5029 - val_accuracy: 0.7656\n",
            "Epoch 529/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4202 - accuracy: 0.8021 - val_loss: 0.5028 - val_accuracy: 0.7656\n",
            "Epoch 530/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4201 - accuracy: 0.8038 - val_loss: 0.5029 - val_accuracy: 0.7656\n",
            "Epoch 531/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4202 - accuracy: 0.8038 - val_loss: 0.5027 - val_accuracy: 0.7656\n",
            "Epoch 532/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4201 - accuracy: 0.8038 - val_loss: 0.5026 - val_accuracy: 0.7656\n",
            "Epoch 533/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4201 - accuracy: 0.8038 - val_loss: 0.5026 - val_accuracy: 0.7656\n",
            "Epoch 534/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4201 - accuracy: 0.8038 - val_loss: 0.5027 - val_accuracy: 0.7656\n",
            "Epoch 535/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4200 - accuracy: 0.8056 - val_loss: 0.5027 - val_accuracy: 0.7656\n",
            "Epoch 536/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4199 - accuracy: 0.8038 - val_loss: 0.5028 - val_accuracy: 0.7656\n",
            "Epoch 537/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4200 - accuracy: 0.8038 - val_loss: 0.5028 - val_accuracy: 0.7656\n",
            "Epoch 538/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4200 - accuracy: 0.8038 - val_loss: 0.5028 - val_accuracy: 0.7656\n",
            "Epoch 539/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4198 - accuracy: 0.8038 - val_loss: 0.5027 - val_accuracy: 0.7656\n",
            "Epoch 540/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4198 - accuracy: 0.8056 - val_loss: 0.5028 - val_accuracy: 0.7656\n",
            "Epoch 541/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4198 - accuracy: 0.8056 - val_loss: 0.5027 - val_accuracy: 0.7656\n",
            "Epoch 542/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4197 - accuracy: 0.8056 - val_loss: 0.5027 - val_accuracy: 0.7656\n",
            "Epoch 543/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4197 - accuracy: 0.8056 - val_loss: 0.5027 - val_accuracy: 0.7656\n",
            "Epoch 544/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4200 - accuracy: 0.8056 - val_loss: 0.5028 - val_accuracy: 0.7656\n",
            "Epoch 545/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4197 - accuracy: 0.8056 - val_loss: 0.5026 - val_accuracy: 0.7656\n",
            "Epoch 546/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4197 - accuracy: 0.8038 - val_loss: 0.5026 - val_accuracy: 0.7656\n",
            "Epoch 547/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4195 - accuracy: 0.8056 - val_loss: 0.5026 - val_accuracy: 0.7656\n",
            "Epoch 548/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4197 - accuracy: 0.8038 - val_loss: 0.5027 - val_accuracy: 0.7656\n",
            "Epoch 549/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4196 - accuracy: 0.8038 - val_loss: 0.5027 - val_accuracy: 0.7656\n",
            "Epoch 550/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4194 - accuracy: 0.8056 - val_loss: 0.5028 - val_accuracy: 0.7656\n",
            "Epoch 551/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4196 - accuracy: 0.8056 - val_loss: 0.5027 - val_accuracy: 0.7656\n",
            "Epoch 552/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4195 - accuracy: 0.8056 - val_loss: 0.5027 - val_accuracy: 0.7656\n",
            "Epoch 553/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4194 - accuracy: 0.8056 - val_loss: 0.5027 - val_accuracy: 0.7656\n",
            "Epoch 554/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4194 - accuracy: 0.8056 - val_loss: 0.5026 - val_accuracy: 0.7656\n",
            "Epoch 555/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4194 - accuracy: 0.8056 - val_loss: 0.5027 - val_accuracy: 0.7656\n",
            "Epoch 556/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4193 - accuracy: 0.8056 - val_loss: 0.5026 - val_accuracy: 0.7656\n",
            "Epoch 557/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4193 - accuracy: 0.8038 - val_loss: 0.5025 - val_accuracy: 0.7656\n",
            "Epoch 558/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4193 - accuracy: 0.8056 - val_loss: 0.5025 - val_accuracy: 0.7656\n",
            "Epoch 559/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4192 - accuracy: 0.8056 - val_loss: 0.5027 - val_accuracy: 0.7656\n",
            "Epoch 560/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4193 - accuracy: 0.8056 - val_loss: 0.5027 - val_accuracy: 0.7656\n",
            "Epoch 561/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4191 - accuracy: 0.8056 - val_loss: 0.5028 - val_accuracy: 0.7656\n",
            "Epoch 562/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4192 - accuracy: 0.8038 - val_loss: 0.5027 - val_accuracy: 0.7656\n",
            "Epoch 563/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4193 - accuracy: 0.8038 - val_loss: 0.5026 - val_accuracy: 0.7656\n",
            "Epoch 564/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4190 - accuracy: 0.8038 - val_loss: 0.5026 - val_accuracy: 0.7656\n",
            "Epoch 565/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4190 - accuracy: 0.8056 - val_loss: 0.5025 - val_accuracy: 0.7656\n",
            "Epoch 566/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4190 - accuracy: 0.8056 - val_loss: 0.5026 - val_accuracy: 0.7708\n",
            "Epoch 567/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4190 - accuracy: 0.8038 - val_loss: 0.5026 - val_accuracy: 0.7708\n",
            "Epoch 568/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4189 - accuracy: 0.8021 - val_loss: 0.5027 - val_accuracy: 0.7708\n",
            "Epoch 569/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4189 - accuracy: 0.8056 - val_loss: 0.5027 - val_accuracy: 0.7708\n",
            "Epoch 570/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4189 - accuracy: 0.8038 - val_loss: 0.5026 - val_accuracy: 0.7708\n",
            "Epoch 571/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4187 - accuracy: 0.8056 - val_loss: 0.5027 - val_accuracy: 0.7708\n",
            "Epoch 572/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4187 - accuracy: 0.8038 - val_loss: 0.5027 - val_accuracy: 0.7708\n",
            "Epoch 573/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4188 - accuracy: 0.8056 - val_loss: 0.5028 - val_accuracy: 0.7708\n",
            "Epoch 574/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4187 - accuracy: 0.8038 - val_loss: 0.5029 - val_accuracy: 0.7708\n",
            "Epoch 575/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4187 - accuracy: 0.8038 - val_loss: 0.5027 - val_accuracy: 0.7708\n",
            "Epoch 576/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4187 - accuracy: 0.8038 - val_loss: 0.5027 - val_accuracy: 0.7708\n",
            "Epoch 577/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4187 - accuracy: 0.8038 - val_loss: 0.5028 - val_accuracy: 0.7760\n",
            "Epoch 578/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4187 - accuracy: 0.8038 - val_loss: 0.5028 - val_accuracy: 0.7760\n",
            "Epoch 579/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4186 - accuracy: 0.8038 - val_loss: 0.5027 - val_accuracy: 0.7708\n",
            "Epoch 580/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4186 - accuracy: 0.8038 - val_loss: 0.5027 - val_accuracy: 0.7708\n",
            "Epoch 581/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4185 - accuracy: 0.8038 - val_loss: 0.5027 - val_accuracy: 0.7760\n",
            "Epoch 582/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4185 - accuracy: 0.8038 - val_loss: 0.5027 - val_accuracy: 0.7708\n",
            "Epoch 583/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4185 - accuracy: 0.8038 - val_loss: 0.5026 - val_accuracy: 0.7760\n",
            "Epoch 584/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4183 - accuracy: 0.8021 - val_loss: 0.5025 - val_accuracy: 0.7760\n",
            "Epoch 585/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4184 - accuracy: 0.8038 - val_loss: 0.5026 - val_accuracy: 0.7708\n",
            "Epoch 586/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4183 - accuracy: 0.8038 - val_loss: 0.5027 - val_accuracy: 0.7812\n",
            "Epoch 587/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4183 - accuracy: 0.8038 - val_loss: 0.5026 - val_accuracy: 0.7812\n",
            "Epoch 588/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4181 - accuracy: 0.8038 - val_loss: 0.5027 - val_accuracy: 0.7812\n",
            "Epoch 589/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4183 - accuracy: 0.8021 - val_loss: 0.5026 - val_accuracy: 0.7812\n",
            "Epoch 590/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4181 - accuracy: 0.8038 - val_loss: 0.5026 - val_accuracy: 0.7812\n",
            "Epoch 591/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4179 - accuracy: 0.8038 - val_loss: 0.5025 - val_accuracy: 0.7812\n",
            "Epoch 592/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4181 - accuracy: 0.8038 - val_loss: 0.5025 - val_accuracy: 0.7760\n",
            "Epoch 593/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4179 - accuracy: 0.8021 - val_loss: 0.5025 - val_accuracy: 0.7760\n",
            "Epoch 594/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4181 - accuracy: 0.8038 - val_loss: 0.5025 - val_accuracy: 0.7812\n",
            "Epoch 595/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4180 - accuracy: 0.8038 - val_loss: 0.5025 - val_accuracy: 0.7812\n",
            "Epoch 596/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4179 - accuracy: 0.8021 - val_loss: 0.5023 - val_accuracy: 0.7812\n",
            "Epoch 597/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4179 - accuracy: 0.8021 - val_loss: 0.5022 - val_accuracy: 0.7812\n",
            "Epoch 598/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4179 - accuracy: 0.8038 - val_loss: 0.5023 - val_accuracy: 0.7812\n",
            "Epoch 599/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4178 - accuracy: 0.8021 - val_loss: 0.5023 - val_accuracy: 0.7812\n",
            "Epoch 600/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4178 - accuracy: 0.8038 - val_loss: 0.5024 - val_accuracy: 0.7760\n",
            "Epoch 601/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4178 - accuracy: 0.8021 - val_loss: 0.5025 - val_accuracy: 0.7760\n",
            "Epoch 602/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4179 - accuracy: 0.8038 - val_loss: 0.5026 - val_accuracy: 0.7760\n",
            "Epoch 603/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4177 - accuracy: 0.8021 - val_loss: 0.5026 - val_accuracy: 0.7760\n",
            "Epoch 604/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4178 - accuracy: 0.8021 - val_loss: 0.5025 - val_accuracy: 0.7812\n",
            "Epoch 605/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4177 - accuracy: 0.8038 - val_loss: 0.5024 - val_accuracy: 0.7812\n",
            "Epoch 606/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4177 - accuracy: 0.8038 - val_loss: 0.5024 - val_accuracy: 0.7812\n",
            "Epoch 607/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4177 - accuracy: 0.8021 - val_loss: 0.5024 - val_accuracy: 0.7812\n",
            "Epoch 608/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4175 - accuracy: 0.8038 - val_loss: 0.5024 - val_accuracy: 0.7812\n",
            "Epoch 609/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4174 - accuracy: 0.8038 - val_loss: 0.5023 - val_accuracy: 0.7760\n",
            "Epoch 610/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4174 - accuracy: 0.8038 - val_loss: 0.5024 - val_accuracy: 0.7812\n",
            "Epoch 611/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4177 - accuracy: 0.8021 - val_loss: 0.5023 - val_accuracy: 0.7812\n",
            "Epoch 612/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4175 - accuracy: 0.8021 - val_loss: 0.5023 - val_accuracy: 0.7812\n",
            "Epoch 613/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4175 - accuracy: 0.8038 - val_loss: 0.5024 - val_accuracy: 0.7812\n",
            "Epoch 614/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4174 - accuracy: 0.8038 - val_loss: 0.5024 - val_accuracy: 0.7812\n",
            "Epoch 615/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4173 - accuracy: 0.8038 - val_loss: 0.5023 - val_accuracy: 0.7812\n",
            "Epoch 616/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4175 - accuracy: 0.8038 - val_loss: 0.5021 - val_accuracy: 0.7812\n",
            "Epoch 617/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4173 - accuracy: 0.8038 - val_loss: 0.5020 - val_accuracy: 0.7812\n",
            "Epoch 618/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4172 - accuracy: 0.8021 - val_loss: 0.5020 - val_accuracy: 0.7812\n",
            "Epoch 619/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4172 - accuracy: 0.8038 - val_loss: 0.5021 - val_accuracy: 0.7812\n",
            "Epoch 620/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4172 - accuracy: 0.8038 - val_loss: 0.5022 - val_accuracy: 0.7812\n",
            "Epoch 621/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4172 - accuracy: 0.8038 - val_loss: 0.5022 - val_accuracy: 0.7812\n",
            "Epoch 622/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4170 - accuracy: 0.8038 - val_loss: 0.5022 - val_accuracy: 0.7812\n",
            "Epoch 623/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4170 - accuracy: 0.8021 - val_loss: 0.5021 - val_accuracy: 0.7812\n",
            "Epoch 624/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4171 - accuracy: 0.8038 - val_loss: 0.5023 - val_accuracy: 0.7812\n",
            "Epoch 625/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4169 - accuracy: 0.8038 - val_loss: 0.5023 - val_accuracy: 0.7812\n",
            "Epoch 626/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4169 - accuracy: 0.8038 - val_loss: 0.5022 - val_accuracy: 0.7812\n",
            "Epoch 627/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4169 - accuracy: 0.8038 - val_loss: 0.5022 - val_accuracy: 0.7812\n",
            "Epoch 628/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4170 - accuracy: 0.8038 - val_loss: 0.5023 - val_accuracy: 0.7812\n",
            "Epoch 629/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4170 - accuracy: 0.8038 - val_loss: 0.5022 - val_accuracy: 0.7812\n",
            "Epoch 630/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4167 - accuracy: 0.8038 - val_loss: 0.5021 - val_accuracy: 0.7812\n",
            "Epoch 631/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4167 - accuracy: 0.8038 - val_loss: 0.5021 - val_accuracy: 0.7812\n",
            "Epoch 632/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4168 - accuracy: 0.8038 - val_loss: 0.5020 - val_accuracy: 0.7812\n",
            "Epoch 633/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4167 - accuracy: 0.8038 - val_loss: 0.5021 - val_accuracy: 0.7865\n",
            "Epoch 634/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4166 - accuracy: 0.8038 - val_loss: 0.5020 - val_accuracy: 0.7865\n",
            "Epoch 635/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4165 - accuracy: 0.8038 - val_loss: 0.5020 - val_accuracy: 0.7865\n",
            "Epoch 636/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4165 - accuracy: 0.8038 - val_loss: 0.5019 - val_accuracy: 0.7865\n",
            "Epoch 637/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4165 - accuracy: 0.8038 - val_loss: 0.5019 - val_accuracy: 0.7865\n",
            "Epoch 638/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4166 - accuracy: 0.8038 - val_loss: 0.5021 - val_accuracy: 0.7865\n",
            "Epoch 639/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4165 - accuracy: 0.8038 - val_loss: 0.5021 - val_accuracy: 0.7865\n",
            "Epoch 640/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4164 - accuracy: 0.8021 - val_loss: 0.5020 - val_accuracy: 0.7865\n",
            "Epoch 641/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4167 - accuracy: 0.8038 - val_loss: 0.5020 - val_accuracy: 0.7865\n",
            "Epoch 642/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4165 - accuracy: 0.8038 - val_loss: 0.5021 - val_accuracy: 0.7865\n",
            "Epoch 643/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4163 - accuracy: 0.8021 - val_loss: 0.5019 - val_accuracy: 0.7865\n",
            "Epoch 644/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4161 - accuracy: 0.8038 - val_loss: 0.5019 - val_accuracy: 0.7865\n",
            "Epoch 645/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4163 - accuracy: 0.8021 - val_loss: 0.5019 - val_accuracy: 0.7865\n",
            "Epoch 646/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4162 - accuracy: 0.8038 - val_loss: 0.5020 - val_accuracy: 0.7865\n",
            "Epoch 647/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4161 - accuracy: 0.8038 - val_loss: 0.5019 - val_accuracy: 0.7865\n",
            "Epoch 648/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4160 - accuracy: 0.8038 - val_loss: 0.5018 - val_accuracy: 0.7865\n",
            "Epoch 649/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4161 - accuracy: 0.8038 - val_loss: 0.5017 - val_accuracy: 0.7865\n",
            "Epoch 650/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4159 - accuracy: 0.8021 - val_loss: 0.5017 - val_accuracy: 0.7865\n",
            "Epoch 651/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4159 - accuracy: 0.8021 - val_loss: 0.5017 - val_accuracy: 0.7865\n",
            "Epoch 652/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4159 - accuracy: 0.8021 - val_loss: 0.5015 - val_accuracy: 0.7865\n",
            "Epoch 653/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4160 - accuracy: 0.8038 - val_loss: 0.5017 - val_accuracy: 0.7865\n",
            "Epoch 654/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4160 - accuracy: 0.8038 - val_loss: 0.5016 - val_accuracy: 0.7865\n",
            "Epoch 655/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4159 - accuracy: 0.8038 - val_loss: 0.5018 - val_accuracy: 0.7865\n",
            "Epoch 656/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4157 - accuracy: 0.8021 - val_loss: 0.5019 - val_accuracy: 0.7865\n",
            "Epoch 657/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4158 - accuracy: 0.8021 - val_loss: 0.5017 - val_accuracy: 0.7865\n",
            "Epoch 658/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4158 - accuracy: 0.8038 - val_loss: 0.5018 - val_accuracy: 0.7865\n",
            "Epoch 659/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4156 - accuracy: 0.8056 - val_loss: 0.5017 - val_accuracy: 0.7865\n",
            "Epoch 660/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4158 - accuracy: 0.8021 - val_loss: 0.5016 - val_accuracy: 0.7865\n",
            "Epoch 661/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4157 - accuracy: 0.8038 - val_loss: 0.5017 - val_accuracy: 0.7865\n",
            "Epoch 662/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4157 - accuracy: 0.8038 - val_loss: 0.5015 - val_accuracy: 0.7865\n",
            "Epoch 663/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4156 - accuracy: 0.8056 - val_loss: 0.5014 - val_accuracy: 0.7865\n",
            "Epoch 664/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4155 - accuracy: 0.8038 - val_loss: 0.5013 - val_accuracy: 0.7865\n",
            "Epoch 665/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4155 - accuracy: 0.8038 - val_loss: 0.5012 - val_accuracy: 0.7917\n",
            "Epoch 666/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4155 - accuracy: 0.8056 - val_loss: 0.5014 - val_accuracy: 0.7865\n",
            "Epoch 667/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4156 - accuracy: 0.8021 - val_loss: 0.5013 - val_accuracy: 0.7865\n",
            "Epoch 668/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4155 - accuracy: 0.8038 - val_loss: 0.5014 - val_accuracy: 0.7865\n",
            "Epoch 669/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4154 - accuracy: 0.8056 - val_loss: 0.5013 - val_accuracy: 0.7917\n",
            "Epoch 670/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4156 - accuracy: 0.8038 - val_loss: 0.5012 - val_accuracy: 0.7865\n",
            "Epoch 671/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4152 - accuracy: 0.8073 - val_loss: 0.5012 - val_accuracy: 0.7917\n",
            "Epoch 672/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4153 - accuracy: 0.8038 - val_loss: 0.5011 - val_accuracy: 0.7917\n",
            "Epoch 673/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4152 - accuracy: 0.8073 - val_loss: 0.5012 - val_accuracy: 0.7917\n",
            "Epoch 674/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4152 - accuracy: 0.8073 - val_loss: 0.5012 - val_accuracy: 0.7917\n",
            "Epoch 675/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4151 - accuracy: 0.8021 - val_loss: 0.5011 - val_accuracy: 0.7917\n",
            "Epoch 676/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4152 - accuracy: 0.8056 - val_loss: 0.5011 - val_accuracy: 0.7917\n",
            "Epoch 677/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4151 - accuracy: 0.8056 - val_loss: 0.5012 - val_accuracy: 0.7917\n",
            "Epoch 678/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4150 - accuracy: 0.8056 - val_loss: 0.5011 - val_accuracy: 0.7917\n",
            "Epoch 679/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4150 - accuracy: 0.8073 - val_loss: 0.5012 - val_accuracy: 0.7917\n",
            "Epoch 680/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4150 - accuracy: 0.8073 - val_loss: 0.5011 - val_accuracy: 0.7917\n",
            "Epoch 681/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4150 - accuracy: 0.8073 - val_loss: 0.5014 - val_accuracy: 0.7865\n",
            "Epoch 682/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4150 - accuracy: 0.8073 - val_loss: 0.5013 - val_accuracy: 0.7917\n",
            "Epoch 683/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4149 - accuracy: 0.8056 - val_loss: 0.5013 - val_accuracy: 0.7917\n",
            "Epoch 684/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4148 - accuracy: 0.8056 - val_loss: 0.5010 - val_accuracy: 0.7917\n",
            "Epoch 685/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4147 - accuracy: 0.8038 - val_loss: 0.5009 - val_accuracy: 0.7917\n",
            "Epoch 686/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4148 - accuracy: 0.8056 - val_loss: 0.5008 - val_accuracy: 0.7917\n",
            "Epoch 687/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4148 - accuracy: 0.8073 - val_loss: 0.5009 - val_accuracy: 0.7917\n",
            "Epoch 688/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4149 - accuracy: 0.8073 - val_loss: 0.5008 - val_accuracy: 0.7865\n",
            "Epoch 689/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4146 - accuracy: 0.8073 - val_loss: 0.5009 - val_accuracy: 0.7917\n",
            "Epoch 690/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4147 - accuracy: 0.8073 - val_loss: 0.5009 - val_accuracy: 0.7917\n",
            "Epoch 691/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4147 - accuracy: 0.8038 - val_loss: 0.5008 - val_accuracy: 0.7917\n",
            "Epoch 692/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4146 - accuracy: 0.8038 - val_loss: 0.5007 - val_accuracy: 0.7865\n",
            "Epoch 693/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4145 - accuracy: 0.8073 - val_loss: 0.5009 - val_accuracy: 0.7865\n",
            "Epoch 694/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4144 - accuracy: 0.8056 - val_loss: 0.5007 - val_accuracy: 0.7865\n",
            "Epoch 695/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4144 - accuracy: 0.8056 - val_loss: 0.5006 - val_accuracy: 0.7865\n",
            "Epoch 696/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4144 - accuracy: 0.8056 - val_loss: 0.5006 - val_accuracy: 0.7865\n",
            "Epoch 697/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4145 - accuracy: 0.8073 - val_loss: 0.5007 - val_accuracy: 0.7865\n",
            "Epoch 698/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4143 - accuracy: 0.8073 - val_loss: 0.5008 - val_accuracy: 0.7865\n",
            "Epoch 699/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4142 - accuracy: 0.8073 - val_loss: 0.5009 - val_accuracy: 0.7865\n",
            "Epoch 700/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4142 - accuracy: 0.8056 - val_loss: 0.5007 - val_accuracy: 0.7865\n",
            "Epoch 701/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4142 - accuracy: 0.8073 - val_loss: 0.5008 - val_accuracy: 0.7865\n",
            "Epoch 702/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4141 - accuracy: 0.8073 - val_loss: 0.5009 - val_accuracy: 0.7865\n",
            "Epoch 703/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4140 - accuracy: 0.8073 - val_loss: 0.5009 - val_accuracy: 0.7865\n",
            "Epoch 704/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4141 - accuracy: 0.8056 - val_loss: 0.5008 - val_accuracy: 0.7865\n",
            "Epoch 705/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4140 - accuracy: 0.8090 - val_loss: 0.5010 - val_accuracy: 0.7865\n",
            "Epoch 706/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4138 - accuracy: 0.8056 - val_loss: 0.5009 - val_accuracy: 0.7865\n",
            "Epoch 707/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4139 - accuracy: 0.8073 - val_loss: 0.5009 - val_accuracy: 0.7865\n",
            "Epoch 708/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4140 - accuracy: 0.8073 - val_loss: 0.5009 - val_accuracy: 0.7865\n",
            "Epoch 709/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4139 - accuracy: 0.8073 - val_loss: 0.5009 - val_accuracy: 0.7865\n",
            "Epoch 710/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4140 - accuracy: 0.8056 - val_loss: 0.5010 - val_accuracy: 0.7865\n",
            "Epoch 711/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4139 - accuracy: 0.8073 - val_loss: 0.5012 - val_accuracy: 0.7865\n",
            "Epoch 712/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4140 - accuracy: 0.8073 - val_loss: 0.5010 - val_accuracy: 0.7865\n",
            "Epoch 713/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4137 - accuracy: 0.8073 - val_loss: 0.5010 - val_accuracy: 0.7865\n",
            "Epoch 714/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4136 - accuracy: 0.8073 - val_loss: 0.5011 - val_accuracy: 0.7865\n",
            "Epoch 715/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4136 - accuracy: 0.8038 - val_loss: 0.5011 - val_accuracy: 0.7865\n",
            "Epoch 716/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4136 - accuracy: 0.8073 - val_loss: 0.5014 - val_accuracy: 0.7865\n",
            "Epoch 717/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4136 - accuracy: 0.8073 - val_loss: 0.5015 - val_accuracy: 0.7865\n",
            "Epoch 718/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4136 - accuracy: 0.8073 - val_loss: 0.5016 - val_accuracy: 0.7812\n",
            "Epoch 719/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4136 - accuracy: 0.8073 - val_loss: 0.5017 - val_accuracy: 0.7865\n",
            "Epoch 720/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4136 - accuracy: 0.8056 - val_loss: 0.5014 - val_accuracy: 0.7865\n",
            "Epoch 721/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4133 - accuracy: 0.8073 - val_loss: 0.5017 - val_accuracy: 0.7865\n",
            "Epoch 722/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4136 - accuracy: 0.8073 - val_loss: 0.5014 - val_accuracy: 0.7865\n",
            "Epoch 723/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4135 - accuracy: 0.8073 - val_loss: 0.5014 - val_accuracy: 0.7865\n",
            "Epoch 724/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4135 - accuracy: 0.8038 - val_loss: 0.5013 - val_accuracy: 0.7865\n",
            "Epoch 725/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4135 - accuracy: 0.8073 - val_loss: 0.5014 - val_accuracy: 0.7865\n",
            "Epoch 726/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4133 - accuracy: 0.8073 - val_loss: 0.5017 - val_accuracy: 0.7812\n",
            "Epoch 727/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4132 - accuracy: 0.8073 - val_loss: 0.5018 - val_accuracy: 0.7865\n",
            "Epoch 728/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4133 - accuracy: 0.8056 - val_loss: 0.5016 - val_accuracy: 0.7865\n",
            "Epoch 729/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4133 - accuracy: 0.8056 - val_loss: 0.5017 - val_accuracy: 0.7865\n",
            "Epoch 730/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4134 - accuracy: 0.8073 - val_loss: 0.5019 - val_accuracy: 0.7865\n",
            "Epoch 731/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4131 - accuracy: 0.8056 - val_loss: 0.5020 - val_accuracy: 0.7812\n",
            "Epoch 732/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4131 - accuracy: 0.8073 - val_loss: 0.5020 - val_accuracy: 0.7865\n",
            "Epoch 733/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4132 - accuracy: 0.8038 - val_loss: 0.5018 - val_accuracy: 0.7865\n",
            "Epoch 734/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4130 - accuracy: 0.8056 - val_loss: 0.5018 - val_accuracy: 0.7865\n",
            "Epoch 735/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4132 - accuracy: 0.8073 - val_loss: 0.5020 - val_accuracy: 0.7812\n",
            "Epoch 736/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4133 - accuracy: 0.8056 - val_loss: 0.5021 - val_accuracy: 0.7812\n",
            "Epoch 737/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4130 - accuracy: 0.8073 - val_loss: 0.5023 - val_accuracy: 0.7812\n",
            "Epoch 738/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4130 - accuracy: 0.8073 - val_loss: 0.5021 - val_accuracy: 0.7865\n",
            "Epoch 739/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4129 - accuracy: 0.8056 - val_loss: 0.5020 - val_accuracy: 0.7865\n",
            "Epoch 740/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4130 - accuracy: 0.8073 - val_loss: 0.5020 - val_accuracy: 0.7865\n",
            "Epoch 741/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4128 - accuracy: 0.8073 - val_loss: 0.5021 - val_accuracy: 0.7865\n",
            "Epoch 742/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4129 - accuracy: 0.8073 - val_loss: 0.5022 - val_accuracy: 0.7865\n",
            "Epoch 743/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4129 - accuracy: 0.8073 - val_loss: 0.5023 - val_accuracy: 0.7865\n",
            "Epoch 744/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4128 - accuracy: 0.8056 - val_loss: 0.5022 - val_accuracy: 0.7865\n",
            "Epoch 745/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4130 - accuracy: 0.8056 - val_loss: 0.5022 - val_accuracy: 0.7865\n",
            "Epoch 746/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4128 - accuracy: 0.8056 - val_loss: 0.5023 - val_accuracy: 0.7812\n",
            "Epoch 747/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4127 - accuracy: 0.8073 - val_loss: 0.5023 - val_accuracy: 0.7812\n",
            "Epoch 748/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4127 - accuracy: 0.8073 - val_loss: 0.5024 - val_accuracy: 0.7812\n",
            "Epoch 749/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4127 - accuracy: 0.8056 - val_loss: 0.5024 - val_accuracy: 0.7812\n",
            "Epoch 750/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4128 - accuracy: 0.8073 - val_loss: 0.5024 - val_accuracy: 0.7812\n",
            "Epoch 751/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4126 - accuracy: 0.8073 - val_loss: 0.5024 - val_accuracy: 0.7865\n",
            "Epoch 752/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4128 - accuracy: 0.8090 - val_loss: 0.5024 - val_accuracy: 0.7865\n",
            "Epoch 753/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4127 - accuracy: 0.8073 - val_loss: 0.5026 - val_accuracy: 0.7812\n",
            "Epoch 754/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4127 - accuracy: 0.8073 - val_loss: 0.5025 - val_accuracy: 0.7812\n",
            "Epoch 755/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4126 - accuracy: 0.8056 - val_loss: 0.5026 - val_accuracy: 0.7812\n",
            "Epoch 756/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4125 - accuracy: 0.8073 - val_loss: 0.5026 - val_accuracy: 0.7812\n",
            "Epoch 757/1500\n",
            "18/18 [==============================] - 0s 21ms/step - loss: 0.4126 - accuracy: 0.8073 - val_loss: 0.5024 - val_accuracy: 0.7865\n",
            "Epoch 758/1500\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.4125 - accuracy: 0.8056 - val_loss: 0.5024 - val_accuracy: 0.7865\n",
            "Epoch 759/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4126 - accuracy: 0.8090 - val_loss: 0.5025 - val_accuracy: 0.7812\n",
            "Epoch 760/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4124 - accuracy: 0.8073 - val_loss: 0.5027 - val_accuracy: 0.7812\n",
            "Epoch 761/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4124 - accuracy: 0.8090 - val_loss: 0.5027 - val_accuracy: 0.7812\n",
            "Epoch 762/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4125 - accuracy: 0.8073 - val_loss: 0.5026 - val_accuracy: 0.7812\n",
            "Epoch 763/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4124 - accuracy: 0.8056 - val_loss: 0.5028 - val_accuracy: 0.7812\n",
            "Epoch 764/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4123 - accuracy: 0.8073 - val_loss: 0.5028 - val_accuracy: 0.7812\n",
            "Epoch 765/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4123 - accuracy: 0.8073 - val_loss: 0.5026 - val_accuracy: 0.7865\n",
            "Epoch 766/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4122 - accuracy: 0.8073 - val_loss: 0.5028 - val_accuracy: 0.7812\n",
            "Epoch 767/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4121 - accuracy: 0.8073 - val_loss: 0.5028 - val_accuracy: 0.7812\n",
            "Epoch 768/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4122 - accuracy: 0.8073 - val_loss: 0.5028 - val_accuracy: 0.7812\n",
            "Epoch 769/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4121 - accuracy: 0.8056 - val_loss: 0.5027 - val_accuracy: 0.7865\n",
            "Epoch 770/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4121 - accuracy: 0.8090 - val_loss: 0.5030 - val_accuracy: 0.7812\n",
            "Epoch 771/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4122 - accuracy: 0.8108 - val_loss: 0.5030 - val_accuracy: 0.7812\n",
            "Epoch 772/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4121 - accuracy: 0.8073 - val_loss: 0.5030 - val_accuracy: 0.7812\n",
            "Epoch 773/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4121 - accuracy: 0.8108 - val_loss: 0.5030 - val_accuracy: 0.7812\n",
            "Epoch 774/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4121 - accuracy: 0.8090 - val_loss: 0.5031 - val_accuracy: 0.7812\n",
            "Epoch 775/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4122 - accuracy: 0.8073 - val_loss: 0.5030 - val_accuracy: 0.7812\n",
            "Epoch 776/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4121 - accuracy: 0.8090 - val_loss: 0.5031 - val_accuracy: 0.7812\n",
            "Epoch 777/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4120 - accuracy: 0.8090 - val_loss: 0.5030 - val_accuracy: 0.7812\n",
            "Epoch 778/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4119 - accuracy: 0.8090 - val_loss: 0.5032 - val_accuracy: 0.7812\n",
            "Epoch 779/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4120 - accuracy: 0.8108 - val_loss: 0.5031 - val_accuracy: 0.7812\n",
            "Epoch 780/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4120 - accuracy: 0.8090 - val_loss: 0.5030 - val_accuracy: 0.7812\n",
            "Epoch 781/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4118 - accuracy: 0.8090 - val_loss: 0.5030 - val_accuracy: 0.7812\n",
            "Epoch 782/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4118 - accuracy: 0.8090 - val_loss: 0.5030 - val_accuracy: 0.7812\n",
            "Epoch 783/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4117 - accuracy: 0.8090 - val_loss: 0.5030 - val_accuracy: 0.7812\n",
            "Epoch 784/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4118 - accuracy: 0.8073 - val_loss: 0.5031 - val_accuracy: 0.7812\n",
            "Epoch 785/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4117 - accuracy: 0.8073 - val_loss: 0.5030 - val_accuracy: 0.7812\n",
            "Epoch 786/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4117 - accuracy: 0.8073 - val_loss: 0.5033 - val_accuracy: 0.7812\n",
            "Epoch 787/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4116 - accuracy: 0.8073 - val_loss: 0.5033 - val_accuracy: 0.7812\n",
            "Epoch 788/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4115 - accuracy: 0.8073 - val_loss: 0.5032 - val_accuracy: 0.7812\n",
            "Epoch 789/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4115 - accuracy: 0.8056 - val_loss: 0.5031 - val_accuracy: 0.7812\n",
            "Epoch 790/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4115 - accuracy: 0.8108 - val_loss: 0.5030 - val_accuracy: 0.7812\n",
            "Epoch 791/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4115 - accuracy: 0.8073 - val_loss: 0.5030 - val_accuracy: 0.7812\n",
            "Epoch 792/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4115 - accuracy: 0.8090 - val_loss: 0.5030 - val_accuracy: 0.7812\n",
            "Epoch 793/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4114 - accuracy: 0.8090 - val_loss: 0.5032 - val_accuracy: 0.7812\n",
            "Epoch 794/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4116 - accuracy: 0.8073 - val_loss: 0.5032 - val_accuracy: 0.7812\n",
            "Epoch 795/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4113 - accuracy: 0.8090 - val_loss: 0.5031 - val_accuracy: 0.7812\n",
            "Epoch 796/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4113 - accuracy: 0.8073 - val_loss: 0.5032 - val_accuracy: 0.7812\n",
            "Epoch 797/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4113 - accuracy: 0.8108 - val_loss: 0.5034 - val_accuracy: 0.7812\n",
            "Epoch 798/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4113 - accuracy: 0.8073 - val_loss: 0.5035 - val_accuracy: 0.7812\n",
            "Epoch 799/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4111 - accuracy: 0.8090 - val_loss: 0.5034 - val_accuracy: 0.7812\n",
            "Epoch 800/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4113 - accuracy: 0.8090 - val_loss: 0.5033 - val_accuracy: 0.7812\n",
            "Epoch 801/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4112 - accuracy: 0.8108 - val_loss: 0.5033 - val_accuracy: 0.7812\n",
            "Epoch 802/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4112 - accuracy: 0.8073 - val_loss: 0.5035 - val_accuracy: 0.7812\n",
            "Epoch 803/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4112 - accuracy: 0.8090 - val_loss: 0.5034 - val_accuracy: 0.7812\n",
            "Epoch 804/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4112 - accuracy: 0.8073 - val_loss: 0.5035 - val_accuracy: 0.7812\n",
            "Epoch 805/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4110 - accuracy: 0.8073 - val_loss: 0.5035 - val_accuracy: 0.7812\n",
            "Epoch 806/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4113 - accuracy: 0.8090 - val_loss: 0.5037 - val_accuracy: 0.7812\n",
            "Epoch 807/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4109 - accuracy: 0.8090 - val_loss: 0.5035 - val_accuracy: 0.7812\n",
            "Epoch 808/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4110 - accuracy: 0.8090 - val_loss: 0.5034 - val_accuracy: 0.7812\n",
            "Epoch 809/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4110 - accuracy: 0.8073 - val_loss: 0.5034 - val_accuracy: 0.7812\n",
            "Epoch 810/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4110 - accuracy: 0.8090 - val_loss: 0.5035 - val_accuracy: 0.7812\n",
            "Epoch 811/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4111 - accuracy: 0.8090 - val_loss: 0.5033 - val_accuracy: 0.7812\n",
            "Epoch 812/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4108 - accuracy: 0.8073 - val_loss: 0.5035 - val_accuracy: 0.7812\n",
            "Epoch 813/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4109 - accuracy: 0.8073 - val_loss: 0.5035 - val_accuracy: 0.7812\n",
            "Epoch 814/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4108 - accuracy: 0.8073 - val_loss: 0.5037 - val_accuracy: 0.7812\n",
            "Epoch 815/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4108 - accuracy: 0.8090 - val_loss: 0.5035 - val_accuracy: 0.7812\n",
            "Epoch 816/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4107 - accuracy: 0.8090 - val_loss: 0.5036 - val_accuracy: 0.7812\n",
            "Epoch 817/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4108 - accuracy: 0.8090 - val_loss: 0.5036 - val_accuracy: 0.7812\n",
            "Epoch 818/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4106 - accuracy: 0.8090 - val_loss: 0.5035 - val_accuracy: 0.7812\n",
            "Epoch 819/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.8090 - val_loss: 0.5037 - val_accuracy: 0.7812\n",
            "Epoch 820/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4107 - accuracy: 0.8073 - val_loss: 0.5037 - val_accuracy: 0.7812\n",
            "Epoch 821/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.8108 - val_loss: 0.5036 - val_accuracy: 0.7812\n",
            "Epoch 822/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4105 - accuracy: 0.8073 - val_loss: 0.5033 - val_accuracy: 0.7812\n",
            "Epoch 823/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4106 - accuracy: 0.8090 - val_loss: 0.5034 - val_accuracy: 0.7812\n",
            "Epoch 824/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.8073 - val_loss: 0.5034 - val_accuracy: 0.7812\n",
            "Epoch 825/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4106 - accuracy: 0.8090 - val_loss: 0.5034 - val_accuracy: 0.7812\n",
            "Epoch 826/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8090 - val_loss: 0.5036 - val_accuracy: 0.7812\n",
            "Epoch 827/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4106 - accuracy: 0.8073 - val_loss: 0.5037 - val_accuracy: 0.7812\n",
            "Epoch 828/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4102 - accuracy: 0.8073 - val_loss: 0.5035 - val_accuracy: 0.7812\n",
            "Epoch 829/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8073 - val_loss: 0.5035 - val_accuracy: 0.7812\n",
            "Epoch 830/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4102 - accuracy: 0.8073 - val_loss: 0.5036 - val_accuracy: 0.7812\n",
            "Epoch 831/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8073 - val_loss: 0.5037 - val_accuracy: 0.7812\n",
            "Epoch 832/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8073 - val_loss: 0.5036 - val_accuracy: 0.7812\n",
            "Epoch 833/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4102 - accuracy: 0.8073 - val_loss: 0.5036 - val_accuracy: 0.7812\n",
            "Epoch 834/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8073 - val_loss: 0.5035 - val_accuracy: 0.7812\n",
            "Epoch 835/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4100 - accuracy: 0.8090 - val_loss: 0.5035 - val_accuracy: 0.7812\n",
            "Epoch 836/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4100 - accuracy: 0.8073 - val_loss: 0.5035 - val_accuracy: 0.7812\n",
            "Epoch 837/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4100 - accuracy: 0.8090 - val_loss: 0.5036 - val_accuracy: 0.7812\n",
            "Epoch 838/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4100 - accuracy: 0.8073 - val_loss: 0.5037 - val_accuracy: 0.7812\n",
            "Epoch 839/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4099 - accuracy: 0.8090 - val_loss: 0.5038 - val_accuracy: 0.7812\n",
            "Epoch 840/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4102 - accuracy: 0.8073 - val_loss: 0.5038 - val_accuracy: 0.7812\n",
            "Epoch 841/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4099 - accuracy: 0.8073 - val_loss: 0.5038 - val_accuracy: 0.7812\n",
            "Epoch 842/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4101 - accuracy: 0.8090 - val_loss: 0.5036 - val_accuracy: 0.7812\n",
            "Epoch 843/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4098 - accuracy: 0.8090 - val_loss: 0.5036 - val_accuracy: 0.7812\n",
            "Epoch 844/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4098 - accuracy: 0.8073 - val_loss: 0.5039 - val_accuracy: 0.7812\n",
            "Epoch 845/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4098 - accuracy: 0.8090 - val_loss: 0.5038 - val_accuracy: 0.7812\n",
            "Epoch 846/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4096 - accuracy: 0.8108 - val_loss: 0.5037 - val_accuracy: 0.7812\n",
            "Epoch 847/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4097 - accuracy: 0.8090 - val_loss: 0.5036 - val_accuracy: 0.7812\n",
            "Epoch 848/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4097 - accuracy: 0.8073 - val_loss: 0.5035 - val_accuracy: 0.7812\n",
            "Epoch 849/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4097 - accuracy: 0.8073 - val_loss: 0.5038 - val_accuracy: 0.7812\n",
            "Epoch 850/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4096 - accuracy: 0.8090 - val_loss: 0.5038 - val_accuracy: 0.7812\n",
            "Epoch 851/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4096 - accuracy: 0.8073 - val_loss: 0.5039 - val_accuracy: 0.7812\n",
            "Epoch 852/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4095 - accuracy: 0.8090 - val_loss: 0.5040 - val_accuracy: 0.7812\n",
            "Epoch 853/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4097 - accuracy: 0.8108 - val_loss: 0.5040 - val_accuracy: 0.7812\n",
            "Epoch 854/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4095 - accuracy: 0.8090 - val_loss: 0.5038 - val_accuracy: 0.7812\n",
            "Epoch 855/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4094 - accuracy: 0.8090 - val_loss: 0.5040 - val_accuracy: 0.7812\n",
            "Epoch 856/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4094 - accuracy: 0.8073 - val_loss: 0.5040 - val_accuracy: 0.7812\n",
            "Epoch 857/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4093 - accuracy: 0.8090 - val_loss: 0.5038 - val_accuracy: 0.7812\n",
            "Epoch 858/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4093 - accuracy: 0.8090 - val_loss: 0.5041 - val_accuracy: 0.7812\n",
            "Epoch 859/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4093 - accuracy: 0.8090 - val_loss: 0.5043 - val_accuracy: 0.7812\n",
            "Epoch 860/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4094 - accuracy: 0.8090 - val_loss: 0.5042 - val_accuracy: 0.7812\n",
            "Epoch 861/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4093 - accuracy: 0.8090 - val_loss: 0.5042 - val_accuracy: 0.7812\n",
            "Epoch 862/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4094 - accuracy: 0.8073 - val_loss: 0.5040 - val_accuracy: 0.7812\n",
            "Epoch 863/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4091 - accuracy: 0.8073 - val_loss: 0.5039 - val_accuracy: 0.7812\n",
            "Epoch 864/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4091 - accuracy: 0.8090 - val_loss: 0.5041 - val_accuracy: 0.7812\n",
            "Epoch 865/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4089 - accuracy: 0.8073 - val_loss: 0.5040 - val_accuracy: 0.7812\n",
            "Epoch 866/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4089 - accuracy: 0.8090 - val_loss: 0.5041 - val_accuracy: 0.7812\n",
            "Epoch 867/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4091 - accuracy: 0.8090 - val_loss: 0.5041 - val_accuracy: 0.7812\n",
            "Epoch 868/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4090 - accuracy: 0.8108 - val_loss: 0.5044 - val_accuracy: 0.7812\n",
            "Epoch 869/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4090 - accuracy: 0.8073 - val_loss: 0.5042 - val_accuracy: 0.7812\n",
            "Epoch 870/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4088 - accuracy: 0.8090 - val_loss: 0.5042 - val_accuracy: 0.7812\n",
            "Epoch 871/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4090 - accuracy: 0.8090 - val_loss: 0.5045 - val_accuracy: 0.7812\n",
            "Epoch 872/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4089 - accuracy: 0.8073 - val_loss: 0.5047 - val_accuracy: 0.7812\n",
            "Epoch 873/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4087 - accuracy: 0.8073 - val_loss: 0.5045 - val_accuracy: 0.7812\n",
            "Epoch 874/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4090 - accuracy: 0.8090 - val_loss: 0.5046 - val_accuracy: 0.7812\n",
            "Epoch 875/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4089 - accuracy: 0.8090 - val_loss: 0.5048 - val_accuracy: 0.7812\n",
            "Epoch 876/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4088 - accuracy: 0.8073 - val_loss: 0.5045 - val_accuracy: 0.7812\n",
            "Epoch 877/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4086 - accuracy: 0.8073 - val_loss: 0.5047 - val_accuracy: 0.7812\n",
            "Epoch 878/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4085 - accuracy: 0.8090 - val_loss: 0.5047 - val_accuracy: 0.7812\n",
            "Epoch 879/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4086 - accuracy: 0.8073 - val_loss: 0.5047 - val_accuracy: 0.7812\n",
            "Epoch 880/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4088 - accuracy: 0.8090 - val_loss: 0.5050 - val_accuracy: 0.7812\n",
            "Epoch 881/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4086 - accuracy: 0.8056 - val_loss: 0.5047 - val_accuracy: 0.7812\n",
            "Epoch 882/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4084 - accuracy: 0.8090 - val_loss: 0.5048 - val_accuracy: 0.7812\n",
            "Epoch 883/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4084 - accuracy: 0.8090 - val_loss: 0.5049 - val_accuracy: 0.7812\n",
            "Epoch 884/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4083 - accuracy: 0.8090 - val_loss: 0.5050 - val_accuracy: 0.7812\n",
            "Epoch 885/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4084 - accuracy: 0.8090 - val_loss: 0.5052 - val_accuracy: 0.7812\n",
            "Epoch 886/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4084 - accuracy: 0.8073 - val_loss: 0.5052 - val_accuracy: 0.7812\n",
            "Epoch 887/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4084 - accuracy: 0.8125 - val_loss: 0.5053 - val_accuracy: 0.7812\n",
            "Epoch 888/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4084 - accuracy: 0.8056 - val_loss: 0.5052 - val_accuracy: 0.7812\n",
            "Epoch 889/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4085 - accuracy: 0.8056 - val_loss: 0.5052 - val_accuracy: 0.7812\n",
            "Epoch 890/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4082 - accuracy: 0.8073 - val_loss: 0.5052 - val_accuracy: 0.7812\n",
            "Epoch 891/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4081 - accuracy: 0.8056 - val_loss: 0.5052 - val_accuracy: 0.7812\n",
            "Epoch 892/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4082 - accuracy: 0.8073 - val_loss: 0.5050 - val_accuracy: 0.7812\n",
            "Epoch 893/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4084 - accuracy: 0.8108 - val_loss: 0.5054 - val_accuracy: 0.7812\n",
            "Epoch 894/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4081 - accuracy: 0.8073 - val_loss: 0.5053 - val_accuracy: 0.7812\n",
            "Epoch 895/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4079 - accuracy: 0.8090 - val_loss: 0.5054 - val_accuracy: 0.7812\n",
            "Epoch 896/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4080 - accuracy: 0.8073 - val_loss: 0.5053 - val_accuracy: 0.7812\n",
            "Epoch 897/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4080 - accuracy: 0.8073 - val_loss: 0.5054 - val_accuracy: 0.7812\n",
            "Epoch 898/1500\n",
            "18/18 [==============================] - 0s 21ms/step - loss: 0.4080 - accuracy: 0.8056 - val_loss: 0.5053 - val_accuracy: 0.7812\n",
            "Epoch 899/1500\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.4079 - accuracy: 0.8108 - val_loss: 0.5055 - val_accuracy: 0.7812\n",
            "Epoch 900/1500\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.4079 - accuracy: 0.8038 - val_loss: 0.5054 - val_accuracy: 0.7812\n",
            "Epoch 901/1500\n",
            "18/18 [==============================] - 0s 20ms/step - loss: 0.4079 - accuracy: 0.8073 - val_loss: 0.5054 - val_accuracy: 0.7812\n",
            "Epoch 902/1500\n",
            "18/18 [==============================] - 0s 19ms/step - loss: 0.4079 - accuracy: 0.8108 - val_loss: 0.5053 - val_accuracy: 0.7812\n",
            "Epoch 903/1500\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 0.4077 - accuracy: 0.8108 - val_loss: 0.5055 - val_accuracy: 0.7812\n",
            "Epoch 904/1500\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.4080 - accuracy: 0.8056 - val_loss: 0.5055 - val_accuracy: 0.7812\n",
            "Epoch 905/1500\n",
            "18/18 [==============================] - 0s 21ms/step - loss: 0.4077 - accuracy: 0.8090 - val_loss: 0.5057 - val_accuracy: 0.7812\n",
            "Epoch 906/1500\n",
            "18/18 [==============================] - 0s 27ms/step - loss: 0.4079 - accuracy: 0.8090 - val_loss: 0.5059 - val_accuracy: 0.7812\n",
            "Epoch 907/1500\n",
            "18/18 [==============================] - 0s 20ms/step - loss: 0.4076 - accuracy: 0.8090 - val_loss: 0.5060 - val_accuracy: 0.7812\n",
            "Epoch 908/1500\n",
            "18/18 [==============================] - 0s 20ms/step - loss: 0.4076 - accuracy: 0.8108 - val_loss: 0.5060 - val_accuracy: 0.7812\n",
            "Epoch 909/1500\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.4077 - accuracy: 0.8108 - val_loss: 0.5062 - val_accuracy: 0.7812\n",
            "Epoch 910/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4075 - accuracy: 0.8090 - val_loss: 0.5063 - val_accuracy: 0.7812\n",
            "Epoch 911/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4076 - accuracy: 0.8073 - val_loss: 0.5061 - val_accuracy: 0.7812\n",
            "Epoch 912/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4076 - accuracy: 0.8056 - val_loss: 0.5059 - val_accuracy: 0.7865\n",
            "Epoch 913/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4076 - accuracy: 0.8073 - val_loss: 0.5059 - val_accuracy: 0.7865\n",
            "Epoch 914/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4074 - accuracy: 0.8108 - val_loss: 0.5061 - val_accuracy: 0.7865\n",
            "Epoch 915/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4074 - accuracy: 0.8073 - val_loss: 0.5061 - val_accuracy: 0.7865\n",
            "Epoch 916/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4074 - accuracy: 0.8125 - val_loss: 0.5063 - val_accuracy: 0.7865\n",
            "Epoch 917/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4075 - accuracy: 0.8090 - val_loss: 0.5063 - val_accuracy: 0.7865\n",
            "Epoch 918/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4072 - accuracy: 0.8073 - val_loss: 0.5061 - val_accuracy: 0.7865\n",
            "Epoch 919/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4073 - accuracy: 0.8073 - val_loss: 0.5061 - val_accuracy: 0.7865\n",
            "Epoch 920/1500\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.4071 - accuracy: 0.8090 - val_loss: 0.5064 - val_accuracy: 0.7865\n",
            "Epoch 921/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4074 - accuracy: 0.8090 - val_loss: 0.5063 - val_accuracy: 0.7865\n",
            "Epoch 922/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4071 - accuracy: 0.8125 - val_loss: 0.5065 - val_accuracy: 0.7812\n",
            "Epoch 923/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4071 - accuracy: 0.8125 - val_loss: 0.5068 - val_accuracy: 0.7812\n",
            "Epoch 924/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4071 - accuracy: 0.8090 - val_loss: 0.5067 - val_accuracy: 0.7812\n",
            "Epoch 925/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4071 - accuracy: 0.8108 - val_loss: 0.5068 - val_accuracy: 0.7812\n",
            "Epoch 926/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4070 - accuracy: 0.8073 - val_loss: 0.5067 - val_accuracy: 0.7865\n",
            "Epoch 927/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4072 - accuracy: 0.8125 - val_loss: 0.5071 - val_accuracy: 0.7812\n",
            "Epoch 928/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4070 - accuracy: 0.8056 - val_loss: 0.5070 - val_accuracy: 0.7812\n",
            "Epoch 929/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4070 - accuracy: 0.8090 - val_loss: 0.5068 - val_accuracy: 0.7865\n",
            "Epoch 930/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4068 - accuracy: 0.8073 - val_loss: 0.5066 - val_accuracy: 0.7865\n",
            "Epoch 931/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4068 - accuracy: 0.8108 - val_loss: 0.5068 - val_accuracy: 0.7865\n",
            "Epoch 932/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4068 - accuracy: 0.8090 - val_loss: 0.5068 - val_accuracy: 0.7865\n",
            "Epoch 933/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4067 - accuracy: 0.8108 - val_loss: 0.5070 - val_accuracy: 0.7865\n",
            "Epoch 934/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4067 - accuracy: 0.8056 - val_loss: 0.5067 - val_accuracy: 0.7865\n",
            "Epoch 935/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4068 - accuracy: 0.8125 - val_loss: 0.5071 - val_accuracy: 0.7812\n",
            "Epoch 936/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4067 - accuracy: 0.8073 - val_loss: 0.5071 - val_accuracy: 0.7865\n",
            "Epoch 937/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4066 - accuracy: 0.8090 - val_loss: 0.5071 - val_accuracy: 0.7865\n",
            "Epoch 938/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4068 - accuracy: 0.8090 - val_loss: 0.5072 - val_accuracy: 0.7865\n",
            "Epoch 939/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4067 - accuracy: 0.8125 - val_loss: 0.5073 - val_accuracy: 0.7812\n",
            "Epoch 940/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4066 - accuracy: 0.8056 - val_loss: 0.5071 - val_accuracy: 0.7812\n",
            "Epoch 941/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4064 - accuracy: 0.8125 - val_loss: 0.5073 - val_accuracy: 0.7812\n",
            "Epoch 942/1500\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 0.4065 - accuracy: 0.8090 - val_loss: 0.5073 - val_accuracy: 0.7812\n",
            "Epoch 943/1500\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.4064 - accuracy: 0.8056 - val_loss: 0.5073 - val_accuracy: 0.7865\n",
            "Epoch 944/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4064 - accuracy: 0.8090 - val_loss: 0.5073 - val_accuracy: 0.7865\n",
            "Epoch 945/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4065 - accuracy: 0.8073 - val_loss: 0.5074 - val_accuracy: 0.7812\n",
            "Epoch 946/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4063 - accuracy: 0.8108 - val_loss: 0.5077 - val_accuracy: 0.7812\n",
            "Epoch 947/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4062 - accuracy: 0.8090 - val_loss: 0.5076 - val_accuracy: 0.7865\n",
            "Epoch 948/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4064 - accuracy: 0.8090 - val_loss: 0.5077 - val_accuracy: 0.7812\n",
            "Epoch 949/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4064 - accuracy: 0.8090 - val_loss: 0.5078 - val_accuracy: 0.7812\n",
            "Epoch 950/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4063 - accuracy: 0.8090 - val_loss: 0.5075 - val_accuracy: 0.7865\n",
            "Epoch 951/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4060 - accuracy: 0.8090 - val_loss: 0.5074 - val_accuracy: 0.7865\n",
            "Epoch 952/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4060 - accuracy: 0.8090 - val_loss: 0.5077 - val_accuracy: 0.7812\n",
            "Epoch 953/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4060 - accuracy: 0.8073 - val_loss: 0.5078 - val_accuracy: 0.7812\n",
            "Epoch 954/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4061 - accuracy: 0.8090 - val_loss: 0.5078 - val_accuracy: 0.7812\n",
            "Epoch 955/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4061 - accuracy: 0.8056 - val_loss: 0.5079 - val_accuracy: 0.7812\n",
            "Epoch 956/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4061 - accuracy: 0.8056 - val_loss: 0.5078 - val_accuracy: 0.7812\n",
            "Epoch 957/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4060 - accuracy: 0.8090 - val_loss: 0.5079 - val_accuracy: 0.7865\n",
            "Epoch 958/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4059 - accuracy: 0.8090 - val_loss: 0.5080 - val_accuracy: 0.7812\n",
            "Epoch 959/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4059 - accuracy: 0.8021 - val_loss: 0.5078 - val_accuracy: 0.7865\n",
            "Epoch 960/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4060 - accuracy: 0.8090 - val_loss: 0.5078 - val_accuracy: 0.7865\n",
            "Epoch 961/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4059 - accuracy: 0.8073 - val_loss: 0.5080 - val_accuracy: 0.7865\n",
            "Epoch 962/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4057 - accuracy: 0.8056 - val_loss: 0.5080 - val_accuracy: 0.7865\n",
            "Epoch 963/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4059 - accuracy: 0.8073 - val_loss: 0.5080 - val_accuracy: 0.7865\n",
            "Epoch 964/1500\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.4059 - accuracy: 0.8090 - val_loss: 0.5082 - val_accuracy: 0.7865\n",
            "Epoch 965/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4057 - accuracy: 0.8108 - val_loss: 0.5084 - val_accuracy: 0.7865\n",
            "Epoch 966/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4056 - accuracy: 0.8056 - val_loss: 0.5081 - val_accuracy: 0.7865\n",
            "Epoch 967/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4055 - accuracy: 0.8073 - val_loss: 0.5081 - val_accuracy: 0.7865\n",
            "Epoch 968/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4056 - accuracy: 0.8038 - val_loss: 0.5081 - val_accuracy: 0.7865\n",
            "Epoch 969/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4055 - accuracy: 0.8073 - val_loss: 0.5082 - val_accuracy: 0.7865\n",
            "Epoch 970/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4055 - accuracy: 0.8108 - val_loss: 0.5084 - val_accuracy: 0.7865\n",
            "Epoch 971/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4057 - accuracy: 0.8073 - val_loss: 0.5084 - val_accuracy: 0.7865\n",
            "Epoch 972/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4055 - accuracy: 0.8073 - val_loss: 0.5084 - val_accuracy: 0.7865\n",
            "Epoch 973/1500\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.4054 - accuracy: 0.8125 - val_loss: 0.5089 - val_accuracy: 0.7812\n",
            "Epoch 974/1500\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.4054 - accuracy: 0.8073 - val_loss: 0.5088 - val_accuracy: 0.7812\n",
            "Epoch 975/1500\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.4054 - accuracy: 0.8090 - val_loss: 0.5089 - val_accuracy: 0.7865\n",
            "Epoch 976/1500\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.4054 - accuracy: 0.8038 - val_loss: 0.5088 - val_accuracy: 0.7865\n",
            "Epoch 977/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4052 - accuracy: 0.8090 - val_loss: 0.5089 - val_accuracy: 0.7865\n",
            "Epoch 978/1500\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.4052 - accuracy: 0.8073 - val_loss: 0.5088 - val_accuracy: 0.7865\n",
            "Epoch 979/1500\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.4052 - accuracy: 0.8056 - val_loss: 0.5087 - val_accuracy: 0.7865\n",
            "Epoch 980/1500\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.4053 - accuracy: 0.8073 - val_loss: 0.5087 - val_accuracy: 0.7865\n",
            "Epoch 981/1500\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.4051 - accuracy: 0.8090 - val_loss: 0.5091 - val_accuracy: 0.7865\n",
            "Epoch 982/1500\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.4051 - accuracy: 0.8038 - val_loss: 0.5089 - val_accuracy: 0.7865\n",
            "Epoch 983/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4050 - accuracy: 0.8125 - val_loss: 0.5091 - val_accuracy: 0.7865\n",
            "Epoch 984/1500\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.4051 - accuracy: 0.8090 - val_loss: 0.5092 - val_accuracy: 0.7865\n",
            "Epoch 985/1500\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.4050 - accuracy: 0.8073 - val_loss: 0.5091 - val_accuracy: 0.7865\n",
            "Epoch 986/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4049 - accuracy: 0.8073 - val_loss: 0.5091 - val_accuracy: 0.7865\n",
            "Epoch 987/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4048 - accuracy: 0.8056 - val_loss: 0.5091 - val_accuracy: 0.7865\n",
            "Epoch 988/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4048 - accuracy: 0.8090 - val_loss: 0.5090 - val_accuracy: 0.7865\n",
            "Epoch 989/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4048 - accuracy: 0.8090 - val_loss: 0.5091 - val_accuracy: 0.7865\n",
            "Epoch 990/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4048 - accuracy: 0.8108 - val_loss: 0.5095 - val_accuracy: 0.7865\n",
            "Epoch 991/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4048 - accuracy: 0.8090 - val_loss: 0.5096 - val_accuracy: 0.7865\n",
            "Epoch 992/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4050 - accuracy: 0.8073 - val_loss: 0.5095 - val_accuracy: 0.7865\n",
            "Epoch 993/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4047 - accuracy: 0.8090 - val_loss: 0.5095 - val_accuracy: 0.7865\n",
            "Epoch 994/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4049 - accuracy: 0.8090 - val_loss: 0.5097 - val_accuracy: 0.7865\n",
            "Epoch 995/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4047 - accuracy: 0.8090 - val_loss: 0.5096 - val_accuracy: 0.7865\n",
            "Epoch 996/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4046 - accuracy: 0.8125 - val_loss: 0.5097 - val_accuracy: 0.7865\n",
            "Epoch 997/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4045 - accuracy: 0.8090 - val_loss: 0.5097 - val_accuracy: 0.7865\n",
            "Epoch 998/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4046 - accuracy: 0.8073 - val_loss: 0.5100 - val_accuracy: 0.7865\n",
            "Epoch 999/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4046 - accuracy: 0.8056 - val_loss: 0.5098 - val_accuracy: 0.7865\n",
            "Epoch 1000/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4045 - accuracy: 0.8108 - val_loss: 0.5100 - val_accuracy: 0.7865\n",
            "Epoch 1001/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4043 - accuracy: 0.8108 - val_loss: 0.5100 - val_accuracy: 0.7865\n",
            "Epoch 1002/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4043 - accuracy: 0.8038 - val_loss: 0.5099 - val_accuracy: 0.7865\n",
            "Epoch 1003/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4045 - accuracy: 0.8108 - val_loss: 0.5099 - val_accuracy: 0.7865\n",
            "Epoch 1004/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4043 - accuracy: 0.8090 - val_loss: 0.5100 - val_accuracy: 0.7865\n",
            "Epoch 1005/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4044 - accuracy: 0.8108 - val_loss: 0.5102 - val_accuracy: 0.7917\n",
            "Epoch 1006/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4041 - accuracy: 0.8090 - val_loss: 0.5102 - val_accuracy: 0.7917\n",
            "Epoch 1007/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4041 - accuracy: 0.8073 - val_loss: 0.5102 - val_accuracy: 0.7917\n",
            "Epoch 1008/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4043 - accuracy: 0.8073 - val_loss: 0.5101 - val_accuracy: 0.7917\n",
            "Epoch 1009/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4043 - accuracy: 0.8056 - val_loss: 0.5102 - val_accuracy: 0.7917\n",
            "Epoch 1010/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4040 - accuracy: 0.8090 - val_loss: 0.5101 - val_accuracy: 0.7917\n",
            "Epoch 1011/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4041 - accuracy: 0.8090 - val_loss: 0.5101 - val_accuracy: 0.7865\n",
            "Epoch 1012/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4040 - accuracy: 0.8090 - val_loss: 0.5102 - val_accuracy: 0.7865\n",
            "Epoch 1013/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4039 - accuracy: 0.8090 - val_loss: 0.5103 - val_accuracy: 0.7865\n",
            "Epoch 1014/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4039 - accuracy: 0.8073 - val_loss: 0.5103 - val_accuracy: 0.7865\n",
            "Epoch 1015/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4038 - accuracy: 0.8108 - val_loss: 0.5105 - val_accuracy: 0.7917\n",
            "Epoch 1016/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4039 - accuracy: 0.8056 - val_loss: 0.5101 - val_accuracy: 0.7865\n",
            "Epoch 1017/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4039 - accuracy: 0.8125 - val_loss: 0.5103 - val_accuracy: 0.7917\n",
            "Epoch 1018/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4039 - accuracy: 0.8056 - val_loss: 0.5102 - val_accuracy: 0.7865\n",
            "Epoch 1019/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4038 - accuracy: 0.8073 - val_loss: 0.5102 - val_accuracy: 0.7917\n",
            "Epoch 1020/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4038 - accuracy: 0.8108 - val_loss: 0.5105 - val_accuracy: 0.7917\n",
            "Epoch 1021/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4039 - accuracy: 0.8056 - val_loss: 0.5104 - val_accuracy: 0.7917\n",
            "Epoch 1022/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4036 - accuracy: 0.8073 - val_loss: 0.5107 - val_accuracy: 0.7917\n",
            "Epoch 1023/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4036 - accuracy: 0.8142 - val_loss: 0.5109 - val_accuracy: 0.7917\n",
            "Epoch 1024/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4035 - accuracy: 0.8073 - val_loss: 0.5111 - val_accuracy: 0.7917\n",
            "Epoch 1025/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4036 - accuracy: 0.8073 - val_loss: 0.5110 - val_accuracy: 0.7917\n",
            "Epoch 1026/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4037 - accuracy: 0.8090 - val_loss: 0.5111 - val_accuracy: 0.7917\n",
            "Epoch 1027/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4036 - accuracy: 0.8073 - val_loss: 0.5110 - val_accuracy: 0.7917\n",
            "Epoch 1028/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4036 - accuracy: 0.8073 - val_loss: 0.5109 - val_accuracy: 0.7917\n",
            "Epoch 1029/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4034 - accuracy: 0.8073 - val_loss: 0.5110 - val_accuracy: 0.7917\n",
            "Epoch 1030/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4034 - accuracy: 0.8073 - val_loss: 0.5111 - val_accuracy: 0.7917\n",
            "Epoch 1031/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4033 - accuracy: 0.8073 - val_loss: 0.5111 - val_accuracy: 0.7865\n",
            "Epoch 1032/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4034 - accuracy: 0.8073 - val_loss: 0.5110 - val_accuracy: 0.7865\n",
            "Epoch 1033/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4032 - accuracy: 0.8108 - val_loss: 0.5114 - val_accuracy: 0.7917\n",
            "Epoch 1034/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4034 - accuracy: 0.8073 - val_loss: 0.5114 - val_accuracy: 0.7917\n",
            "Epoch 1035/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4032 - accuracy: 0.8090 - val_loss: 0.5115 - val_accuracy: 0.7865\n",
            "Epoch 1036/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4033 - accuracy: 0.8108 - val_loss: 0.5116 - val_accuracy: 0.7917\n",
            "Epoch 1037/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4032 - accuracy: 0.8073 - val_loss: 0.5116 - val_accuracy: 0.7865\n",
            "Epoch 1038/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4030 - accuracy: 0.8090 - val_loss: 0.5116 - val_accuracy: 0.7865\n",
            "Epoch 1039/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4030 - accuracy: 0.8090 - val_loss: 0.5118 - val_accuracy: 0.7917\n",
            "Epoch 1040/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4031 - accuracy: 0.8090 - val_loss: 0.5119 - val_accuracy: 0.7865\n",
            "Epoch 1041/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4028 - accuracy: 0.8108 - val_loss: 0.5121 - val_accuracy: 0.7917\n",
            "Epoch 1042/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4029 - accuracy: 0.8108 - val_loss: 0.5123 - val_accuracy: 0.7917\n",
            "Epoch 1043/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4030 - accuracy: 0.8108 - val_loss: 0.5123 - val_accuracy: 0.7917\n",
            "Epoch 1044/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4027 - accuracy: 0.8090 - val_loss: 0.5121 - val_accuracy: 0.7865\n",
            "Epoch 1045/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4027 - accuracy: 0.8108 - val_loss: 0.5122 - val_accuracy: 0.7865\n",
            "Epoch 1046/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4026 - accuracy: 0.8090 - val_loss: 0.5124 - val_accuracy: 0.7917\n",
            "Epoch 1047/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4027 - accuracy: 0.8108 - val_loss: 0.5123 - val_accuracy: 0.7917\n",
            "Epoch 1048/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4026 - accuracy: 0.8090 - val_loss: 0.5123 - val_accuracy: 0.7917\n",
            "Epoch 1049/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4027 - accuracy: 0.8125 - val_loss: 0.5125 - val_accuracy: 0.7917\n",
            "Epoch 1050/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4025 - accuracy: 0.8073 - val_loss: 0.5125 - val_accuracy: 0.7865\n",
            "Epoch 1051/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4026 - accuracy: 0.8073 - val_loss: 0.5125 - val_accuracy: 0.7812\n",
            "Epoch 1052/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4025 - accuracy: 0.8125 - val_loss: 0.5127 - val_accuracy: 0.7865\n",
            "Epoch 1053/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4023 - accuracy: 0.8090 - val_loss: 0.5129 - val_accuracy: 0.7812\n",
            "Epoch 1054/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4023 - accuracy: 0.8125 - val_loss: 0.5129 - val_accuracy: 0.7812\n",
            "Epoch 1055/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4023 - accuracy: 0.8160 - val_loss: 0.5131 - val_accuracy: 0.7865\n",
            "Epoch 1056/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4021 - accuracy: 0.8090 - val_loss: 0.5129 - val_accuracy: 0.7917\n",
            "Epoch 1057/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4023 - accuracy: 0.8073 - val_loss: 0.5127 - val_accuracy: 0.7812\n",
            "Epoch 1058/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4020 - accuracy: 0.8142 - val_loss: 0.5131 - val_accuracy: 0.7917\n",
            "Epoch 1059/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4022 - accuracy: 0.8090 - val_loss: 0.5129 - val_accuracy: 0.7865\n",
            "Epoch 1060/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4023 - accuracy: 0.8125 - val_loss: 0.5129 - val_accuracy: 0.7812\n",
            "Epoch 1061/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4021 - accuracy: 0.8090 - val_loss: 0.5130 - val_accuracy: 0.7812\n",
            "Epoch 1062/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4021 - accuracy: 0.8125 - val_loss: 0.5133 - val_accuracy: 0.7812\n",
            "Epoch 1063/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4019 - accuracy: 0.8142 - val_loss: 0.5133 - val_accuracy: 0.7812\n",
            "Epoch 1064/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4019 - accuracy: 0.8160 - val_loss: 0.5135 - val_accuracy: 0.7812\n",
            "Epoch 1065/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4019 - accuracy: 0.8125 - val_loss: 0.5135 - val_accuracy: 0.7812\n",
            "Epoch 1066/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4019 - accuracy: 0.8108 - val_loss: 0.5134 - val_accuracy: 0.7812\n",
            "Epoch 1067/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4018 - accuracy: 0.8108 - val_loss: 0.5133 - val_accuracy: 0.7812\n",
            "Epoch 1068/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4019 - accuracy: 0.8194 - val_loss: 0.5136 - val_accuracy: 0.7812\n",
            "Epoch 1069/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4017 - accuracy: 0.8177 - val_loss: 0.5139 - val_accuracy: 0.7812\n",
            "Epoch 1070/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4016 - accuracy: 0.8160 - val_loss: 0.5140 - val_accuracy: 0.7812\n",
            "Epoch 1071/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4016 - accuracy: 0.8177 - val_loss: 0.5142 - val_accuracy: 0.7917\n",
            "Epoch 1072/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4017 - accuracy: 0.8073 - val_loss: 0.5138 - val_accuracy: 0.7865\n",
            "Epoch 1073/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4016 - accuracy: 0.8160 - val_loss: 0.5143 - val_accuracy: 0.7812\n",
            "Epoch 1074/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4019 - accuracy: 0.8125 - val_loss: 0.5141 - val_accuracy: 0.7812\n",
            "Epoch 1075/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4014 - accuracy: 0.8142 - val_loss: 0.5144 - val_accuracy: 0.7917\n",
            "Epoch 1076/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4016 - accuracy: 0.8142 - val_loss: 0.5142 - val_accuracy: 0.7917\n",
            "Epoch 1077/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4016 - accuracy: 0.8142 - val_loss: 0.5146 - val_accuracy: 0.7865\n",
            "Epoch 1078/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4013 - accuracy: 0.8142 - val_loss: 0.5147 - val_accuracy: 0.7917\n",
            "Epoch 1079/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4014 - accuracy: 0.8125 - val_loss: 0.5144 - val_accuracy: 0.7865\n",
            "Epoch 1080/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4012 - accuracy: 0.8160 - val_loss: 0.5147 - val_accuracy: 0.7865\n",
            "Epoch 1081/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4013 - accuracy: 0.8177 - val_loss: 0.5146 - val_accuracy: 0.7917\n",
            "Epoch 1082/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4013 - accuracy: 0.8160 - val_loss: 0.5146 - val_accuracy: 0.7917\n",
            "Epoch 1083/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4012 - accuracy: 0.8142 - val_loss: 0.5148 - val_accuracy: 0.7865\n",
            "Epoch 1084/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4012 - accuracy: 0.8125 - val_loss: 0.5146 - val_accuracy: 0.7865\n",
            "Epoch 1085/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4011 - accuracy: 0.8142 - val_loss: 0.5146 - val_accuracy: 0.7865\n",
            "Epoch 1086/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4011 - accuracy: 0.8177 - val_loss: 0.5147 - val_accuracy: 0.7865\n",
            "Epoch 1087/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4010 - accuracy: 0.8125 - val_loss: 0.5145 - val_accuracy: 0.7865\n",
            "Epoch 1088/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4012 - accuracy: 0.8125 - val_loss: 0.5147 - val_accuracy: 0.7865\n",
            "Epoch 1089/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4010 - accuracy: 0.8108 - val_loss: 0.5149 - val_accuracy: 0.7865\n",
            "Epoch 1090/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4010 - accuracy: 0.8142 - val_loss: 0.5148 - val_accuracy: 0.7865\n",
            "Epoch 1091/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4009 - accuracy: 0.8125 - val_loss: 0.5152 - val_accuracy: 0.7917\n",
            "Epoch 1092/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4008 - accuracy: 0.8142 - val_loss: 0.5154 - val_accuracy: 0.7917\n",
            "Epoch 1093/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4009 - accuracy: 0.8160 - val_loss: 0.5156 - val_accuracy: 0.7917\n",
            "Epoch 1094/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4008 - accuracy: 0.8160 - val_loss: 0.5153 - val_accuracy: 0.7917\n",
            "Epoch 1095/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4010 - accuracy: 0.8142 - val_loss: 0.5154 - val_accuracy: 0.7917\n",
            "Epoch 1096/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4006 - accuracy: 0.8142 - val_loss: 0.5154 - val_accuracy: 0.7917\n",
            "Epoch 1097/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4007 - accuracy: 0.8142 - val_loss: 0.5156 - val_accuracy: 0.7865\n",
            "Epoch 1098/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4005 - accuracy: 0.8125 - val_loss: 0.5157 - val_accuracy: 0.7917\n",
            "Epoch 1099/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4008 - accuracy: 0.8125 - val_loss: 0.5156 - val_accuracy: 0.7865\n",
            "Epoch 1100/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4005 - accuracy: 0.8142 - val_loss: 0.5158 - val_accuracy: 0.7865\n",
            "Epoch 1101/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4007 - accuracy: 0.8160 - val_loss: 0.5158 - val_accuracy: 0.7865\n",
            "Epoch 1102/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4004 - accuracy: 0.8160 - val_loss: 0.5161 - val_accuracy: 0.7917\n",
            "Epoch 1103/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4004 - accuracy: 0.8177 - val_loss: 0.5162 - val_accuracy: 0.7917\n",
            "Epoch 1104/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4005 - accuracy: 0.8142 - val_loss: 0.5161 - val_accuracy: 0.7917\n",
            "Epoch 1105/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4003 - accuracy: 0.8160 - val_loss: 0.5163 - val_accuracy: 0.7917\n",
            "Epoch 1106/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4003 - accuracy: 0.8142 - val_loss: 0.5164 - val_accuracy: 0.7917\n",
            "Epoch 1107/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4003 - accuracy: 0.8160 - val_loss: 0.5163 - val_accuracy: 0.7917\n",
            "Epoch 1108/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4004 - accuracy: 0.8177 - val_loss: 0.5163 - val_accuracy: 0.7917\n",
            "Epoch 1109/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4004 - accuracy: 0.8142 - val_loss: 0.5168 - val_accuracy: 0.7917\n",
            "Epoch 1110/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4001 - accuracy: 0.8125 - val_loss: 0.5164 - val_accuracy: 0.7917\n",
            "Epoch 1111/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4004 - accuracy: 0.8160 - val_loss: 0.5162 - val_accuracy: 0.7865\n",
            "Epoch 1112/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4004 - accuracy: 0.8142 - val_loss: 0.5167 - val_accuracy: 0.7917\n",
            "Epoch 1113/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4000 - accuracy: 0.8125 - val_loss: 0.5169 - val_accuracy: 0.7917\n",
            "Epoch 1114/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4003 - accuracy: 0.8125 - val_loss: 0.5170 - val_accuracy: 0.7917\n",
            "Epoch 1115/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4001 - accuracy: 0.8142 - val_loss: 0.5172 - val_accuracy: 0.7917\n",
            "Epoch 1116/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4000 - accuracy: 0.8177 - val_loss: 0.5172 - val_accuracy: 0.7917\n",
            "Epoch 1117/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4000 - accuracy: 0.8160 - val_loss: 0.5173 - val_accuracy: 0.7917\n",
            "Epoch 1118/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3999 - accuracy: 0.8142 - val_loss: 0.5176 - val_accuracy: 0.7917\n",
            "Epoch 1119/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3999 - accuracy: 0.8125 - val_loss: 0.5174 - val_accuracy: 0.7917\n",
            "Epoch 1120/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3999 - accuracy: 0.8160 - val_loss: 0.5175 - val_accuracy: 0.7917\n",
            "Epoch 1121/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3999 - accuracy: 0.8142 - val_loss: 0.5174 - val_accuracy: 0.7865\n",
            "Epoch 1122/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3998 - accuracy: 0.8194 - val_loss: 0.5172 - val_accuracy: 0.7812\n",
            "Epoch 1123/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4000 - accuracy: 0.8142 - val_loss: 0.5173 - val_accuracy: 0.7812\n",
            "Epoch 1124/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3999 - accuracy: 0.8160 - val_loss: 0.5175 - val_accuracy: 0.7865\n",
            "Epoch 1125/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4000 - accuracy: 0.8125 - val_loss: 0.5175 - val_accuracy: 0.7865\n",
            "Epoch 1126/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3996 - accuracy: 0.8194 - val_loss: 0.5178 - val_accuracy: 0.7865\n",
            "Epoch 1127/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3996 - accuracy: 0.8212 - val_loss: 0.5180 - val_accuracy: 0.7865\n",
            "Epoch 1128/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3995 - accuracy: 0.8212 - val_loss: 0.5183 - val_accuracy: 0.7865\n",
            "Epoch 1129/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3995 - accuracy: 0.8177 - val_loss: 0.5182 - val_accuracy: 0.7865\n",
            "Epoch 1130/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3995 - accuracy: 0.8177 - val_loss: 0.5184 - val_accuracy: 0.7865\n",
            "Epoch 1131/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3995 - accuracy: 0.8177 - val_loss: 0.5183 - val_accuracy: 0.7865\n",
            "Epoch 1132/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3996 - accuracy: 0.8212 - val_loss: 0.5184 - val_accuracy: 0.7865\n",
            "Epoch 1133/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3995 - accuracy: 0.8177 - val_loss: 0.5181 - val_accuracy: 0.7865\n",
            "Epoch 1134/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3994 - accuracy: 0.8194 - val_loss: 0.5183 - val_accuracy: 0.7865\n",
            "Epoch 1135/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3994 - accuracy: 0.8212 - val_loss: 0.5186 - val_accuracy: 0.7917\n",
            "Epoch 1136/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3992 - accuracy: 0.8229 - val_loss: 0.5187 - val_accuracy: 0.7865\n",
            "Epoch 1137/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3994 - accuracy: 0.8194 - val_loss: 0.5188 - val_accuracy: 0.7865\n",
            "Epoch 1138/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3993 - accuracy: 0.8177 - val_loss: 0.5189 - val_accuracy: 0.7917\n",
            "Epoch 1139/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3993 - accuracy: 0.8194 - val_loss: 0.5189 - val_accuracy: 0.7865\n",
            "Epoch 1140/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3991 - accuracy: 0.8212 - val_loss: 0.5189 - val_accuracy: 0.7917\n",
            "Epoch 1141/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3991 - accuracy: 0.8177 - val_loss: 0.5189 - val_accuracy: 0.7917\n",
            "Epoch 1142/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3991 - accuracy: 0.8160 - val_loss: 0.5189 - val_accuracy: 0.7917\n",
            "Epoch 1143/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3992 - accuracy: 0.8177 - val_loss: 0.5189 - val_accuracy: 0.7917\n",
            "Epoch 1144/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3994 - accuracy: 0.8212 - val_loss: 0.5193 - val_accuracy: 0.7917\n",
            "Epoch 1145/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3993 - accuracy: 0.8142 - val_loss: 0.5191 - val_accuracy: 0.7917\n",
            "Epoch 1146/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3993 - accuracy: 0.8160 - val_loss: 0.5190 - val_accuracy: 0.7917\n",
            "Epoch 1147/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3990 - accuracy: 0.8212 - val_loss: 0.5192 - val_accuracy: 0.7917\n",
            "Epoch 1148/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3989 - accuracy: 0.8212 - val_loss: 0.5194 - val_accuracy: 0.7917\n",
            "Epoch 1149/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3990 - accuracy: 0.8160 - val_loss: 0.5195 - val_accuracy: 0.7917\n",
            "Epoch 1150/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3989 - accuracy: 0.8177 - val_loss: 0.5191 - val_accuracy: 0.7917\n",
            "Epoch 1151/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3994 - accuracy: 0.8177 - val_loss: 0.5192 - val_accuracy: 0.7917\n",
            "Epoch 1152/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3988 - accuracy: 0.8194 - val_loss: 0.5194 - val_accuracy: 0.7917\n",
            "Epoch 1153/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3988 - accuracy: 0.8212 - val_loss: 0.5194 - val_accuracy: 0.7917\n",
            "Epoch 1154/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3988 - accuracy: 0.8212 - val_loss: 0.5196 - val_accuracy: 0.7917\n",
            "Epoch 1155/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3989 - accuracy: 0.8177 - val_loss: 0.5198 - val_accuracy: 0.7917\n",
            "Epoch 1156/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3989 - accuracy: 0.8194 - val_loss: 0.5202 - val_accuracy: 0.7917\n",
            "Epoch 1157/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3989 - accuracy: 0.8194 - val_loss: 0.5203 - val_accuracy: 0.7917\n",
            "Epoch 1158/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3987 - accuracy: 0.8177 - val_loss: 0.5199 - val_accuracy: 0.7917\n",
            "Epoch 1159/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3989 - accuracy: 0.8160 - val_loss: 0.5199 - val_accuracy: 0.7865\n",
            "Epoch 1160/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3987 - accuracy: 0.8177 - val_loss: 0.5200 - val_accuracy: 0.7917\n",
            "Epoch 1161/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3986 - accuracy: 0.8229 - val_loss: 0.5204 - val_accuracy: 0.7917\n",
            "Epoch 1162/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3986 - accuracy: 0.8212 - val_loss: 0.5203 - val_accuracy: 0.7917\n",
            "Epoch 1163/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3988 - accuracy: 0.8194 - val_loss: 0.5204 - val_accuracy: 0.7917\n",
            "Epoch 1164/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3986 - accuracy: 0.8212 - val_loss: 0.5205 - val_accuracy: 0.7917\n",
            "Epoch 1165/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3987 - accuracy: 0.8212 - val_loss: 0.5204 - val_accuracy: 0.7917\n",
            "Epoch 1166/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3987 - accuracy: 0.8160 - val_loss: 0.5204 - val_accuracy: 0.7917\n",
            "Epoch 1167/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3987 - accuracy: 0.8177 - val_loss: 0.5206 - val_accuracy: 0.7917\n",
            "Epoch 1168/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3986 - accuracy: 0.8177 - val_loss: 0.5203 - val_accuracy: 0.7917\n",
            "Epoch 1169/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3984 - accuracy: 0.8177 - val_loss: 0.5204 - val_accuracy: 0.7917\n",
            "Epoch 1170/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3984 - accuracy: 0.8212 - val_loss: 0.5208 - val_accuracy: 0.7917\n",
            "Epoch 1171/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3985 - accuracy: 0.8194 - val_loss: 0.5209 - val_accuracy: 0.7917\n",
            "Epoch 1172/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3985 - accuracy: 0.8229 - val_loss: 0.5215 - val_accuracy: 0.7917\n",
            "Epoch 1173/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3986 - accuracy: 0.8194 - val_loss: 0.5216 - val_accuracy: 0.7917\n",
            "Epoch 1174/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3986 - accuracy: 0.8212 - val_loss: 0.5214 - val_accuracy: 0.7917\n",
            "Epoch 1175/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3984 - accuracy: 0.8194 - val_loss: 0.5215 - val_accuracy: 0.7917\n",
            "Epoch 1176/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3985 - accuracy: 0.8212 - val_loss: 0.5220 - val_accuracy: 0.7917\n",
            "Epoch 1177/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3984 - accuracy: 0.8194 - val_loss: 0.5217 - val_accuracy: 0.7917\n",
            "Epoch 1178/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3985 - accuracy: 0.8177 - val_loss: 0.5216 - val_accuracy: 0.7917\n",
            "Epoch 1179/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3983 - accuracy: 0.8194 - val_loss: 0.5221 - val_accuracy: 0.7917\n",
            "Epoch 1180/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3984 - accuracy: 0.8194 - val_loss: 0.5220 - val_accuracy: 0.7917\n",
            "Epoch 1181/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3982 - accuracy: 0.8177 - val_loss: 0.5219 - val_accuracy: 0.7969\n",
            "Epoch 1182/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3982 - accuracy: 0.8194 - val_loss: 0.5220 - val_accuracy: 0.7917\n",
            "Epoch 1183/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3982 - accuracy: 0.8212 - val_loss: 0.5222 - val_accuracy: 0.7917\n",
            "Epoch 1184/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3983 - accuracy: 0.8177 - val_loss: 0.5222 - val_accuracy: 0.7969\n",
            "Epoch 1185/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3982 - accuracy: 0.8212 - val_loss: 0.5223 - val_accuracy: 0.7969\n",
            "Epoch 1186/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3981 - accuracy: 0.8212 - val_loss: 0.5224 - val_accuracy: 0.7969\n",
            "Epoch 1187/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3982 - accuracy: 0.8160 - val_loss: 0.5225 - val_accuracy: 0.7969\n",
            "Epoch 1188/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3981 - accuracy: 0.8177 - val_loss: 0.5223 - val_accuracy: 0.7969\n",
            "Epoch 1189/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3982 - accuracy: 0.8177 - val_loss: 0.5226 - val_accuracy: 0.7969\n",
            "Epoch 1190/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3980 - accuracy: 0.8160 - val_loss: 0.5224 - val_accuracy: 0.7969\n",
            "Epoch 1191/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3981 - accuracy: 0.8177 - val_loss: 0.5223 - val_accuracy: 0.7969\n",
            "Epoch 1192/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3979 - accuracy: 0.8177 - val_loss: 0.5222 - val_accuracy: 0.7969\n",
            "Epoch 1193/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3982 - accuracy: 0.8264 - val_loss: 0.5227 - val_accuracy: 0.7969\n",
            "Epoch 1194/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3979 - accuracy: 0.8194 - val_loss: 0.5229 - val_accuracy: 0.7969\n",
            "Epoch 1195/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3979 - accuracy: 0.8212 - val_loss: 0.5229 - val_accuracy: 0.7969\n",
            "Epoch 1196/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3979 - accuracy: 0.8160 - val_loss: 0.5226 - val_accuracy: 0.7969\n",
            "Epoch 1197/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3981 - accuracy: 0.8194 - val_loss: 0.5227 - val_accuracy: 0.7969\n",
            "Epoch 1198/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3980 - accuracy: 0.8160 - val_loss: 0.5227 - val_accuracy: 0.7969\n",
            "Epoch 1199/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3978 - accuracy: 0.8194 - val_loss: 0.5230 - val_accuracy: 0.7969\n",
            "Epoch 1200/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3979 - accuracy: 0.8194 - val_loss: 0.5230 - val_accuracy: 0.7969\n",
            "Epoch 1201/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3979 - accuracy: 0.8194 - val_loss: 0.5231 - val_accuracy: 0.7969\n",
            "Epoch 1202/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3977 - accuracy: 0.8212 - val_loss: 0.5232 - val_accuracy: 0.7969\n",
            "Epoch 1203/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3977 - accuracy: 0.8194 - val_loss: 0.5232 - val_accuracy: 0.7969\n",
            "Epoch 1204/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3977 - accuracy: 0.8177 - val_loss: 0.5234 - val_accuracy: 0.7969\n",
            "Epoch 1205/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3980 - accuracy: 0.8212 - val_loss: 0.5235 - val_accuracy: 0.7969\n",
            "Epoch 1206/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3978 - accuracy: 0.8142 - val_loss: 0.5234 - val_accuracy: 0.7969\n",
            "Epoch 1207/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3977 - accuracy: 0.8194 - val_loss: 0.5236 - val_accuracy: 0.7969\n",
            "Epoch 1208/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3978 - accuracy: 0.8142 - val_loss: 0.5235 - val_accuracy: 0.7969\n",
            "Epoch 1209/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3978 - accuracy: 0.8194 - val_loss: 0.5239 - val_accuracy: 0.7969\n",
            "Epoch 1210/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3978 - accuracy: 0.8160 - val_loss: 0.5236 - val_accuracy: 0.7969\n",
            "Epoch 1211/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3976 - accuracy: 0.8177 - val_loss: 0.5236 - val_accuracy: 0.7969\n",
            "Epoch 1212/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3978 - accuracy: 0.8177 - val_loss: 0.5238 - val_accuracy: 0.7969\n",
            "Epoch 1213/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3976 - accuracy: 0.8194 - val_loss: 0.5234 - val_accuracy: 0.7969\n",
            "Epoch 1214/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3977 - accuracy: 0.8160 - val_loss: 0.5236 - val_accuracy: 0.7969\n",
            "Epoch 1215/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3975 - accuracy: 0.8194 - val_loss: 0.5236 - val_accuracy: 0.7969\n",
            "Epoch 1216/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3974 - accuracy: 0.8194 - val_loss: 0.5239 - val_accuracy: 0.7969\n",
            "Epoch 1217/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3975 - accuracy: 0.8194 - val_loss: 0.5243 - val_accuracy: 0.7969\n",
            "Epoch 1218/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3976 - accuracy: 0.8194 - val_loss: 0.5246 - val_accuracy: 0.7969\n",
            "Epoch 1219/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3977 - accuracy: 0.8177 - val_loss: 0.5244 - val_accuracy: 0.7969\n",
            "Epoch 1220/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3975 - accuracy: 0.8194 - val_loss: 0.5242 - val_accuracy: 0.7969\n",
            "Epoch 1221/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3976 - accuracy: 0.8160 - val_loss: 0.5244 - val_accuracy: 0.7969\n",
            "Epoch 1222/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3972 - accuracy: 0.8212 - val_loss: 0.5248 - val_accuracy: 0.7969\n",
            "Epoch 1223/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3975 - accuracy: 0.8160 - val_loss: 0.5247 - val_accuracy: 0.7969\n",
            "Epoch 1224/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3974 - accuracy: 0.8194 - val_loss: 0.5248 - val_accuracy: 0.7969\n",
            "Epoch 1225/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3974 - accuracy: 0.8194 - val_loss: 0.5250 - val_accuracy: 0.7969\n",
            "Epoch 1226/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3976 - accuracy: 0.8194 - val_loss: 0.5254 - val_accuracy: 0.7969\n",
            "Epoch 1227/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3973 - accuracy: 0.8177 - val_loss: 0.5255 - val_accuracy: 0.7969\n",
            "Epoch 1228/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3972 - accuracy: 0.8160 - val_loss: 0.5254 - val_accuracy: 0.7969\n",
            "Epoch 1229/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3972 - accuracy: 0.8177 - val_loss: 0.5255 - val_accuracy: 0.7969\n",
            "Epoch 1230/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3973 - accuracy: 0.8212 - val_loss: 0.5254 - val_accuracy: 0.7969\n",
            "Epoch 1231/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3976 - accuracy: 0.8177 - val_loss: 0.5251 - val_accuracy: 0.7969\n",
            "Epoch 1232/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3975 - accuracy: 0.8247 - val_loss: 0.5255 - val_accuracy: 0.7969\n",
            "Epoch 1233/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3971 - accuracy: 0.8194 - val_loss: 0.5257 - val_accuracy: 0.7969\n",
            "Epoch 1234/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3972 - accuracy: 0.8194 - val_loss: 0.5255 - val_accuracy: 0.7969\n",
            "Epoch 1235/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3973 - accuracy: 0.8177 - val_loss: 0.5260 - val_accuracy: 0.7969\n",
            "Epoch 1236/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3972 - accuracy: 0.8177 - val_loss: 0.5258 - val_accuracy: 0.7969\n",
            "Epoch 1237/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3970 - accuracy: 0.8177 - val_loss: 0.5257 - val_accuracy: 0.7969\n",
            "Epoch 1238/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3970 - accuracy: 0.8194 - val_loss: 0.5260 - val_accuracy: 0.7969\n",
            "Epoch 1239/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3970 - accuracy: 0.8194 - val_loss: 0.5261 - val_accuracy: 0.7969\n",
            "Epoch 1240/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3971 - accuracy: 0.8194 - val_loss: 0.5262 - val_accuracy: 0.7969\n",
            "Epoch 1241/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3973 - accuracy: 0.8160 - val_loss: 0.5262 - val_accuracy: 0.7969\n",
            "Epoch 1242/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3969 - accuracy: 0.8212 - val_loss: 0.5259 - val_accuracy: 0.7969\n",
            "Epoch 1243/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3971 - accuracy: 0.8194 - val_loss: 0.5262 - val_accuracy: 0.7969\n",
            "Epoch 1244/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3969 - accuracy: 0.8160 - val_loss: 0.5263 - val_accuracy: 0.7969\n",
            "Epoch 1245/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3970 - accuracy: 0.8177 - val_loss: 0.5263 - val_accuracy: 0.7969\n",
            "Epoch 1246/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3969 - accuracy: 0.8194 - val_loss: 0.5262 - val_accuracy: 0.7969\n",
            "Epoch 1247/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3970 - accuracy: 0.8194 - val_loss: 0.5264 - val_accuracy: 0.7969\n",
            "Epoch 1248/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3971 - accuracy: 0.8194 - val_loss: 0.5263 - val_accuracy: 0.7917\n",
            "Epoch 1249/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3968 - accuracy: 0.8177 - val_loss: 0.5262 - val_accuracy: 0.7917\n",
            "Epoch 1250/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3970 - accuracy: 0.8194 - val_loss: 0.5268 - val_accuracy: 0.7969\n",
            "Epoch 1251/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3968 - accuracy: 0.8194 - val_loss: 0.5270 - val_accuracy: 0.7969\n",
            "Epoch 1252/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3970 - accuracy: 0.8194 - val_loss: 0.5269 - val_accuracy: 0.7969\n",
            "Epoch 1253/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3969 - accuracy: 0.8194 - val_loss: 0.5270 - val_accuracy: 0.7969\n",
            "Epoch 1254/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3967 - accuracy: 0.8177 - val_loss: 0.5273 - val_accuracy: 0.7969\n",
            "Epoch 1255/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3968 - accuracy: 0.8177 - val_loss: 0.5275 - val_accuracy: 0.7969\n",
            "Epoch 1256/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3967 - accuracy: 0.8194 - val_loss: 0.5278 - val_accuracy: 0.7969\n",
            "Epoch 1257/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3968 - accuracy: 0.8194 - val_loss: 0.5282 - val_accuracy: 0.7969\n",
            "Epoch 1258/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3967 - accuracy: 0.8212 - val_loss: 0.5278 - val_accuracy: 0.7969\n",
            "Epoch 1259/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3965 - accuracy: 0.8194 - val_loss: 0.5280 - val_accuracy: 0.7969\n",
            "Epoch 1260/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3965 - accuracy: 0.8194 - val_loss: 0.5283 - val_accuracy: 0.7969\n",
            "Epoch 1261/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3965 - accuracy: 0.8229 - val_loss: 0.5283 - val_accuracy: 0.7969\n",
            "Epoch 1262/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3966 - accuracy: 0.8177 - val_loss: 0.5282 - val_accuracy: 0.7969\n",
            "Epoch 1263/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3965 - accuracy: 0.8194 - val_loss: 0.5281 - val_accuracy: 0.7969\n",
            "Epoch 1264/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3967 - accuracy: 0.8194 - val_loss: 0.5278 - val_accuracy: 0.7969\n",
            "Epoch 1265/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3964 - accuracy: 0.8177 - val_loss: 0.5279 - val_accuracy: 0.7969\n",
            "Epoch 1266/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3965 - accuracy: 0.8194 - val_loss: 0.5284 - val_accuracy: 0.7969\n",
            "Epoch 1267/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3962 - accuracy: 0.8194 - val_loss: 0.5282 - val_accuracy: 0.7969\n",
            "Epoch 1268/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3964 - accuracy: 0.8194 - val_loss: 0.5283 - val_accuracy: 0.7969\n",
            "Epoch 1269/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3963 - accuracy: 0.8177 - val_loss: 0.5282 - val_accuracy: 0.7969\n",
            "Epoch 1270/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3964 - accuracy: 0.8194 - val_loss: 0.5283 - val_accuracy: 0.7969\n",
            "Epoch 1271/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3965 - accuracy: 0.8194 - val_loss: 0.5284 - val_accuracy: 0.7917\n",
            "Epoch 1272/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3965 - accuracy: 0.8177 - val_loss: 0.5285 - val_accuracy: 0.7917\n",
            "Epoch 1273/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3963 - accuracy: 0.8194 - val_loss: 0.5286 - val_accuracy: 0.7969\n",
            "Epoch 1274/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3965 - accuracy: 0.8177 - val_loss: 0.5287 - val_accuracy: 0.7969\n",
            "Epoch 1275/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3965 - accuracy: 0.8194 - val_loss: 0.5285 - val_accuracy: 0.7917\n",
            "Epoch 1276/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3965 - accuracy: 0.8177 - val_loss: 0.5287 - val_accuracy: 0.7969\n",
            "Epoch 1277/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3964 - accuracy: 0.8177 - val_loss: 0.5289 - val_accuracy: 0.7969\n",
            "Epoch 1278/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3962 - accuracy: 0.8194 - val_loss: 0.5289 - val_accuracy: 0.7917\n",
            "Epoch 1279/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3964 - accuracy: 0.8212 - val_loss: 0.5293 - val_accuracy: 0.7969\n",
            "Epoch 1280/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3961 - accuracy: 0.8160 - val_loss: 0.5292 - val_accuracy: 0.7969\n",
            "Epoch 1281/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3962 - accuracy: 0.8194 - val_loss: 0.5292 - val_accuracy: 0.7969\n",
            "Epoch 1282/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3961 - accuracy: 0.8194 - val_loss: 0.5292 - val_accuracy: 0.7969\n",
            "Epoch 1283/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3963 - accuracy: 0.8194 - val_loss: 0.5292 - val_accuracy: 0.7917\n",
            "Epoch 1284/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3962 - accuracy: 0.8194 - val_loss: 0.5293 - val_accuracy: 0.7969\n",
            "Epoch 1285/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3964 - accuracy: 0.8177 - val_loss: 0.5292 - val_accuracy: 0.7917\n",
            "Epoch 1286/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3962 - accuracy: 0.8177 - val_loss: 0.5294 - val_accuracy: 0.7917\n",
            "Epoch 1287/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3963 - accuracy: 0.8177 - val_loss: 0.5297 - val_accuracy: 0.7969\n",
            "Epoch 1288/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3962 - accuracy: 0.8194 - val_loss: 0.5296 - val_accuracy: 0.7917\n",
            "Epoch 1289/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3959 - accuracy: 0.8194 - val_loss: 0.5300 - val_accuracy: 0.7969\n",
            "Epoch 1290/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3960 - accuracy: 0.8194 - val_loss: 0.5300 - val_accuracy: 0.7917\n",
            "Epoch 1291/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3959 - accuracy: 0.8194 - val_loss: 0.5298 - val_accuracy: 0.7917\n",
            "Epoch 1292/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3960 - accuracy: 0.8194 - val_loss: 0.5297 - val_accuracy: 0.7917\n",
            "Epoch 1293/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3960 - accuracy: 0.8177 - val_loss: 0.5298 - val_accuracy: 0.7917\n",
            "Epoch 1294/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3960 - accuracy: 0.8194 - val_loss: 0.5298 - val_accuracy: 0.7917\n",
            "Epoch 1295/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3959 - accuracy: 0.8194 - val_loss: 0.5301 - val_accuracy: 0.7917\n",
            "Epoch 1296/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3959 - accuracy: 0.8177 - val_loss: 0.5299 - val_accuracy: 0.7917\n",
            "Epoch 1297/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3962 - accuracy: 0.8142 - val_loss: 0.5304 - val_accuracy: 0.7969\n",
            "Epoch 1298/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3959 - accuracy: 0.8160 - val_loss: 0.5304 - val_accuracy: 0.7917\n",
            "Epoch 1299/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3960 - accuracy: 0.8194 - val_loss: 0.5303 - val_accuracy: 0.7917\n",
            "Epoch 1300/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3958 - accuracy: 0.8177 - val_loss: 0.5307 - val_accuracy: 0.7917\n",
            "Epoch 1301/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3959 - accuracy: 0.8194 - val_loss: 0.5304 - val_accuracy: 0.7917\n",
            "Epoch 1302/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3957 - accuracy: 0.8194 - val_loss: 0.5306 - val_accuracy: 0.7917\n",
            "Epoch 1303/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3958 - accuracy: 0.8212 - val_loss: 0.5309 - val_accuracy: 0.7917\n",
            "Epoch 1304/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3959 - accuracy: 0.8212 - val_loss: 0.5310 - val_accuracy: 0.7917\n",
            "Epoch 1305/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3955 - accuracy: 0.8177 - val_loss: 0.5312 - val_accuracy: 0.7969\n",
            "Epoch 1306/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3956 - accuracy: 0.8212 - val_loss: 0.5310 - val_accuracy: 0.7969\n",
            "Epoch 1307/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3959 - accuracy: 0.8177 - val_loss: 0.5308 - val_accuracy: 0.7917\n",
            "Epoch 1308/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3959 - accuracy: 0.8194 - val_loss: 0.5307 - val_accuracy: 0.7917\n",
            "Epoch 1309/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3957 - accuracy: 0.8194 - val_loss: 0.5307 - val_accuracy: 0.7917\n",
            "Epoch 1310/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3956 - accuracy: 0.8194 - val_loss: 0.5305 - val_accuracy: 0.7917\n",
            "Epoch 1311/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3956 - accuracy: 0.8194 - val_loss: 0.5308 - val_accuracy: 0.7917\n",
            "Epoch 1312/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3956 - accuracy: 0.8142 - val_loss: 0.5314 - val_accuracy: 0.7917\n",
            "Epoch 1313/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3957 - accuracy: 0.8194 - val_loss: 0.5309 - val_accuracy: 0.7917\n",
            "Epoch 1314/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3955 - accuracy: 0.8229 - val_loss: 0.5309 - val_accuracy: 0.7917\n",
            "Epoch 1315/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3955 - accuracy: 0.8125 - val_loss: 0.5314 - val_accuracy: 0.7917\n",
            "Epoch 1316/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3953 - accuracy: 0.8212 - val_loss: 0.5316 - val_accuracy: 0.7917\n",
            "Epoch 1317/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3955 - accuracy: 0.8177 - val_loss: 0.5317 - val_accuracy: 0.7917\n",
            "Epoch 1318/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3954 - accuracy: 0.8177 - val_loss: 0.5319 - val_accuracy: 0.7917\n",
            "Epoch 1319/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3957 - accuracy: 0.8194 - val_loss: 0.5318 - val_accuracy: 0.7917\n",
            "Epoch 1320/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3956 - accuracy: 0.8194 - val_loss: 0.5315 - val_accuracy: 0.7917\n",
            "Epoch 1321/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3955 - accuracy: 0.8212 - val_loss: 0.5316 - val_accuracy: 0.7917\n",
            "Epoch 1322/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3953 - accuracy: 0.8194 - val_loss: 0.5318 - val_accuracy: 0.7917\n",
            "Epoch 1323/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3955 - accuracy: 0.8212 - val_loss: 0.5316 - val_accuracy: 0.7917\n",
            "Epoch 1324/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3955 - accuracy: 0.8212 - val_loss: 0.5315 - val_accuracy: 0.7917\n",
            "Epoch 1325/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3953 - accuracy: 0.8212 - val_loss: 0.5312 - val_accuracy: 0.7917\n",
            "Epoch 1326/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3955 - accuracy: 0.8177 - val_loss: 0.5315 - val_accuracy: 0.7917\n",
            "Epoch 1327/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3956 - accuracy: 0.8194 - val_loss: 0.5318 - val_accuracy: 0.7917\n",
            "Epoch 1328/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3952 - accuracy: 0.8194 - val_loss: 0.5322 - val_accuracy: 0.7917\n",
            "Epoch 1329/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3955 - accuracy: 0.8194 - val_loss: 0.5321 - val_accuracy: 0.7917\n",
            "Epoch 1330/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3953 - accuracy: 0.8177 - val_loss: 0.5318 - val_accuracy: 0.7917\n",
            "Epoch 1331/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3954 - accuracy: 0.8160 - val_loss: 0.5319 - val_accuracy: 0.7917\n",
            "Epoch 1332/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3954 - accuracy: 0.8177 - val_loss: 0.5320 - val_accuracy: 0.7917\n",
            "Epoch 1333/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3954 - accuracy: 0.8177 - val_loss: 0.5322 - val_accuracy: 0.7917\n",
            "Epoch 1334/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3951 - accuracy: 0.8194 - val_loss: 0.5323 - val_accuracy: 0.7917\n",
            "Epoch 1335/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3952 - accuracy: 0.8229 - val_loss: 0.5325 - val_accuracy: 0.7917\n",
            "Epoch 1336/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3952 - accuracy: 0.8177 - val_loss: 0.5325 - val_accuracy: 0.7917\n",
            "Epoch 1337/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3952 - accuracy: 0.8194 - val_loss: 0.5323 - val_accuracy: 0.7917\n",
            "Epoch 1338/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3951 - accuracy: 0.8194 - val_loss: 0.5325 - val_accuracy: 0.7917\n",
            "Epoch 1339/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3952 - accuracy: 0.8212 - val_loss: 0.5324 - val_accuracy: 0.7917\n",
            "Epoch 1340/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3950 - accuracy: 0.8194 - val_loss: 0.5325 - val_accuracy: 0.7917\n",
            "Epoch 1341/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3954 - accuracy: 0.8229 - val_loss: 0.5328 - val_accuracy: 0.7917\n",
            "Epoch 1342/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3950 - accuracy: 0.8212 - val_loss: 0.5327 - val_accuracy: 0.7917\n",
            "Epoch 1343/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3949 - accuracy: 0.8177 - val_loss: 0.5329 - val_accuracy: 0.7917\n",
            "Epoch 1344/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3952 - accuracy: 0.8194 - val_loss: 0.5329 - val_accuracy: 0.7917\n",
            "Epoch 1345/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3950 - accuracy: 0.8229 - val_loss: 0.5329 - val_accuracy: 0.7917\n",
            "Epoch 1346/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3948 - accuracy: 0.8194 - val_loss: 0.5327 - val_accuracy: 0.7917\n",
            "Epoch 1347/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3949 - accuracy: 0.8177 - val_loss: 0.5330 - val_accuracy: 0.7917\n",
            "Epoch 1348/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3951 - accuracy: 0.8177 - val_loss: 0.5334 - val_accuracy: 0.7917\n",
            "Epoch 1349/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3950 - accuracy: 0.8194 - val_loss: 0.5330 - val_accuracy: 0.7917\n",
            "Epoch 1350/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3951 - accuracy: 0.8194 - val_loss: 0.5329 - val_accuracy: 0.7917\n",
            "Epoch 1351/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3950 - accuracy: 0.8194 - val_loss: 0.5327 - val_accuracy: 0.7917\n",
            "Epoch 1352/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3949 - accuracy: 0.8229 - val_loss: 0.5330 - val_accuracy: 0.7917\n",
            "Epoch 1353/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3950 - accuracy: 0.8177 - val_loss: 0.5331 - val_accuracy: 0.7917\n",
            "Epoch 1354/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3947 - accuracy: 0.8229 - val_loss: 0.5333 - val_accuracy: 0.7917\n",
            "Epoch 1355/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3947 - accuracy: 0.8177 - val_loss: 0.5336 - val_accuracy: 0.7917\n",
            "Epoch 1356/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3950 - accuracy: 0.8194 - val_loss: 0.5334 - val_accuracy: 0.7917\n",
            "Epoch 1357/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3948 - accuracy: 0.8160 - val_loss: 0.5336 - val_accuracy: 0.7917\n",
            "Epoch 1358/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3947 - accuracy: 0.8194 - val_loss: 0.5333 - val_accuracy: 0.7917\n",
            "Epoch 1359/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3947 - accuracy: 0.8177 - val_loss: 0.5338 - val_accuracy: 0.7917\n",
            "Epoch 1360/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3946 - accuracy: 0.8212 - val_loss: 0.5336 - val_accuracy: 0.7917\n",
            "Epoch 1361/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3946 - accuracy: 0.8142 - val_loss: 0.5343 - val_accuracy: 0.7917\n",
            "Epoch 1362/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3949 - accuracy: 0.8212 - val_loss: 0.5339 - val_accuracy: 0.7917\n",
            "Epoch 1363/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3949 - accuracy: 0.8194 - val_loss: 0.5336 - val_accuracy: 0.7917\n",
            "Epoch 1364/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3948 - accuracy: 0.8177 - val_loss: 0.5338 - val_accuracy: 0.7917\n",
            "Epoch 1365/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3952 - accuracy: 0.8212 - val_loss: 0.5340 - val_accuracy: 0.7917\n",
            "Epoch 1366/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3948 - accuracy: 0.8142 - val_loss: 0.5344 - val_accuracy: 0.7917\n",
            "Epoch 1367/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3947 - accuracy: 0.8212 - val_loss: 0.5343 - val_accuracy: 0.7917\n",
            "Epoch 1368/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3950 - accuracy: 0.8212 - val_loss: 0.5342 - val_accuracy: 0.7917\n",
            "Epoch 1369/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3947 - accuracy: 0.8212 - val_loss: 0.5343 - val_accuracy: 0.7917\n",
            "Epoch 1370/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3947 - accuracy: 0.8177 - val_loss: 0.5340 - val_accuracy: 0.7917\n",
            "Epoch 1371/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3944 - accuracy: 0.8229 - val_loss: 0.5341 - val_accuracy: 0.7917\n",
            "Epoch 1372/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3946 - accuracy: 0.8212 - val_loss: 0.5342 - val_accuracy: 0.7917\n",
            "Epoch 1373/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3946 - accuracy: 0.8194 - val_loss: 0.5345 - val_accuracy: 0.7917\n",
            "Epoch 1374/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3946 - accuracy: 0.8194 - val_loss: 0.5343 - val_accuracy: 0.7917\n",
            "Epoch 1375/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3945 - accuracy: 0.8194 - val_loss: 0.5340 - val_accuracy: 0.7917\n",
            "Epoch 1376/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3945 - accuracy: 0.8160 - val_loss: 0.5345 - val_accuracy: 0.7917\n",
            "Epoch 1377/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3944 - accuracy: 0.8212 - val_loss: 0.5348 - val_accuracy: 0.7917\n",
            "Epoch 1378/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3946 - accuracy: 0.8212 - val_loss: 0.5344 - val_accuracy: 0.7917\n",
            "Epoch 1379/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3945 - accuracy: 0.8177 - val_loss: 0.5345 - val_accuracy: 0.7917\n",
            "Epoch 1380/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3945 - accuracy: 0.8212 - val_loss: 0.5349 - val_accuracy: 0.7917\n",
            "Epoch 1381/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3944 - accuracy: 0.8212 - val_loss: 0.5347 - val_accuracy: 0.7917\n",
            "Epoch 1382/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3945 - accuracy: 0.8194 - val_loss: 0.5351 - val_accuracy: 0.7917\n",
            "Epoch 1383/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3945 - accuracy: 0.8177 - val_loss: 0.5354 - val_accuracy: 0.7917\n",
            "Epoch 1384/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3945 - accuracy: 0.8212 - val_loss: 0.5354 - val_accuracy: 0.7917\n",
            "Epoch 1385/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3944 - accuracy: 0.8212 - val_loss: 0.5354 - val_accuracy: 0.7917\n",
            "Epoch 1386/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3945 - accuracy: 0.8212 - val_loss: 0.5351 - val_accuracy: 0.7917\n",
            "Epoch 1387/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3944 - accuracy: 0.8229 - val_loss: 0.5353 - val_accuracy: 0.7917\n",
            "Epoch 1388/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3945 - accuracy: 0.8194 - val_loss: 0.5353 - val_accuracy: 0.7917\n",
            "Epoch 1389/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3941 - accuracy: 0.8229 - val_loss: 0.5352 - val_accuracy: 0.7917\n",
            "Epoch 1390/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3944 - accuracy: 0.8177 - val_loss: 0.5350 - val_accuracy: 0.7917\n",
            "Epoch 1391/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3943 - accuracy: 0.8160 - val_loss: 0.5353 - val_accuracy: 0.7917\n",
            "Epoch 1392/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3945 - accuracy: 0.8194 - val_loss: 0.5355 - val_accuracy: 0.7917\n",
            "Epoch 1393/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3942 - accuracy: 0.8194 - val_loss: 0.5354 - val_accuracy: 0.7917\n",
            "Epoch 1394/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3944 - accuracy: 0.8212 - val_loss: 0.5355 - val_accuracy: 0.7917\n",
            "Epoch 1395/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3944 - accuracy: 0.8194 - val_loss: 0.5357 - val_accuracy: 0.7917\n",
            "Epoch 1396/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3941 - accuracy: 0.8177 - val_loss: 0.5354 - val_accuracy: 0.7917\n",
            "Epoch 1397/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3941 - accuracy: 0.8194 - val_loss: 0.5356 - val_accuracy: 0.7917\n",
            "Epoch 1398/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3941 - accuracy: 0.8194 - val_loss: 0.5355 - val_accuracy: 0.7917\n",
            "Epoch 1399/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3942 - accuracy: 0.8212 - val_loss: 0.5360 - val_accuracy: 0.7917\n",
            "Epoch 1400/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3940 - accuracy: 0.8247 - val_loss: 0.5358 - val_accuracy: 0.7917\n",
            "Epoch 1401/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3942 - accuracy: 0.8194 - val_loss: 0.5355 - val_accuracy: 0.7917\n",
            "Epoch 1402/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3942 - accuracy: 0.8229 - val_loss: 0.5356 - val_accuracy: 0.7917\n",
            "Epoch 1403/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3939 - accuracy: 0.8212 - val_loss: 0.5356 - val_accuracy: 0.7917\n",
            "Epoch 1404/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3940 - accuracy: 0.8194 - val_loss: 0.5354 - val_accuracy: 0.7917\n",
            "Epoch 1405/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3941 - accuracy: 0.8177 - val_loss: 0.5360 - val_accuracy: 0.7917\n",
            "Epoch 1406/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3942 - accuracy: 0.8177 - val_loss: 0.5356 - val_accuracy: 0.7917\n",
            "Epoch 1407/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3939 - accuracy: 0.8212 - val_loss: 0.5355 - val_accuracy: 0.7865\n",
            "Epoch 1408/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3940 - accuracy: 0.8160 - val_loss: 0.5361 - val_accuracy: 0.7917\n",
            "Epoch 1409/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3943 - accuracy: 0.8194 - val_loss: 0.5364 - val_accuracy: 0.7917\n",
            "Epoch 1410/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3940 - accuracy: 0.8212 - val_loss: 0.5362 - val_accuracy: 0.7917\n",
            "Epoch 1411/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3940 - accuracy: 0.8212 - val_loss: 0.5362 - val_accuracy: 0.7865\n",
            "Epoch 1412/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3938 - accuracy: 0.8212 - val_loss: 0.5361 - val_accuracy: 0.7865\n",
            "Epoch 1413/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3939 - accuracy: 0.8177 - val_loss: 0.5363 - val_accuracy: 0.7865\n",
            "Epoch 1414/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3941 - accuracy: 0.8177 - val_loss: 0.5362 - val_accuracy: 0.7865\n",
            "Epoch 1415/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3941 - accuracy: 0.8160 - val_loss: 0.5362 - val_accuracy: 0.7865\n",
            "Epoch 1416/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3937 - accuracy: 0.8212 - val_loss: 0.5363 - val_accuracy: 0.7865\n",
            "Epoch 1417/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3937 - accuracy: 0.8212 - val_loss: 0.5361 - val_accuracy: 0.7865\n",
            "Epoch 1418/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3938 - accuracy: 0.8212 - val_loss: 0.5366 - val_accuracy: 0.7865\n",
            "Epoch 1419/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3938 - accuracy: 0.8212 - val_loss: 0.5369 - val_accuracy: 0.7917\n",
            "Epoch 1420/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3938 - accuracy: 0.8212 - val_loss: 0.5368 - val_accuracy: 0.7865\n",
            "Epoch 1421/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3937 - accuracy: 0.8212 - val_loss: 0.5366 - val_accuracy: 0.7865\n",
            "Epoch 1422/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3937 - accuracy: 0.8194 - val_loss: 0.5366 - val_accuracy: 0.7865\n",
            "Epoch 1423/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3935 - accuracy: 0.8229 - val_loss: 0.5364 - val_accuracy: 0.7865\n",
            "Epoch 1424/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3938 - accuracy: 0.8160 - val_loss: 0.5364 - val_accuracy: 0.7865\n",
            "Epoch 1425/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3937 - accuracy: 0.8212 - val_loss: 0.5369 - val_accuracy: 0.7865\n",
            "Epoch 1426/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3939 - accuracy: 0.8194 - val_loss: 0.5372 - val_accuracy: 0.7865\n",
            "Epoch 1427/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3939 - accuracy: 0.8194 - val_loss: 0.5373 - val_accuracy: 0.7865\n",
            "Epoch 1428/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3935 - accuracy: 0.8194 - val_loss: 0.5371 - val_accuracy: 0.7865\n",
            "Epoch 1429/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3939 - accuracy: 0.8194 - val_loss: 0.5369 - val_accuracy: 0.7865\n",
            "Epoch 1430/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3936 - accuracy: 0.8212 - val_loss: 0.5370 - val_accuracy: 0.7865\n",
            "Epoch 1431/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3937 - accuracy: 0.8177 - val_loss: 0.5367 - val_accuracy: 0.7865\n",
            "Epoch 1432/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3935 - accuracy: 0.8177 - val_loss: 0.5369 - val_accuracy: 0.7865\n",
            "Epoch 1433/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3936 - accuracy: 0.8194 - val_loss: 0.5372 - val_accuracy: 0.7865\n",
            "Epoch 1434/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3937 - accuracy: 0.8229 - val_loss: 0.5371 - val_accuracy: 0.7865\n",
            "Epoch 1435/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3934 - accuracy: 0.8194 - val_loss: 0.5375 - val_accuracy: 0.7865\n",
            "Epoch 1436/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3935 - accuracy: 0.8194 - val_loss: 0.5373 - val_accuracy: 0.7865\n",
            "Epoch 1437/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3937 - accuracy: 0.8194 - val_loss: 0.5376 - val_accuracy: 0.7865\n",
            "Epoch 1438/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3935 - accuracy: 0.8177 - val_loss: 0.5376 - val_accuracy: 0.7865\n",
            "Epoch 1439/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3936 - accuracy: 0.8194 - val_loss: 0.5375 - val_accuracy: 0.7865\n",
            "Epoch 1440/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3936 - accuracy: 0.8212 - val_loss: 0.5376 - val_accuracy: 0.7865\n",
            "Epoch 1441/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3934 - accuracy: 0.8160 - val_loss: 0.5378 - val_accuracy: 0.7865\n",
            "Epoch 1442/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3936 - accuracy: 0.8177 - val_loss: 0.5381 - val_accuracy: 0.7865\n",
            "Epoch 1443/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3937 - accuracy: 0.8229 - val_loss: 0.5378 - val_accuracy: 0.7865\n",
            "Epoch 1444/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3935 - accuracy: 0.8229 - val_loss: 0.5377 - val_accuracy: 0.7865\n",
            "Epoch 1445/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3937 - accuracy: 0.8177 - val_loss: 0.5379 - val_accuracy: 0.7865\n",
            "Epoch 1446/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3934 - accuracy: 0.8212 - val_loss: 0.5378 - val_accuracy: 0.7865\n",
            "Epoch 1447/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3935 - accuracy: 0.8194 - val_loss: 0.5379 - val_accuracy: 0.7865\n",
            "Epoch 1448/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3936 - accuracy: 0.8160 - val_loss: 0.5383 - val_accuracy: 0.7865\n",
            "Epoch 1449/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3934 - accuracy: 0.8177 - val_loss: 0.5379 - val_accuracy: 0.7865\n",
            "Epoch 1450/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3937 - accuracy: 0.8194 - val_loss: 0.5378 - val_accuracy: 0.7865\n",
            "Epoch 1451/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3934 - accuracy: 0.8177 - val_loss: 0.5376 - val_accuracy: 0.7865\n",
            "Epoch 1452/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3934 - accuracy: 0.8194 - val_loss: 0.5379 - val_accuracy: 0.7865\n",
            "Epoch 1453/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3933 - accuracy: 0.8177 - val_loss: 0.5385 - val_accuracy: 0.7865\n",
            "Epoch 1454/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3934 - accuracy: 0.8194 - val_loss: 0.5383 - val_accuracy: 0.7865\n",
            "Epoch 1455/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3934 - accuracy: 0.8212 - val_loss: 0.5383 - val_accuracy: 0.7865\n",
            "Epoch 1456/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3934 - accuracy: 0.8177 - val_loss: 0.5387 - val_accuracy: 0.7865\n",
            "Epoch 1457/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3934 - accuracy: 0.8177 - val_loss: 0.5387 - val_accuracy: 0.7865\n",
            "Epoch 1458/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3932 - accuracy: 0.8212 - val_loss: 0.5386 - val_accuracy: 0.7865\n",
            "Epoch 1459/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3933 - accuracy: 0.8212 - val_loss: 0.5384 - val_accuracy: 0.7865\n",
            "Epoch 1460/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3935 - accuracy: 0.8194 - val_loss: 0.5385 - val_accuracy: 0.7865\n",
            "Epoch 1461/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3934 - accuracy: 0.8177 - val_loss: 0.5390 - val_accuracy: 0.7865\n",
            "Epoch 1462/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3932 - accuracy: 0.8194 - val_loss: 0.5387 - val_accuracy: 0.7865\n",
            "Epoch 1463/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3936 - accuracy: 0.8160 - val_loss: 0.5385 - val_accuracy: 0.7865\n",
            "Epoch 1464/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3931 - accuracy: 0.8212 - val_loss: 0.5383 - val_accuracy: 0.7865\n",
            "Epoch 1465/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3933 - accuracy: 0.8160 - val_loss: 0.5387 - val_accuracy: 0.7865\n",
            "Epoch 1466/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3933 - accuracy: 0.8212 - val_loss: 0.5384 - val_accuracy: 0.7865\n",
            "Epoch 1467/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3933 - accuracy: 0.8177 - val_loss: 0.5381 - val_accuracy: 0.7865\n",
            "Epoch 1468/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3933 - accuracy: 0.8160 - val_loss: 0.5384 - val_accuracy: 0.7865\n",
            "Epoch 1469/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3931 - accuracy: 0.8177 - val_loss: 0.5385 - val_accuracy: 0.7865\n",
            "Epoch 1470/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3933 - accuracy: 0.8177 - val_loss: 0.5389 - val_accuracy: 0.7865\n",
            "Epoch 1471/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3933 - accuracy: 0.8160 - val_loss: 0.5392 - val_accuracy: 0.7865\n",
            "Epoch 1472/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3933 - accuracy: 0.8177 - val_loss: 0.5393 - val_accuracy: 0.7865\n",
            "Epoch 1473/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3936 - accuracy: 0.8212 - val_loss: 0.5390 - val_accuracy: 0.7865\n",
            "Epoch 1474/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3930 - accuracy: 0.8194 - val_loss: 0.5390 - val_accuracy: 0.7865\n",
            "Epoch 1475/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3931 - accuracy: 0.8194 - val_loss: 0.5392 - val_accuracy: 0.7865\n",
            "Epoch 1476/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3931 - accuracy: 0.8177 - val_loss: 0.5392 - val_accuracy: 0.7865\n",
            "Epoch 1477/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3929 - accuracy: 0.8160 - val_loss: 0.5394 - val_accuracy: 0.7865\n",
            "Epoch 1478/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3930 - accuracy: 0.8177 - val_loss: 0.5394 - val_accuracy: 0.7865\n",
            "Epoch 1479/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3929 - accuracy: 0.8177 - val_loss: 0.5397 - val_accuracy: 0.7865\n",
            "Epoch 1480/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3932 - accuracy: 0.8212 - val_loss: 0.5395 - val_accuracy: 0.7865\n",
            "Epoch 1481/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3928 - accuracy: 0.8177 - val_loss: 0.5397 - val_accuracy: 0.7865\n",
            "Epoch 1482/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3931 - accuracy: 0.8177 - val_loss: 0.5396 - val_accuracy: 0.7865\n",
            "Epoch 1483/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3929 - accuracy: 0.8177 - val_loss: 0.5395 - val_accuracy: 0.7865\n",
            "Epoch 1484/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3929 - accuracy: 0.8194 - val_loss: 0.5397 - val_accuracy: 0.7865\n",
            "Epoch 1485/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3929 - accuracy: 0.8177 - val_loss: 0.5401 - val_accuracy: 0.7865\n",
            "Epoch 1486/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3929 - accuracy: 0.8177 - val_loss: 0.5398 - val_accuracy: 0.7865\n",
            "Epoch 1487/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3928 - accuracy: 0.8212 - val_loss: 0.5397 - val_accuracy: 0.7865\n",
            "Epoch 1488/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3930 - accuracy: 0.8177 - val_loss: 0.5398 - val_accuracy: 0.7865\n",
            "Epoch 1489/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3928 - accuracy: 0.8160 - val_loss: 0.5400 - val_accuracy: 0.7865\n",
            "Epoch 1490/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3930 - accuracy: 0.8177 - val_loss: 0.5401 - val_accuracy: 0.7865\n",
            "Epoch 1491/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3929 - accuracy: 0.8177 - val_loss: 0.5402 - val_accuracy: 0.7865\n",
            "Epoch 1492/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3929 - accuracy: 0.8194 - val_loss: 0.5402 - val_accuracy: 0.7865\n",
            "Epoch 1493/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3929 - accuracy: 0.8177 - val_loss: 0.5405 - val_accuracy: 0.7865\n",
            "Epoch 1494/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3927 - accuracy: 0.8212 - val_loss: 0.5404 - val_accuracy: 0.7865\n",
            "Epoch 1495/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3931 - accuracy: 0.8247 - val_loss: 0.5401 - val_accuracy: 0.7865\n",
            "Epoch 1496/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3929 - accuracy: 0.8177 - val_loss: 0.5406 - val_accuracy: 0.7865\n",
            "Epoch 1497/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3930 - accuracy: 0.8194 - val_loss: 0.5400 - val_accuracy: 0.7865\n",
            "Epoch 1498/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3927 - accuracy: 0.8177 - val_loss: 0.5400 - val_accuracy: 0.7865\n",
            "Epoch 1499/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3927 - accuracy: 0.8160 - val_loss: 0.5402 - val_accuracy: 0.7865\n",
            "Epoch 1500/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3928 - accuracy: 0.8194 - val_loss: 0.5403 - val_accuracy: 0.7865\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_class_nn_supp = (model_supp.predict(X_test_norm) > 0.5).astype(\"int32\")\n",
        "y_pred_prob_nn_supp = model_supp.predict(X_test_norm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GtAu-3-kpFX_",
        "outputId": "819dc891-2d19-4051-8231-6146be1989ac"
      },
      "id": "GtAu-3-kpFX_",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 0s 4ms/step\n",
            "6/6 [==============================] - 0s 3ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_supp)))\n",
        "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_supp)))\n",
        "\n",
        "plot_roc(y_test, y_pred_prob_nn_supp, 'NN')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "id": "ZU7yjeTMpP12",
        "outputId": "f6b6cb17-c07e-4938-888a-241961736cd4"
      },
      "id": "ZU7yjeTMpP12",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy is 0.786\n",
            "roc-auc is 0.814\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqQAAAKqCAYAAADsTEzZAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABtz0lEQVR4nO3deVyU5f7/8Tcgi6CoJa6ZW4upHS1Nj6lHK5XKPHnSxCX3NTUrSnNfM0zTbHEtl1IRzMysPCppnjIty63NfclMRc0FBYEBrt8ffZmfyCKDwD3L6/l48NC5ue+ZD1wz8OZz3fc1XsYYIwAAAMAi3lYXAAAAAM9GIAUAAIClCKQAAACwFIEUAAAAliKQAgAAwFIEUgAAAFiKQAoAAABLEUgBAABgKQIpAAAALEUgBZCtadOmqVq1avLx8VHdunWtLgdOpEePHqpSpUqGbV5eXho/frzD97V48WJ5eXnpxx9/zJ/iPEjz5s1Vu3btG+537NgxeXl5afHixQVfFJAHBFI4rfRfUukfRYoUUcWKFdWjRw/9+eefWR5jjNGSJUv0r3/9SyVLllRgYKDuvfdeTZw4UfHx8dk+1ieffKLHHntMpUuXlp+fnypUqKAOHTpo06ZNuao1MTFRb775pho2bKgSJUooICBAd911lwYPHqwDBw7k6eu32oYNGzRs2DA1btxYixYt0muvvVagj9ejRw95eXnpH//4h7J6R2MvLy8NHjzYfjv9F6yXl5c+/vjjTPuPHz9eXl5eOnfuXIHWnVvp9aR/BAYGqmbNmho9erTi4uLs+2UVztKP9fb21h9//JHpvuPi4lS0aNFM36Nr7d27V15eXgoICNDFixfz/etzNmvXrs1TOAZgjSJWFwDcyMSJE1W1alUlJibqu+++0+LFi7Vlyxb98ssvCggIsO+Xmpqqzp07a8WKFWratKnGjx+vwMBAffPNN5owYYI++ugjffnllypbtqz9GGOMevXqpcWLF+u+++5TeHi4ypUrp1OnTumTTz7RI488om+//VYPPvhgtvWdO3dOjz76qHbs2KEnnnhCnTt3VrFixbR//35FRUVp/vz5Sk5OLtDvUUHYtGmTvL29tWDBAvn5+RXa4/78889atWqV2rVrl+tjJk6cqKeeekpeXl4FWFn+mDNnjooVK6YrV65ow4YNmjx5sjZt2qRvv/32hvX7+/tr+fLlGjZsWIbtq1atuuHjLl26VOXKldOFCxe0cuVK9enT56a+jqxcvXpVRYo4x6+VtWvXatasWYRSwEU4x08OIAePPfaY6tevL0nq06ePSpcurddff11r1qxRhw4d7PtNnTpVK1as0Msvv6xp06bZt/fr108dOnRQ27Zt1aNHD/33v/+1f2769OlavHixXnjhBc2YMSNDIBg1apSWLFlyw1+wPXr00K5du7Ry5cpMIWrSpEkaNWrUTX396VJSUpSWllZo4fDMmTMqWrRovj2eMUaJiYkqWrRotvsULVpUlSpVcihg1q1bV7t379Ynn3yip556Kl9qLUjt27dX6dKlJUkDBgxQu3bttGrVKn333Xdq1KhRjsc+/vjjWQbSyMhItW7dOstOsfT39z4yMlKdO3fW0aNHtWzZsgIJpNf+gYi8iY+PV1BQkNVlAIWOKXu4nKZNm0qSDh8+bN929epVTZs2TXfddZciIiIyHdOmTRt1795d69at03fffWc/JiIiQjVq1NAbb7yRZfjp2rWrGjRokG0t33//vb744gv17t07y46ev7+/3njjDfvt5s2bq3nz5pn2u/58vPTp6DfeeEMzZ85U9erV5e/vr127dqlIkSKaMGFCpvvYv3+/vLy89O6779q3Xbx4US+88IIqVaokf39/3XHHHXr99deVlpaW7dck/T09vmjRIsXHx9unmNPPPUtJSdGkSZPsNVWpUkUjR45UUlJShvuoUqWKnnjiCa1fv17169dX0aJFNW/evBwf19vbW6NHj9ZPP/2kTz75JMd903Xs2FF33XWXJk6cmOVUf27s2rVLjz32mIKDg1WsWDE98sgj9udJuvSp9G+//Vbh4eEKCQlRUFCQ/vOf/+js2bN5elxJevjhhyVJR48eveG+nTt31u7du7Vv3z77ttOnT2vTpk3q3Llztsd9++23OnbsmDp27KiOHTvq66+/1okTJ3Jd4+rVq1W7dm0FBASodu3a2Y7N9eeQ/v777xo4cKDuvvtuFS1aVLfeequefvppHTt2LMvjExIS1L9/f916660KDg5Wt27ddOHChUz7/fe//1XTpk0VFBSk4sWLq3Xr1vr111/tn+/Ro4dmzZplryn9I11aWppmzpypWrVqKSAgQGXLllX//v0zPdaPP/6o0NBQlS5dWkWLFlXVqlXVq1evG36/0p/7GzZsUN26dRUQEKCaNWtm6mSnP6f+97//aeDAgSpTpoxuu+02++dnz56tWrVqyd/fXxUqVNCgQYOyPd1ix44devDBB+11zp0794Z1StK+ffvUvn173XLLLQoICFD9+vW1Zs2aLOvcsmWLhgwZopCQEJUsWVL9+/dXcnKyLl68qG7duqlUqVIqVaqUhg0blufXIjwXgRQuJ/2XWalSpezbtmzZogsXLqhz587ZdjS7desmSfr888/tx5w/f16dO3eWj49PnmpJ/8HdtWvXPB1/I4sWLdI777yjfv36afr06SpfvryaNWumFStWZNo3OjpaPj4+evrppyX9/cu9WbNmWrp0qbp166a3335bjRs31ogRIxQeHp7j4y5ZskRNmzaVv7+/lixZYj8vV/q7Sz127Fjdf//9evPNN9WsWTNFRESoY8eOme5n//796tSpk1q2bKm33norVxdGde7cWXfeeWeuA6aPj49Gjx6tPXv25DrEXuvXX39V06ZNtWfPHg0bNkxjxozR0aNH1bx5c33//feZ9n/uuee0Z88ejRs3Ts8++6w+++yzbM/bzI30P6xuvfXWG+77r3/9S7fddpsiIyPt26Kjo1WsWDG1bt062+OWLVum6tWr64EHHlCbNm0UGBio5cuX56q+DRs2qF27dvLy8lJERITatm2rnj175uoCpB9++EFbt25Vx44d9fbbb2vAgAHauHGjmjdvroSEhEz7Dx48WHv37tX48ePVrVs3LVu2TG3bts3wPFiyZIlat26tYsWK6fXXX9eYMWP022+/qUmTJvafDf3791fLli3t+6d/pOvfv7+GDh2qxo0b66233lLPnj21bNkyhYaGymazSfp7hqBVq1Y6duyYhg8frnfeeUddunTJ9IdKdg4ePKiwsDA99thjioiIUJEiRfT0008rJiYm074DBw7Ub7/9prFjx2r48OGS/j5veNCgQapQoYKmT5+udu3aad68eWrVqpW9xnQXLlzQ448/rnr16mnq1Km67bbb9Oyzz2rhwoU51vjrr7/qn//8p/bu3avhw4dr+vTpCgoKUtu2bbN8LT333HM6ePCgJkyYoH//+9+aP3++xowZozZt2ig1NVWvvfaamjRpomnTpmX4fgO5YgAntWjRIiPJfPnll+bs2bPmjz/+MCtXrjQhISHG39/f/PHHH/Z9Z86caSSZTz75JNv7O3/+vJFknnrqKWOMMW+99dYNj7mR//znP0aSuXDhQq72b9asmWnWrFmm7d27dzeVK1e23z569KiRZIKDg82ZM2cy7Dtv3jwjyfz8888ZttesWdM8/PDD9tuTJk0yQUFB5sCBAxn2Gz58uPHx8THHjx/Psdbu3buboKCgDNt2795tJJk+ffpk2P7yyy8bSWbTpk32bZUrVzaSzLp163J8nKwe74MPPjCSzKpVq+yfl2QGDRpkv53+PZo2bZpJSUkxd955p6lTp45JS0szxhgzbtw4I8mcPXs2x8dt27at8fPzM4cPH7ZvO3nypClevLj517/+Zd+W/nxs0aKF/TGMMebFF180Pj4+5uLFizk+Tno9+/fvN2fPnjVHjx418+bNM/7+/qZs2bImPj4+w+P88MMPmY49e/asefnll80dd9xh/9wDDzxgevbsmeX3yBhjkpOTza233mpGjRpl39a5c2dTp06dHOtNV7duXVO+fPkMX9+GDRuMpAzP2fTHHzdunP12QkJCpvvbtm2bkWQ+/PBD+7b0r7levXomOTnZvn3q1KlGkvn000+NMcZcvnzZlCxZ0vTt2zfDfZ4+fdqUKFEiw/ZBgwaZrH7FffPNN0aSWbZsWYbt69aty7D9k08+yTQOuZX+3P/444/t2y5dumTKly9v7rvvvkxfd5MmTUxKSop9+5kzZ4yfn59p1aqVSU1NtW9/9913jSSzcOFC+7ZmzZoZSWb69On2bUlJSaZu3bqmTJky9u9n+utl0aJF9v0eeeQRc++995rExET7trS0NPPggw+aO++8M1OdoaGhGZ77jRo1Ml5eXmbAgAH2bSkpKea2227L8ucckBM6pHB6LVq0UEhIiCpVqqT27dsrKChIa9asyTC1dfnyZUlS8eLFs72f9M+lX9Gc/m9Ox9xIftxHTtq1a6eQkJAM25566ikVKVJE0dHR9m2//PKLfvvtN4WFhdm3ffTRR2ratKlKlSqlc+fO2T9atGih1NRUff311w7Xs3btWknK1GF96aWXJElffPFFhu1Vq1ZVaGiow4/TpUuXPHdJV69enevHSU1N1YYNG9S2bVtVq1bNvr18+fLq3LmztmzZkuEKeOnvc5Kvnf5t2rSpUlNT9fvvv+fqMe+++26FhISoatWq6t+/v+644w598cUXCgwMzNXxnTt31qFDh/TDDz/Y/81puv6///2v/vrrL3Xq1Mm+rVOnTtqzZ0+Gae6snDp1Srt371b37t1VokQJ+/aWLVuqZs2aN6z12vOFbTab/vrrL91xxx0qWbKkdu7cmWn/fv36ydfX13772WefVZEiRezPu5iYGF28eFGdOnXK8Jz28fFRw4YN9dVXX92wpo8++kglSpRQy5YtM9xHvXr1VKxYMft9lCxZUtLfMyrXdyRzo0KFCvrPf/5jv51+CsKuXbt0+vTpDPv27ds3wyzNl19+qeTkZL3wwgvy9vbOsF9wcHCm11mRIkXUv39/+20/Pz/1799fZ86c0Y4dO7Ks7/z589q0aZM6dOigy5cv278Pf/31l0JDQ3Xw4MFMq5n07t07w3O/YcOGMsaod+/e9m0+Pj6qX7++jhw5kptvE2BHIIXTmzVrlmJiYrRy5Uo9/vjjOnfunPz9/TPskx4I04NpVq4PrcHBwTc85kby4z5yUrVq1UzbSpcurUceeSTDtH10dLSKFCmS4aKegwcPat26dQoJCcnw0aJFC0l/T0k66vfff5e3t7fuuOOODNvLlSunkiVLZgplWdWfG+kBc/fu3bkOmF26dNEdd9zh0LmkZ8+eVUJCgu6+++5Mn7vnnnuUlpaWaZml22+/PcPt9FNHsjrXMSsff/yxYmJitHnzZh06dEi//PKL6tWrl6tjJem+++5TjRo1FBkZqWXLlqlcuXL281CzsnTpUlWtWlX+/v46dOiQDh06pOrVqyswMFDLli3L8bHSx/POO+/M9LmsvmfXu3r1qsaOHWs/h7l06dIKCQnRxYsXdenSpUz7X/84xYoVU/ny5e1T8QcPHpT093m31z+vN2zYkKvn9MGDB3Xp0iWVKVMm031cuXLFfh/NmjVTu3btNGHCBJUuXVpPPvmkFi1alOlc6ezccccdmc5Lv+uuuyQp0zm0179O0r/v13+P/fz8VK1atUyvswoVKmS6ECq7x0p36NAhGWM0ZsyYTN+HcePGScr8M+L65376HymVKlXKtD23rwcgHVfZw+k1aNDAfpV927Zt1aRJE3Xu3Fn79+9XsWLFJP0dHiTpp59+Utu2bbO8n59++kmS7J2dGjVqSPp7maHsjrmRa+8j/WKrnHh5eWUZllJTU7PcP7sr0jt27KiePXtq9+7dqlu3rlasWKFHHnnEfvW29PeFGy1btsx0RXa69F9YeZHb5ZVyuqL+Rrp06aJJkyZp4sSJuRqf9BDbo0cPffrpp3l+3Nw8TlZyG4L/9a9/ZRinvOjcubPmzJmj4sWLKywsLEMX7VpxcXH67LPPlJiYmGWojIyM1OTJkwtsuaznnntOixYt0gsvvKBGjRqpRIkS8vLyUseOHW94YV1W0o9ZsmSJypUrl+nzuVlyKi0tTWXKlMk2jKfPSHh5eWnlypX67rvv9Nlnn2n9+vXq1auXpk+fru+++87+syc/3MzrJK/Sv5cvv/xytrMY1//hmd1zP6vtuX09AOkIpHApPj4+ioiI0EMPPaR3333XfgFAkyZNVLJkSUVGRmrUqFFZ/oD88MMPJUlPPPGE/ZhSpUpp+fLlGjlyZJ4ubGrTpo0iIiK0dOnSXAXSUqVKZTmVldvp3nRt27ZV//797dP2Bw4c0IgRIzLsU716dV25csXeEc0PlStXVlpamg4ePGj/I0CSYmNjdfHiRVWuXDnfHisvAfOZZ57Rq6++ar/o4kZCQkIUGBio/fv3Z/rcvn375O3tnan74ww6d+6ssWPH6tSpUzlePLJq1SolJiZqzpw5mULw/v37NXr0aH377bdq0qRJlsenj2d6Z/L6429k5cqV6t69u6ZPn27flpiYmO2V4gcPHtRDDz1kv33lyhWdOnVKjz/+uKS/n9OSVKZMmRs+r7ML2dWrV9eXX36pxo0b5yoI/vOf/9Q///lPTZ48WZGRkerSpYuioqJuuGxWegfy2jrS3yTj+ne4ul76933//v0ZTiVJTk7W0aNHM33tJ0+ezLRc1I0eK/1+fX198/VnBJBXTNnD5TRv3lwNGjTQzJkzlZiYKEkKDAzUyy+/rP3792e57ucXX3yhxYsXKzQ0VP/85z/tx7zyyivau3evXnnllSz/ol+6dKm2b9+ebS2NGjXSo48+qvfffz/LqeXk5GS9/PLL9tvVq1fXvn37MiwTtGfPHn377be5/vqlv89vCw0N1YoVKxQVFSU/P79MXcQOHTpo27ZtWr9+fabjL168qJSUFIceU5I9GMycOTPD9hkzZkhSjld658UzzzyjO+64I8tlrrJy7VT/9UvXZLd/q1at9Omnn2aY2oyNjVVkZKSaNGliPy3DmVSvXl0zZ85UREREjsuSLV26VNWqVdOAAQPUvn37DB8vv/yyihUrluO0ffny5VW3bl198MEHGabYY2Ji9Ntvv92wTh8fn0yvq3feeSfbGYH58+dnOF9zzpw5SklJ0WOPPSZJCg0NVXBwsF577bUsz+u89nWVHs6uD78dOnRQamqqJk2alOn4lJQU+/4XLlzIVHv6KhG5mbY/efJkhivV4+Li9OGHH6pu3bpZdnev1aJFC/n5+entt9/OUMOCBQt06dKlTK+zlJSUDEuqJScna968eQoJCcn2dJAyZcqoefPmmjdvnk6dOpXp8zezlBmQF3RI4ZKGDh2qp59+WosXL9aAAQMkScOHD9euXbv0+uuva9u2bWrXrp2KFi2qLVu2aOnSpbrnnnv0wQcfZLqfX3/9VdOnT9dXX32l9u3bq1y5cjp9+rRWr16t7du3a+vWrTnW8uGHH6pVq1Z66qmn1KZNGz3yyCMKCgrSwYMHFRUVpVOnTtnXIu3Vq5dmzJih0NBQ9e7dW2fOnNHcuXNVq1atTBfP3EhYWJieeeYZzZ49W6GhofaLMK792tasWaMnnnhCPXr0UL169RQfH6+ff/5ZK1eu1LFjxxyeOq5Tp466d++u+fPn6+LFi2rWrJm2b9+uDz74QG3bts3Q3coPPj4+GjVqlHr27JnrY9Kn+nfv3p2r/V999VXFxMSoSZMmGjhwoIoUKaJ58+YpKSlJU6dOzWPlBe/555/P8fMnT57UV199pSFDhmT5eX9/f4WGhuqjjz7S22+/neFiomtFRESodevWatKkiXr16qXz58/rnXfeUa1atXTlypUca3jiiSe0ZMkSlShRQjVr1tS2bdv05ZdfZrvEVXJysh555BF16NBB+/fv1+zZs9WkSRN7tzs4OFhz5sxR165ddf/996tjx44KCQnR8ePH9cUXX6hx48b2dXjTg9iQIUMUGhoqHx8fdezYUc2aNVP//v0VERGh3bt3q1WrVvL19dXBgwf10Ucf6a233lL79u31wQcfaPbs2frPf/6j6tWr6/Lly3rvvfcUHBxs/8MsJ3fddZd69+6tH374QWXLltXChQsVGxurRYsW3fDYkJAQjRgxQhMmTNCjjz6qf//73/bvxwMPPKBnnnkmw/4VKlTQ66+/rmPHjumuu+5SdHS0du/erfnz52c7rtLf5+c3adJE9957r/r27atq1aopNjZW27Zt04kTJ7Rnz54b1grkG2su7gduLKvlb9Klpqaa6tWrm+rVq2dYLiU1NdUsWrTING7c2AQHB5uAgABTq1YtM2HCBHPlypVsH2vlypWmVatW5pZbbjFFihQx5cuXN2FhYWbz5s25qjUhIcG88cYb5oEHHjDFihUzfn5+5s477zTPPfecOXToUIZ9ly5daqpVq2b8/PxM3bp1zfr167Nd9mnatGnZPmZcXJwpWrSokWSWLl2a5T6XL182I0aMMHfccYfx8/MzpUuXNg8++KB54403Miyvk5Wsln0yxhibzWYmTJhgqlatanx9fU2lSpXMiBEjMiwdY8zfS9+0bt06x8fI7eNVr149x2Wfrpf+3FEuln0yxpidO3ea0NBQU6xYMRMYGGgeeughs3Xr1izv8/rn41dffWUkma+++irHx8jtMlQ3WvYpJ9d+j6ZPn24kmY0bN2a7/+LFizMsq5Sdjz/+2Nxzzz3G39/f1KxZ06xatSrTczb98a9d9unChQumZ8+epnTp0qZYsWImNDTU7Nu3z1SuXNl0794909f8v//9z/Tr18+UKlXKFCtWzHTp0sX89ddfmer56quvTGhoqClRooQJCAgw1atXNz169DA//vijfZ+UlBTz3HPPmZCQEOPl5ZVpCaj58+ebevXqmaJFi5rixYube++91wwbNsycPHnSGPP3c6JTp07m9ttvN/7+/qZMmTLmiSeeyPAY2Ul/7q9fv9784x//MP7+/qZGjRrmo48+yrBfTj/jjPl7macaNWoYX19fU7ZsWfPss89mWmKuWbNmplatWubHH380jRo1MgEBAaZy5crm3XffzbBfVss+GWPM4cOHTbdu3Uy5cuWMr6+vqVixonniiSfMypUrb1hnds/L7F7LQE68jOHMYwAA8kuVKlVUu3Zt+5twALgxziEFAACApQikAAAAsBSBFAAAAJbiHFIAAABYig4pAAAALEUgBQAAgKVcYmH8tLQ0nTx5UsWLFy+w91wGAABA3hljdPnyZVWoUEHe3o71PF0ikJ48edIp308aAAAAGf3xxx+67bbbHDrGJQJp8eLFJf39BV77vtI2m00bNmywv/Ub3A9j7BkYZ8/AOLs/xtgzZDfOcXFxqlSpkj23OcLhQPr1119r2rRp2rFjh06dOqVPPvlEbdu2zfGYzZs3Kzw8XL/++qsqVaqk0aNHq0ePHrl+zPRp+uDg4EyBNDAwUMHBwTzx3RRj7BkYZ8/AOLs/xtgz3Gic83J6pcMXNcXHx6tOnTqaNWtWrvY/evSoWrdurYceeki7d+/WCy+8oD59+mj9+vUOFwsAAAD343CH9LHHHtNjjz2W6/3nzp2rqlWravr06ZKke+65R1u2bNGbb76p0NBQRx8eAAAAhcQYo4SEhAzbbDabEhMTlZ9L2Rf4OaTbtm1TixYtMmwLDQ3VCy+8kO0xSUlJSkpKst+Oi4uT9Pc3wGaz2ben///abXAvjLFnYJw9A+Ps/hhj92KMUfPmzbVt27YsP3/mzBmVLFnSfvtmxr3AA+np06dVtmzZDNvKli2ruLg4Xb16VUWLFs10TEREhCZMmJBp+4YNGxQYGJhpe0xMTP4VDKfEGHsGxtkzMM7ujzF2D4mJidmGUUnatGmTAgIC7Lev76Q6wimvsh8xYoTCw8Ptt9Ov2mrVqlWmi5piYmLUsmVLTp52U4yxZ2CcPQPj7P4YY/cSHx9v//+JEyd06tQphYeHa9asWfrtt9/0xBNPyM/Pz75P+ox2XhR4IC1XrpxiY2MzbIuNjVVwcHCW3VFJ8vf3l7+/f6btvr6+WT7Bs9sO98EYewbG2TMwzu6PMXYP145hiRIltGPHDkVHR6t06dI6cuSI/Pz8MuxzM2Ne4IG0UaNGWrt2bYZtMTExatSoUUE/NAAAAPJBr169tGLFCkkFc46ww8s+XblyRbt379bu3bsl/b2s0+7du3X8+HFJf0+3d+vWzb7/gAEDdOTIEQ0bNkz79u3T7NmztWLFCr344ov58xUAAACgQE2ZMqVA79/hQPrjjz/qvvvu03333SdJCg8P13333aexY8dKkk6dOmUPp5JUtWpVffHFF4qJiVGdOnU0ffp0vf/++yz5BAAA4MQOHDhg///1F6jnN4en7Js3b57julOLFy/O8phdu3Y5+lAAAACwwK+//prhAvOC5pRX2QMAgMKV1QLojkpfMD0+Pp6Lmlzc0qVL9e6776p27dqF8ngEUgAAPJwxRk2aNNHWrVutLgVOpKDPG72Ww+eQAgAA95KQkEAYRbYaN26c5RsT5Sc6pAAAwC42NlZBQUF5OtZms2n9+vUKDQ1lyt7FnDt3TomJiQoICFDp0qUzfC4wMFBeXl4F+vgEUgAAYBcUFHRTgTQgIEBBQUEEUheye/duDR06VJ9//nmWb0xUGJiyBwAA8FDJycmaNGmSoqOjLQujEh1SAAAAj7Rz507Fx8dr5cqVBT4lfyN0SAEAADzMjh07NHz4cNWuXdvyMCrRIQUAAPAoaWlpOnHihFasWKGSJUtaXY4kAikAAC4rPxazl6T4+Ph8qAau4IcfftDs2bO1aNEiq0vJgEAKAIALYjF7OOrIkSMaM2aMoqOjrS4lE84hBQDABRXEYvaFsQA6rLFr1y7dcsst+vjjj1WiRAmry8mEDikAAC7uZhazv1ZhLICOwrdt2zZNnDhR0dHR+fI8KQgEUgAAXNzNLGYP97du3TpFR0crODjY6lKyRSAFAABwQ1u3btXOnTs1YcIEq0u5IQIpAACAm9m2bZsmT56sqKgoq0vJFQIpAACAGzl9+rQqVKig6OhoFStWzOpycoWr7AEAANzE119/rb59+6pixYouE0YlOqQAALiE6xfBZzF7XC8+Pl6zZs1SVFSUihRxrYjnWtUCAOCBWAQfN7J582YFBgY65aL3ucGUPQAATi6nRfBZzB5fffWVZsyYodq1a1tdSp7RIQUAwIVcvwg+i9l7tpSUFF2+fFlRUVEu/YcJgRQAABfCIvhI9+WXX2rVqlWaPXu21aXcNAIpAACAi/nll1/07rvvavny5VaXki84hxQAAMCFbN26VbfffruioqJUtGhRq8vJFwRSAAAAF7F+/Xq98cYb8vPzU0BAgNXl5Bum7AEAKCTXryWaW6w5Cunv58+2bdsUGRnpVmFUIpACAFAoWEsUN2Pt2rU6efKkxo8fb3UpBYJACgBAIchpLdHcYs1Rz7R+/XotWrRIS5cutbqUAkMgBQCgkF2/lmhuseao5/njjz90zz33aOnSpfL397e6nAJDIAUAoJCxlihyY82aNYqMjNTy5cvd/g8RrrIHAABwMufPn9eqVav04Ycfun0YleiQAgAAOJXVq1eratWqWrx4sdWlFBo6pAAAAE5i1apVio6OVs2aNa0upVARSAEAAJxAcnKy/Pz89OGHH8rX19fqcgoVU/YA4EbyuvB6YbDZbEpMTFR8fLzH/bKVWNweOVu5cqW+//57TZs2zepSLEEgBQA3wcLrgGv67rvvtHr1ao86Z/R6TNkDgJvIj4XXUfBY3B7X+vLLL1WrVi0tXrxYRYp4bp/Qc79yAHBjeV14vSDZbDatX79eoaGhHjlln47F7ZFu+fLl+u9//6vmzZt7dBiVCKQA4JacceF1m82mgIAABQUFeXQgBSQpNTVVR48e1cKFCz0+jEoEUgAAgEK1bNkyeXl5aeTIkVaX4jQ4hxQAAKCQREdHa+PGjQoLC7O6FKdChxQAAKAQHDlyRI0bN1b79u3l4+NjdTlOhQ4pAABAAVu8eLGmTJmi2267jTCaBTqkAOACcrPgPQuvA87p1KlT+uGHHzR37lyrS3FaBFIAcHIseA+4rg8++ECNGjXSrFmzrC7FqTFlDwBOztEF71l4HXAO77//vrZt26Y77rjD6lKcHh1SAHAhuVnwnoXXAeslJibqtttuU69eveTtTf/vRgikAOBCnHHBewAZzZs3T7GxsRo7dqzVpbgMAikAAEA+iYmJ0c8//6x33nnH6lJcCoEUAAAgH3z66adq2bKlWrRowWkzDuKkBgAAgJs0a9Ysbdq0SUWLFiWM5gGBFAAA4CYkJycrMTFRM2fOJIzmEVP2ADxSbhaadxYseA84r7feektVqlTRSy+9ZHUpLo1ACsDjsNA8gPwwb948HT9+XEOGDLG6FJdHIAXgcRxdaN5ZsOA94Dz27dunNm3aqHz58kzT5wMCKQCPlpuF5p0FC94DzmH69Ok6e/aspkyZYnUpboNACsCjsdA8AEccPnxY58+fV0REhNWluBWusgcAAMiFmTNnys/PT5MnT2a2Ip/RIQUAALiBKVOm6PLly7rtttusLsUtEUgBAAByEB8fr4YNG6p58+Z0RgsIgRSA27t+zVHW9QSQW6+++qqCg4NZ2qmAEUgBuDXWHAWQVytXrpTNZtNzzz1ndSluj0AKwK3ltOYo63oCyM7y5cvVrl07tW/f3upSPAKBFIDHuH7NUdb1BJCV8ePHy9vbW35+flaX4jEIpAA8BmuOAshJ+vnm5cuXV//+/a0ux6OwDikAAPB4xhiNHTtW27dvJ4xagEAKAAA83pQpUxQYGKiHHnrI6lI8ElP2AADAYxlj9PPPP6tPnz4KCQmxuhyPRYcUAAB4JGOMRowYofXr1xNGLUaHFIDLun7B+6ywCD6A7Pz8888KCQnRSy+9ZHUpHo8OKQCXlL7gfbFixXL8KFu2rNWlAnAyxhhNmDBB5cuXJ4w6CQIpAJeU04L3WWERfADS32F06NChCg4OZpreiTBlD8DlXb/gfVZYBB+AMUaXL1/WU089pQcffNDqcnANAikAl8eC9wBuxBij8PBw3X///eratavV5eA6TNkDAAC3t2jRIlWrVo0w6qTokAIAALdljNHChQvVo0cP+fj4WF0OskGHFAAAuCVjjIYMGaLk5GTCqJOjQwoAANyOMUaXLl1So0aN1LlzZ6vLwQ0QSAE4JDeL0TvKZrMpMTFR8fHx8vX1zdUxLHgPIDtpaWkaPHiwevXqRRh1EQRSALmWvhi9I+t/AkBhGz58uO677z7Vr1/f6lKQSwRSALnm6GL0hYEF7wGkS0tL086dOzV8+HDdcsstVpcDBxBIAeRJbhajzy2bzab169crNDQ011P26VjwHoD0dxgdMGCAGjVqRGfUBRFIAeRJfi5Gb7PZFBAQoKCgIIcDKQBI0vfff69GjRqpZ8+eVpeCPGDZJwAA4LJSU1P18ssvq1atWoRRF0YgBQAALiktLU39+vVTnTp1FBwcbHU5uAlM2QMAAJeTmpqqy5cva+DAgapXr57V5eAm0SEFAAAuJTU1Vb1799Y333xDGHUTdEgBN5efC9mzGD0AZ/Duu++qVatWatOmjdWlIJ8QSAE3xkL2ANxJSkqK3nvvPQ0ZMoTl3twMU/aAGyuohexZjB5AYUtJSVHPnj11yy23EEbdEB1SwEPk50L2LEYPoDClpaXpwoUL6tChA9P0bopACniI/FzIHgAKi81mU48ePTRmzBjCqBtjyh4AADit5557Tk899ZRq1KhhdSkoQHRIAQCA07HZbNq5c6emTp3KovcegA4pAABwKsnJyXrmmWd06tQpwqiHoEMKAACcyjfffKPOnTvrySeftLoUFBICKQAAcArJycl68cUXNX36dAUEBFhdDgoRU/YAAMByNptNzzzzjB577DHCqAeiQwoAACyVlJSkhIQEjR07VrVr17a6HFiADikAALBMYmKiOnfurD179hBGPRiBFAAAWObNN99Unz591Lx5c6tLgYWYsgcAAIUuMTFRCxYs0PDhw3krYtAhBQAAhSsxMVGdOnXSnXfeSRiFJDqkAACgEKWmpur8+fMaMmSIHnroIavLgZOgQwoAAApFQkKCnnrqKaWkpBBGkQGBFAAAFIp+/frp+eef1+233251KXAyTNkDAIAClZCQoN27d2vevHkKCgqyuhw4ITqkAACgwMTHxyssLEw2m40wimwRSAEAQIH56quv9PLLL6tZs2ZWlwInlqdAOmvWLFWpUkUBAQFq2LChtm/fnuP+M2fO1N13362iRYuqUqVKevHFF5WYmJinggEAgPO7cuWK+vbtq0cffZQwihtyOJBGR0crPDxc48aN086dO1WnTh2FhobqzJkzWe4fGRmp4cOHa9y4cdq7d68WLFig6OhojRw58qaLBwAAzufq1avq2LGjunfvriJFuFwFN+ZwIJ0xY4b69u2rnj17qmbNmpo7d64CAwO1cOHCLPffunWrGjdurM6dO6tKlSpq1aqVOnXqdMOuKgAAcD1Xr15VUlKSZsyYoSZNmlhdDlyEQ3+2JCcna8eOHRoxYoR9m7e3t1q0aKFt27ZlecyDDz6opUuXavv27WrQoIGOHDmitWvXqmvXrtk+TlJSkpKSkuy34+LiJEk2m002m82+Pf3/126De2GMb871rxdn/T4yzp6BcXZ/58+f17Rp01SpUiU1aNCAsXZT2b2Wb2a8HQqk586dU2pqqsqWLZthe9myZbVv374sj+ncubPOnTunJk2ayBijlJQUDRgwIMcp+4iICE2YMCHT9g0bNigwMDDT9piYGEe+DLggxjhvrj1Xe/369QoICLCwmhtjnD0D4+y+li9frg4dOujcuXNau3at1eWggF3/Wk5ISMjzfRX4iR2bN2/Wa6+9ptmzZ6thw4Y6dOiQnn/+eU2aNEljxozJ8pgRI0YoPDzcfjsuLk6VKlVSq1atFBwcbN9us9kUExOjli1bytfXt6C/FFiAMb458fHx9v+HhoY67ZIrjLNnYJzd16VLl7R06VItXLiQMfYA2b2W02e088KhQFq6dGn5+PgoNjY2w/bY2FiVK1cuy2PGjBmjrl27qk+fPpKke++9V/Hx8erXr59GjRolb+/Mp7H6+/vL398/03ZfX98sn+DZbYf7YIzz5trvmSt8D12hRtw8xtm9XLp0Sc8884wmTpxoH1fG2DNcP843M+YOXdTk5+enevXqaePGjfZtaWlp2rhxoxo1apTlMQkJCZlCp4+PjyTJGONovQAAwEnYbDZdvHhRr776qho0aGB1OXBhDl9lHx4ervfee08ffPCB9u7dq2effVbx8fHq2bOnJKlbt24ZLnpq06aN5syZo6ioKB09elQxMTEaM2aM2rRpYw+mAADAtVy8eFFPPPGEAgMDVb9+favLgYtz+BzSsLAwnT17VmPHjtXp06dVt25drVu3zn6h0/HjxzN0REePHi0vLy+NHj1af/75p0JCQtSmTRtNnjw5/74KAABQaIwx6tWrlyZPnqyQkBCry4EbyNNFTYMHD9bgwYOz/NzmzZszPkCRIho3bpzGjRuXl4cCAABO5MKFC9q7d68iIyOdfuUOuA7eyx4AAOTK+fPnFRYWpoCAAMIo8hXv5wUAAHJl8+bNev3113XfffdZXQrcDIEUAADk6K+//tLQoUO1YMECeXl5WV0O3BBT9gAAIFuXLl1Sx44d9cILLxBGUWDokAIAgCydO3dOvr6+ev/991W5cmWry4Ebo0MKAAAyOXv2rDp27KhTp04RRlHgCKQAACCTN998UzNnzlSNGjWsLgUegCl7AABgd+bMGa1YsUKvvfaa1aXAg9AhBQAAkqTY2Fh16tRJDz/8sNWlwMPQIQUAAEpKStKVK1f07rvv6p577rG6HHgYOqQAAHi4U6dOqXXr1goJCSGMwhIEUgAAPFhaWpr69u2rWbNmKTg42Opy4KGYsgcAwEOdPHlSv//+u1atWiU/Pz+ry4EHo0MKAIAH+vPPP/XMM8+odOnShFFYjkAKAIAH2rJli+bNm6c777zT6lIAAikAAJ7kxIkT6t27tzp06EAYhdPgHFIAADzEmTNn1K1bN7333nvy8vKyuhzAjkAKAIAHOHHihIKDg7Vs2TKVL1/e6nKADJiyBwDAzf3+++/q1q2bLl68SBiFU6JDCrgIY4wSEhIcOiY+Pr6AqgHgSt59910tXLhQt99+u9WlAFkikAIuwBijJk2aaOvWrVaXAsCFHDt2TGvXrtW0adOsLgXIEVP2gAtISEi4qTDauHFjBQYG5mNFAJzd0aNH1atXLz3xxBNWlwLcEB1SwMXExsYqKCjIoWMCAwO5ohbwIAkJCUpOTtbixYuZpodLIJACLiYoKMjhQArAcxw+fFj9+/fX559/roCAAKvLAXKFKXsAANyEzWbTc889p8WLFxNG4VLokAIA4AYOHjyoCxcuaM2aNSpShF/vcC10SAEAcHEHDx5U//79VbFiRcIoXBLPWgAAXJgxRj/88IOWLl2qChUqWF0OkCcEUsAJXb8IPgvcA8jK/v37NX36dM2fP9/qUoCbQiAFnAyL4APIjePHj2vgwIFatmyZ1aUAN41zSAEnk9Mi+CxwD0D6e2mnUqVKacWKFSpXrpzV5QA3jUAKOLHY2FhduXLF/vHNN9+wwD3g4X777Tf169dPiYmJuvXWW60uB8gXTNkDToxF8AFcb8GCBVq+fLlCQkKsLgXINwRSAABcwC+//KJt27Zp+vTpVpcC5Dum7AEAcHI///yzXnjhBbVt29bqUoACQYcUAAAndvnyZRUpUkRRUVEqXbq01eUABYIOKQAATmrPnj1q37697rzzTsIo3BqBFAAAJ5SQkKCRI0cqMjKStwOF2+MZDgCAk9m1a5ck6bPPPpO3N70juD+e5QAAOJGdO3fqlVdeUeXKlQmj8Bh0SAEAcBLGGP3222+Kjo5WqVKlrC4HKDQEUgAAnMCPP/6oRYsWadasWVaXAhQ6AikAABbbt2+fRo0apejoaKtLASzBySkAAFjo119/VcWKFfXRRx+pZMmSVpcDWIJACgCARb7//nu9/PLLMsYoODjY6nIAyzBlDxQiY4wSEhJy3Cc+Pr6QqgFgJWOMoqOjFR0dTRiFxyOQAoXEGKMmTZpo69atVpcCwGLbtm3T/v37NWPGDKtLAZwCU/ZAIUlISHAojDZu3FiBgYEFWBEAK2zdulWTJk1Su3btrC4FcBp0SAELxMbGKigoKMd9AgMD5eXlVUgVASgMFy5cUMmSJRUdHa3ixYtbXQ7gNAikgAWCgoJuGEgBuJdvvvlGb7zxhj755BPegQm4Dq8IAAAK2MWLFzVjxgwtW7aMMApkgQ4pAAAF6H//+59Kly6tVatWcRoOkA3+TAMAoIBs3rxZb7zxhqpUqUIYBXJAhxQAgAKQlpamP//8U9HR0ayYAdwAgRRuLzeL0RcGFrwHPMfGjRu1du1aTZ8+3epSAJdAIIVbYzF6AIVtx44devvttxUVFWV1KYDL4BxSuDVHF6MvDCx4D7ivH3/8UXfffbeioqJUtGhRq8sBXAYdUniM3CxGXxhY8B5wT+vXr9fcuXO1fPlyBQQEWF0O4FIIpPAYLEYPoKCkpaXpyy+/JIwCeUQgBQDgJqxbt04XL17UtGnTrC4FcFmcQwoAQB7997//1fvvv6///Oc/VpcCuDQCKQAAeXD27FlVqVJFy5Ytk7+/v9XlAC6NQAoAgIM+++wzPf/886pRowZhFMgHnEMKl5WbBe9ZjB5Afjt9+rSWL1+uxYsXs2IGkE8IpHBJLHgPwAqff/65atSooWXLlhFGgXzElD1ckqML3rMYPYCb9cknn2jp0qWqXLkyYRTIZ3RI4fJys+A9i9EDuBmpqalKTEzUkiVL5Ovra3U5gNshkMLlseA9gIL08ccfa/fu3Zo0aZLVpQBui0AKAEA2/ve//2nVqlVavHix1aUAbo1ACgBAFrZs2aJ69erpgw8+UJEi/LoEChIXNQEAcJ3o6GjNnz9fAQEBhFGgEBBIAQC4hs1m008//aSFCxcSRoFCwivNA+RmAXlnZbPZlJiYqPj4+AxXtrLgPYCCEBkZqWLFimny5MlWlwJ4FAKpm2MBeQDIneXLlysmJkbvv/++1aUAHodA6uYcXUDe1bDgPYD8cPLkSd1///3q0KGDfHx8rC4H8DgEUg+SmwXknY3NZtP69esVGhqa5WLULHgP4GZ9+OGH2rp1q+bOnWt1KYDHIpB6EFdcQN5msykgIEBBQUG8OwqAfHf06FF9++23mj17ttWlAB6Nq+wBAB5p2bJlKlKkiObNm8c0PWAxAikAwOMsXLhQ33zzjSpWrGh1KQBEIAUAeJiUlBQFBwdr9uzZ8vbm1yDgDDiHFADgMebPn6+LFy9q2LBhVpcC4BoEUgCAR/jss8+0Z88evfPOO1aXAuA6BFIAgNuLiYnRww8/rNatWzNNDzghXpUAALc2e/ZsrVmzRoGBgYRRwEnxygQAuK2EhARduHBBb7/9Nm+iATgxpuwBAG7p3Xff1T333KNRo0ZZXQqAG6BDCgBwO7Nnz9aRI0f08MMPW10KgFygQwoAcCvHjx9XaGionn32WabpARdBhxQA4DbefPNNzZ07V9WrVyeMAi6EDikAwC388ssvio2NVUREhNWlAHAQHVIAgMubM2eOypQpoylTptAZBVwQHVIAgEubOnWqLly4oJCQEKtLAZBHBFIAgMtKSkpSjRo11KZNGzqjgAsjkAIAXNJrr72mW2+9Vf3797e6FAA3iXNIAQAuZ8mSJUpMTFS/fv2sLgVAPqBDCgBwKWvWrNHTTz8tf39/pukBN0GHFADgMiZOnKhdu3YpICCAMAq4ETqkAACXcPHiRZUoUULPP/+81aUAyGd0SAEATs0Yo/Hjx+vAgQOEUcBNEUgBAE5t8uTJ8vX1VYMGDawuBUABYcoeAOCUjDE6fPiwunXrpttvv93qcgAUIDqkAACnY4zRqFGj9OmnnxJGAQ9AIAUAOJ3vv/9eJUuW1EsvvWR1KQAKAYEUAOA0jDGaMmWK7rnnHg0bNszqcgAUEgIpAMApGGP0yiuvyM/PTyVKlLC6HACFiIuaAACWM8bo6tWratGihVq1amV1OQAKGYEUAGApY4xeeuklNWzYUGFhYVaXA8ACTNkDACw1a9YsValShTAKeDA6pAAASxhj9NFHH2nAgAEqUoRfR4Any1OHNP2v2YCAADVs2FDbt2/Pcf+LFy9q0KBBKl++vPz9/XXXXXdp7dq1eSoYAOD6jDF6/vnndfbsWcIoAMc7pNHR0QoPD9fcuXPVsGFDzZw5U6Ghodq/f7/KlCmTaf/k5GS1bNlSZcqU0cqVK1WxYkX9/vvvKlmyZH7UDwBwQWfOnNF9992nnj17Wl0KACfgcId0xowZ6tu3r3r27KmaNWtq7ty5CgwM1MKFC7Pcf+HChTp//rxWr16txo0bq0qVKmrWrJnq1Klz08UDAFxLWlqaXnjhBf3111+EUQB2DgXS5ORk7dixQy1atPj/d+DtrRYtWmjbtm1ZHrNmzRo1atRIgwYNUtmyZVW7dm299tprSk1NvbnKAQAuZ/Hixapdu7Zq1qxpdSkAnIhDU/bnzp1TamqqypYtm2F72bJltW/fviyPOXLkiDZt2qQuXbpo7dq1OnTokAYOHCibzaZx48ZleUxSUpKSkpLst+Pi4iRJNptNNpvNvj39/9duQ0bXf79c7XvFGHsGxtn9paWl6bffflPbtm0VFhbGWLspXsueIbtxvplxL/AzydPS0lSmTBnNnz9fPj4+qlevnv78809NmzYt20AaERGhCRMmZNq+YcMGBQYGZtoeExOT73W7i8TERPv/169fr4CAAAuryTvG2DMwzu4pLS1N8+bN01133aVHHnmEcfYAjLFnuH6cExIS8nxfDgXS0qVLy8fHR7GxsRm2x8bGqly5clkeU758efn6+srHx8e+7Z577tHp06eVnJwsPz+/TMeMGDFC4eHh9ttxcXGqVKmSWrVqpeDgYPt2m82mmJgYtWzZUr6+vo58KW7LGJPhCREfH2//f2hoqIKCgqwoK88YY8/AOLu3jRs3ql27durSpQvj7OZ4LXuG7MY5fUY7LxwKpH5+fqpXr542btyotm3bSvr7L9+NGzdq8ODBWR7TuHFjRUZGKi0tTd7ef5+yeuDAAZUvXz7LMCpJ/v7+8vf3z7Td19c3yyd4dts9jTFGTZo00datW7P8vCt/n1y5duQe4+xe0tLSNG7cOI0cOVJFixa1T+cxzu6PMfYM14/zzYy5w1fZh4eH67333tMHH3ygvXv36tlnn1V8fLz9aslu3bppxIgR9v2fffZZnT9/Xs8//7wOHDigL774Qq+99poGDRqU56KRtYSEhGzDaOPGjbM83QEACkJqaqr69eunO+64Q0WLFrW6HABOzuFzSMPCwnT27FmNHTtWp0+fVt26dbVu3Tr7hU7Hjx+3d0IlqVKlSlq/fr1efPFF/eMf/1DFihX1/PPP65VXXsm/rwKZxMbGZpieDwwMlJeXl4UVAfAUqampunr1qrp3766mTZtaXQ4AF5Cni5oGDx6c7RT95s2bM21r1KiRvvvuu7w8FPIoKCjI5c4XBeD6UlNT1adPH4WFhenRRx+1uhwALiJPbx0KAEBWpk6dqhYtWhBGATiENxAGANy0lJQURUdHa9iwYRlWVQGA3KBDCgC4KSkpKerVq5d8fHwIowDyhA4pACDPjDE6deqUnnzySbVr187qcgC4KDqkLswYo/j4+AwfAFBYUlJS1L17d6WlpRFGAdwUOqQu6kaL4ANAQevfv7/+/e9/q3LlylaXAsDFEUhdFIvgA7CKzWbTgQMHNGXKFIWEhFhdDgA3QCB1AyyCD6Cw2Gw2devWTWFhYapVq5bV5QBwEwRSN8Ai+AAKy9q1axUWFqa2bdtaXQoAN0IgBQDcUHJyskaOHKkpU6aoSBF+dQDIX1xlDwDIUXJysp555hk1a9aMMAqgQPCTBQCQraSkJCUnJ2vo0KF64IEHrC4HgJuiQwoAyFJSUpK6dOmin376iTAKoEARSAEAWZo0aZJ69eqlxo0bW10KADfHlD0AIIPExERFR0dr0qRJLCEHoFDQIQUA2CUmJqpTp04qV64cYRRAoaFDCgCQ9PdbEp84cUIDBw5Uy5YtrS4HgAehQwoA0NWrV9W+fXsFBwcTRgEUOgIpAHg4Y4y6d++ugQMHqkyZMlaXA8ADMWUPAB4sISFBhw8f1vz581WyZEmrywHgoeiQAoCHio+PV1hYmM6dO0cYBWApOqQA4KE+++wzvfTSS2revLnVpQDwcARSAPAw8fHxGjVqlGbMmCFvbybKAFiPn0QA4EHSp+nbtWtHGAXgNOiQAoCHuHLliiQpIiJC9957r8XVAMD/x5/HAOABLl++rA4dOujw4cOEUQBOh0AKAB5gwoQJGj16tOrUqWN1KQCQCVP2AODG4uLitGrVKk2bNo33pgfgtOiQAoCbunTpkjp06KAaNWoQRgE4NTqkAOCG0tLS9Oeff2rChAlq2LCh1eUAQI7okLoIY4zi4+MzfABAVi5evKg2bdqoYsWKhFEALoEOqQswxqhJkybaunWr1aUAcHJpaWl65plnNH78eJUoUcLqcgAgVwikLiAhISHbMNq4cWMFBgYWckUAnNGFCxf0xx9/aPny5SpevLjV5QBArjFl72JiY2N15coV+8c333zDxQoAdOHCBYWFhSklJYUwCsDl0CF1MUFBQQoKCrK6DABOZs2aNZoyZYruv/9+q0sBAIcRSAHAhZ0/f17jx4/XW2+9xWwJAJfFlD0AuKgLFy6oY8eO6t27N2EUgEujQwoALuj8+fPy9fXVrFmzdOedd1pdDgDcFDqkAOBizp07pw4dOuj06dOEUQBugQ6pEzLGKCEhwX6bRfABXGvChAl68803CaMA3AaB1MmwCD6A7Jw5c0Zr167V22+/zTmjANwKU/ZOhkXwAWTlzJkz6tSpkxo0aEAYBeB26JA6sdjY2AxrjgYGBvKLCPBAKSkpOnXqlN555x3VrFnT6nIAIN/RIXVi6Yvgp38QRgHPc/r0abVu3Vp33XUXYRSA2yKQAoCTstls6t69u9566y0VLVrU6nIAoMAwZQ8ATujUqVP666+/9Mknn3DuOAC3R4cUAJzMyZMn1aVLF/n5+RFGAXgEOqQA4GTWrl2refPmsc4oAI9BILUYi+ADSPfnn39q6tSpeuutt6wuBQAKFYHUQiyCDyDdqVOn1LVrV82fP9/qUgCg0BFILcQi+ACkv5d2KlasmBYvXqzbb7/d6nIAoNBxUZOTiI2N1ZUrV+wf33zzDeuOAh7g+PHj6tSpk+Li4gijADwWHVInkb74PQDPEhERoYULF6pixYpWlwIAliGQAoAFfv/9d3399deaM2eO1aUAgOWYsgeAQnbs2DH17NlT//rXv6wuBQCcAoEUAApRcnKy/vrrLy1atEiVK1e2uhwAcAoEUgAoJEeOHNG///1v/eMf/yCMAsA1OIcUAArB1atX1b9/fy1cuFC+vr5WlwMAToVACgAF7NChQ7LZbPr888/l7+9vdTkA4HSYsgeAAnTo0CH1799fwcHBhFEAyAaBFAAK0MaNG/Xhhx+yzigA5IApewAoAAcOHNC8efM0ffp0q0sBAKdHIAWAfHbkyBE9++yzWrp0qdWlAIBLIJACQD46fvy4QkJCFBkZqbJly1pdDgC4BM4hBYB8snfvXvXs2VPJycmEUQBwAIEUAPKBMUZvvvmmIiMjdeutt1pdDgC4FKbsAeAm/frrr/rpp580f/58q0sBAJdEhxQAbsIvv/yi559/Xi1atLC6FABwWQRSAMijxMREJSQkaPny5QoJCbG6HABwWQRSAMiDn376Se3bt1f9+vUJowBwkziHFAAcdOnSJQ0dOlSRkZHy9ubvegC4WQRSAHDA7t27FRQUpM8//1y+vr5WlwMAboE/7QEgl3bt2qVhw4bp1ltvJYwCQD4ikAJALn3//feKiorSLbfcYnUpAOBWmLIHgBvYsWOHPvroI02ZMsXqUgDALRFIASAHv/zyi0aOHKno6GirSwEAt8WUPQBk4+DBg7r99tsVHR2tkiVLWl0OALgtAikAZGH79u0aPHiwvLy8CKMAUMAIpABwnbS0NC1YsEArVqxQ8eLFrS4HANwe55ACwDW+++47/fnnn5o3b57VpQCAx6BDCgD/Z9u2bZo4caJatmxpdSkA4FHokAKApPj4ePn4+Cg6OpppegAoZHRIAXi8LVu2qHv37nrggQcIowBgATqkhcgYo4SEBPvt+Ph4C6sBIElnzpzR66+/ruXLl8vLy8vqcgDAI9EhLSTGGDVp0kTFihWzf5QtW9bqsgCPtmXLFiUkJGj16tUqVqyY1eUAgMcikBaShIQEbd26NcvPNW7cWIGBgYVcEeDZ/ve//+n1119XSEiIfHx8rC4HADwaU/YWiI2NVVBQkP12YGAgU4VAITLGaO/evYqKisrwWgQAWINAaoGgoCB+CQIW+eqrr7R582ZNmDDB6lIAAP+HQArAY3z33XeaOXOmli9fbnUpAIBrcA4pAI/wyy+/6J577tHy5cs5ZxsAnAyBFIDbi4mJ0ZgxY+Tv708YBQAnRCAF4NZSUlK0evVqLV++XAEBAVaXAwDIAueQAnBb69evl81m06xZs6wuBQCQAzqkANzSunXrNH/+fLVo0cLqUgAAN0CHFIDbiYuL06233qrIyEj5+/tbXQ4A4AbokAJwK59//rmee+45PfDAA4RRAHARdEgBuI3ff/9dH374oZYsWWJ1KQAAB9AhBeAW/vvf/6pIkSKKioqiMwoALoZACsDlffrpp/rggw8UEhIib29+rAGAq+EnNwCXZoxRbGysPvzwQ/n5+VldDgAgDziHFIDLWrVqlQ4cOKDhw4dbXQoA4CYQSAG4pJiYGK1cuVIffPCB1aUAAG4SgRSAy9mxY4caNGig5s2by9fX1+pyAAA3iXNIAbiUFStW6M0331RQUBBhFADcBIEUgMu4evWqvvvuOy1evFhFijDBAwDugp/oAFxCVFSUypQpoxkzZlhdCgAgn9EhBeD0li9frnXr1ulf//qX1aUAAAoAHVIATu38+fOqUaOGOnToIB8fH6vLAQAUAAIpAKe1ZMkSff/993r33XetLgUAUIAIpACc0m+//abNmzdr/vz5VpcCAChgeTqHdNasWapSpYoCAgLUsGFDbd++PVfHRUVFycvLS23bts3LwwLwEB999JFCQkL0/vvvM00PAB7A4UAaHR2t8PBwjRs3Tjt37lSdOnUUGhqqM2fO5HjcsWPH9PLLL6tp06Z5LhaA+1u0aJFiYmJ06623ysvLy+pyAACFwOFAOmPGDPXt21c9e/ZUzZo1NXfuXAUGBmrhwoXZHpOamqouXbpowoQJqlat2k0VDMB9paWlSZLmzp0rb28WAQEAT+HQT/zk5GTt2LFDLVq0+P934O2tFi1aaNu2bdkeN3HiRJUpU0a9e/fOe6UA3FpMTIzmzJmjnj17EkYBwMM4dFHTuXPnlJqaqrJly2bYXrZsWe3bty/LY7Zs2aIFCxZo9+7duX6cpKQkJSUl2W/HxcVJkmw2m2w2m317+v+v3easrq/bFWp2Bq40xsi7FStW6PDhw5oyZQpj7cZ4Pbs/xtgzZDfONzPuBXqV/eXLl9W1a1e99957Kl26dK6Pi4iI0IQJEzJt37BhgwIDAzNtj4mJuak6C0NiYqL9/+vXr1dAQICF1bgeVxhj5M2+fft0++23q1+/ftq4caPV5aAQ8Hp2f4yxZ7h+nBMSEvJ8X17GGJPbnZOTkxUYGKiVK1dmuFK+e/fuunjxoj799NMM++/evVv33Xdfhqtk088R8/b21v79+1W9evVMj5NVh7RSpUo6d+6cgoOD7dttNptiYmLUsmVL+fr65vbLsER8fLxKlSolSbpw4YKCgoIsrsg1uNIYw3Hz58/Xr7/+qmnTpunLL79knN0cr2f3xxh7huzGOS4uTqVLl9alS5cy5LXccKhD6ufnp3r16mnjxo32QJqWlqaNGzdq8ODBmfavUaOGfv755wzbRo8ercuXL+utt95SpUqVsnwcf39/+fv7Z9ru6+ub5RM8u+3O5Nr6XKFeZ8P3zP1cunRJp06d0qxZs5SSkiKJcfYUjLP7Y4w9w/XjfDNj7vCUfXh4uLp376769eurQYMGmjlzpuLj49WzZ09JUrdu3VSxYkVFREQoICBAtWvXznB8yZIlJSnTdndjjMnQuo6Pj7ewGsC5zJ49W/Xq1dOrr75qdSkAACfgcCANCwvT2bNnNXbsWJ0+fVp169bVunXr7Bc6HT9+3OOvkDXGqEmTJtq6davVpQBOZ9asWTp48KCeffZZq0sBADiJPF3UNHjw4Cyn6CVp8+bNOR67ePHivDykS0lISMg2jDZu3DjLC7MAT3DmzBk1bdpUAwcOZNF7AIAd72VfwGJjYzNcwBQYGMgvYnikmTNn6ty5c0zTAwAyIZAWsKCgIK6oh8fbvn27Tpw4oWnTplldCgDACXn2yZ4ACtyCBQt09913a9q0acwOAACyRIcUQIGZNm2a/vrrLwUHBxNGAQDZIpACKBApKSmqUKGCXn75ZcIoACBHBFIA+W7KlCkqX768unfvbnUpAAAXQCDNByyCD/x/CxYsUHx8vLp162Z1KQAAF0EgvUksgg/8f5s2bVLHjh1Z3gwA4BAC6U1iEXzgb5MmTVJqaqoefvhhq0sBALgYAmk+YhF8eKozZ87I399fw4YNs7oUAIALYh3SfJS+CH76B2EUnmDixIk6c+YMYRQAkGcEUgB5NnHiRHl7e6t27dpWlwIAcGFM2QNwmDFGp06dUocOHVSjRg2rywEAuDg6pAAcYozRmDFjFBUVRRgFAOQLAikAh2zcuFHFihVTeHi41aUAANwEU/YAcsUYo7feekv9+/dXixYtrC4HAOBG6JACuCFjjIYPH66UlBQVLVrU6nIAAG6GDimAHBljlJSUpEaNGqlt27ZWlwMAcEMEUgDZMsZo6NChatKkCWEUAFBgmLIHkK0ZM2aoUqVKhFEAQIGiQwogE2OM1q1bp0GDBikgIMDqcgAAbo4OKYAMjDF64YUXdPjwYcIoAKBQ0CEFkMHx48dVq1Yt9evXz+pSAAAegg4pAEl/d0ZffPFFpaWlEUYBAIWKQApAkvTiiy/q7rvvVtWqVa0uBQDgYZiyBzxcWlqaTpw4oSFDhqhatWpWlwMA8EB0SAEPlpaWpkGDBmnTpk2EUQCAZQikgAdbs2aN6tWrpx49elhdCgDAgzFlD3igtLQ0RUREaNiwYfL19bW6HACAh6NDCniYtLQ09e/fXxUrViSMAgCcAh1SwIOkpqYqMTFR7du3V2hoqNXlAAAgiQ4p4DFSU1PVt29fbd++nTAKAHAqdEgdZIxRQkKC/XZ8fLyF1QC5N2HCBD388MN66KGHrC4FAIAMCKQOMMaoSZMm2rp1q9WlALmWmpqqL774QqNHj5afn5/V5QAAkAlT9g5ISEjINow2btxYgYGBhVwRkLOUlBT16tVL8fHxhFEAgNOiQ5pHsbGxCgoKst8ODAyUl5eXhRUBmR0+fFitW7dWhw4drC4FAIBs0SHNo6CgoAwfhFE4k5SUFPXu3VslSpQgjAIAnB6BFHAzxhj17t1bjz76qMqVK2d1OQAA3BBT9oAbsdlsOnHihF599VVVqlTJ6nIAAMgVOqSAm7DZbOrWrZv27NlDGAUAuBQCKeAmVqxYoaefflpt27a1uhQAABzClP0NXLsQPovgwxklJydr8uTJGjdunLy9+RsTAOB6+O2Vg/SF8IsVK6ZixYqpbNmyVpcEZJCcnKyuXbvq/vvvJ4wCAFwWHdIcZLcQPovgwxkkJycrKSlJgwcPVtOmTa0uBwCAPKOlkkuxsbG6cuWKrly5om+++YZ1R2GppKQkdenSRfv27SOMAgBcHh3SXEpfAB9wBiNHjlSPHj30wAMPWF0KAAA3jUAKuJDExEStXbtWr7/+uooU4eULAHAPTNkDLiIxMVGdO3dWYGAgYRQA4Fb4rQa4iAMHDqh///4KDQ21uhQAAPIVHdJrGGMUHx+f4QOw2tWrV9WxY0fdfvvthFEAgFsikP6f69ccZd1ROIO0tDR16dJFvXv3VsmSJa0uBwCAAsGU/f/Jbs1RiXVHYY2EhASdPn1as2fPVrly5awuBwCAAkOHNAvXrjnKuqOwQkJCgjp16qTff/+dMAoAcHt0SLPAmqOwWmRkpJ5//nk99NBDVpcCAECBI5ACTiQ+Pl6vvfaaXn31VbryAACPwZQ94CTi4+MVFhamVq1aEUYBAB6FDingBBISEpSamqrx48erfv36VpcDAEChokMKWOzKlSt6+umn9eeffxJGAQAeiUAKWGzo0KEaOXKk7rnnHqtLAQDAEkzZAxa5fPmyNmzYoFmzZsnbm78NAQCei9+CgAXi4uLUoUMHVahQgTAKAPB4dEiBQmaM0b59+zRu3Dj985//tLocAAAsR2sGKESXLl3SU089pdq1axNGAQD4PwRSoJCkpKSoY8eOGjFihAIDA60uBwAAp8GUPVAILl68qPPnz2vJkiUqXbq01eUAAOBU6JACBezChQvq0KGDzp8/TxgFACALdEiBArZ8+XJFRESoXr16VpcCAIBTIpACBeT8+fOaPn26Jk+ebHUpAAA4NabsgQJw/vx5dezYUe3bt7e6FAAAnB4dUiCfxcXFycfHRzNnzlTNmjWtLgcAAKdHhxTIR+fOndNTTz2lCxcuEEYBAMglAimQj4YNG6YZM2aoSpUqVpcCAIDLYMoeyAdnz57V119/rQULFsjLy8vqcgAAcCl0SIGbdObMGXXs2FF33303YRQAgDygQwrcBGOMDhw4oLffflu1atWyuhwAAFwSHVIgj2JjY/Xkk0+qYcOGhFEAAG4CHVIgDxITE9WlSxe988478vX1tbocAABcGoEUcNCpU6eUlJSklStXqmTJklaXAwCAy2PKHnDAqVOn1KVLFyUlJRFGAQDIJwRSwAHR0dGaM2eO7r77bqtLAQDAbTBlD+TCn3/+qTlz5ujVV1+1uhQAANwOHVLgBk6ePKlu3bqpR48eVpcCAIBbokMK5OCvv/5S0aJF9d5776latWpWlwMAgFuiQwpk448//tDTTz+t5ORkwigAAAXIYzukxhglJCTYb8fHx1tYDZyNMUYjR47U+++/r7Jly1pdDgAAbs0jA6kxRk2aNNHWrVutLgVO6Pfff9fOnTv14Ycf8t70AAAUAo+csk9ISMg2jDZu3FiBgYGFXBGcxbFjx9SzZ0/dd999hFEAAAqJR3ZIrxUbG6ugoCD77cDAQIKIh0pNTdWxY8e0cOFCValSxepyAADwGB4fSIOCgjIEUnimo0eP6oUXXtAnn3wib2+PnDgAAMAyHh9Igbi4OPXu3VuLFy8mjAIAYAECKTza4cOH5efnpzVr1qhYsWJWlwMAgEeiHQSPdejQIfXr10/e3t6EUQAALEQghcf69NNP9eGHH6pixYpWlwIAgEdjyh4e5+DBg1q6dKkmTJhgdSkAAEAEUniYQ4cOacCAAVqyZInVpQAAgP9DIIXHOH36tG655RYtXbpU5cuXt7ocAADwfziHFB5h37596ty5s7y9vQmjAAA4GQIp3J4xRpMmTVJkZKRKlixpdTkAAOA6TNnDrf322286fPiwli1bZnUpAAAgG3RI4bZ+/fVXDRkyRA0bNrS6FAAAkAMCKdxSSkqKYmNjFRkZqTJlylhdDgAAyAGBFG7n559/VseOHfXQQw8RRgEAcAGcQwq3cvbsWYWHh2v58uXy8vKyuhwAAJALdEjhNn7++WfZbDatWbNGpUuXtrocAACQSwRSuIXdu3frpZdekr+/v4oWLWp1OQAAwAFM2cMtxMTEKCoqSrfccovVpQAAAAcRSOHSdu7cqbVr12r06NFWlwIAAPKIQAqXtWfPHo0YMUJRUVFWlwIAAG4C55DCJf3xxx+qUKGCoqKiVKpUKavLAQAAN4FACpfzww8/qE+fPgoKCiKMAgDgBvIUSGfNmqUqVaooICBADRs21Pbt27Pd97333lPTpk1VqlQplSpVSi1atMhxfyAnKSkpeuutt7RixQoFBgZaXQ4AAMgHDgfS6OhohYeHa9y4cdq5c6fq1Kmj0NBQnTlzJsv9N2/erE6dOumrr77Stm3bVKlSJbVq1Up//vnnTRcPz/L9999r48aNWrp0qUqUKGF1OQAAIJ84HEhnzJihvn37qmfPnqpZs6bmzp2rwMBALVy4MMv9ly1bpoEDB6pu3bqqUaOG3n//faWlpWnjxo03XTw8x/fff6/x48erUaNGVpcCAADymUNX2ScnJ2vHjh0aMWKEfZu3t7datGihbdu25eo+EhISZLPZclwvMikpSUlJSfbbcXFxkiSbzSabzWbfnv7/a7flxvX34ejxKDzp43Pp0iUtXbpURYsWZbzcUF5fy3AtjLP7Y4w9Q3bjfDPj7lAgPXfunFJTU1W2bNkM28uWLat9+/bl6j5eeeUVVahQQS1atMh2n4iICE2YMCHT9g0bNmR53mBMTEyuHjtdYmKi/f/r169XQECAQ8ej8Ozbt09r165VeHi4tmzZYnU5KGCOvpbhmhhn98cYe4brxzkhISHP91Wo65BOmTJFUVFR2rx5c44hcMSIEQoPD7ffjouLs597GhwcbN9us9kUExOjli1bytfXN9d1xMfH2/8fGhqqoKAgB78SFIbjx49rzpw5evbZZx0eY7iWvL6W4VoYZ/fHGHuG7MY5fUY7LxwKpKVLl5aPj49iY2MzbI+NjVW5cuVyPPaNN97QlClT9OWXX+of//hHjvv6+/vL398/03ZfX98sn+DZbc/Otfs6eiwKx3fffadq1app5cqV2rhxI+PkIRhnz8A4uz/G2DNcP843M+YOXdTk5+enevXqZbggKf0CpZwuNpk6daomTZqkdevWqX79+nkuFp7h66+/1uTJkxUUFJTlHyYAAMC9ODxlHx4eru7du6t+/fpq0KCBZs6cqfj4ePXs2VOS1K1bN1WsWFERERGSpNdff11jx45VZGSkqlSpotOnT0uSihUrpmLFiuXjlwJ3sX37dkVFRSkoKIgT4wEA8AAOB9KwsDCdPXtWY8eO1enTp1W3bl2tW7fOfqHT8ePH5e39/xuvc+bMUXJystq3b5/hfsaNG6fx48ffXPVwK5s3b9YPP/ygoUOHWl0KAAAoRHm6qGnw4MEaPHhwlp/bvHlzhtvHjh3Ly0PAw2zZskUzZsxQVFSU1aUAAIBCxnvZw3KHDx/W3XffraioKN4OFAAAD0QghaW+/PJLhYeHq2TJkoRRAAA8FIEUlklMTFRkZKSioqJYHgQAAA9WqAvjA+k2bNggf39/LVy40OpSAACAxeiQotCtX79ec+fOVcOGDa0uBQAAOAECKQpVYmKi/Pz8FBkZmePbxwIAAM/BlD0Kzdq1a7V69WrNnz/f6lIAAIATIZCiUOzbt0+LFi3S0qVLrS4FAAA4GabsUeA2btyokJAQLV++nPemBwAAmRBIUaDWrFmjefPmqXjx4ipShIY8AADIjECKAmOM0aFDh7R06VL5+flZXQ4AAHBStKxQIFavXq0//vhD4eHhVpcCAACcHIEU+W7t2rWKjo7Whx9+aHUpAADABRBIka/27t2rBx54QC1btuTtQAEAQK5wDinyzcqVK/Xqq6/q1ltvJYwCAIBcI5AiX8TFxWnTpk364IMP5O3N0woAAOQeU/a4adHR0apatapmz55tdSkAAMAF0crCTYmKitIXX3yh+++/3+pSAACAiyKQIs+uXLmiChUqaOHChSx6DwAA8owUgTxZunSpdu7cqRkzZlhdCgAAcHEEUjjsxx9/1KZNm/Tee+9ZXQoAAHADTNnDIZ9++qnuvPNOvffee/Lx8bG6HAAA4AYIpMi1xYsX6/PPP1fx4sUJowAAIN8QSJEraWlpiouL07x581hnFAAA5CvOIcUNLVy4UJI0ZMgQiysBAADuyCMCqTFGCQkJ9tvx8fEWVuNali9fru3bt7PoPQAAKDBuH0iNMWrSpIm2bt1qdSkuZ8+ePWrZsqXCwsKYpgcAAAXG7VNGQkJCtmG0cePGCgwMLOSKXMO8efM0f/583XrrrYRRAABQoNy+Q3qt2NhYBQUF2W8HBgbKy8vLwoqc09mzZ3X48GG9++67fH8AAECB86jWV1BQUIYPwlZmc+fO1enTpzV16lS+PwAAoFB4VCBFzmbNmqW9e/eqdu3aVpcCAAA8iEdN2SN7ly5d0v3336+BAwfSGQUAAIWKQAq99dZbunjxosaNG2d1KQAAwAMRSD3cV199pePHj+uNN96wuhQAAOChCKQebNmyZWrbtq2aN2/OND0AALAMFzV5qOnTp2vPnj0sfQUAACxHh9QD2Ww2BQcHKzw8nDAKAAAsRyD1MFOnTlXVqlXVt29fq0sBAACQxJS9R5kzZ44uXbqk9u3bW10KAACAHR1SD/HDDz+oY8eOKlmyJNP0AADAqdAh9QCTJ0/WmjVrVKpUKcIoAABwOgRSN3f8+HFJ0sSJEy2uBAAAIGsEUjcWERGhlJQUjRo1is4oAABwWpxD6qYmTJggLy8vVatWzepSAAAAckQgdTPGGJ0/f15PPPGE6tWrZ3U5AAAAN0QgdSPGGI0dO1YhISEaMmSI1eUAAADkCueQupE1a9YoMDCQMAoAAFwKHVI3YIzR/Pnz1bNnTz355JNWlwMAAOAQOqQuzhijESNGKC4uTn5+flaXAwAA4DA6pC7MGKPExETde++96tKli9XlAAAA5AkdUhdljNErr7yir7/+mjAKAABcmkt3SNM7hPHx8fL19c1yn/j4+EKuqnBERESofPnyCg0NtboUAACAm+KygdQYo+bNm2vbtm1Wl1KojDH69ttvNXjwYAUHB1tdDgAAwE1z2Sn7hIQEh8Jo48aNFRgYWIAVFTxjjMLDw7Vz507CKAAAcBsu2yG91okTJ1SyZMkc9wkMDHT593M/cOCA7rzzTg0cONDqUgAAAPKNy3ZIrxUUFHTDD1cOo8YYDRs2TMHBwYRRAADgdtwikLozY4yef/55Va1aVeXLl7e6HAAAgHznFlP27iotLU3nzp1Tv379VLt2bavLAQAAKBB0SJ1UWlqaBg8erPXr1xNGAQCAWyOQOqnIyEjdd9996tq1q9WlAAAAFCim7J1MWlqa3n77bQ0ZMkTe3vy9AAAA3B+Jx4mkpaVpwIABCg4OJowCAACPQYfUSaSlpSk+Pl6tW7fWk08+aXU5AAAAhYY2nBNITU1Vv3799MsvvxBGAQCAxyGQOoGRI0eqWbNmatSokdWlAAAAFDqm7C2Umpqqr7/+WuPGjVNgYKDV5QAAAFiCDqlFUlNT1adPH508eZIwCgAAPBodUov8/PPPatWqlTp16mR1KQAAAJaiQ1rIUlJS9Oyzz6py5cqEUQAAABFIC5UxRj179lTz5s1VqlQpq8sBAABwCkzZF5KUlBSdO3dOo0eP1t133211OQAAAE6DDmkhsNls6t69u3744QfCKAAAwHUIpIVg4cKFeuqpp9SmTRurSwEAAHA6TNkXIJvNpjfffFNDhw6Vl5eX1eUAAAA4JTqkBSQ5OVldu3bVXXfdRRgFAADIAR3SAmCz2ZSQkKA+ffqoRYsWVpcDAADg1OiQ5rPk5GR16dJFf/zxB2EUAAAgFwik+ezFF19Ut27ddO+991pdCgAAgEtgyj6fJCUl6euvv9b06dMVEBBgdTkAAAAugw5pPkhKSlKXLl2UkpJCGAUAAHAQHdJ8sGPHDvXp00ePPvqo1aUAAAC4HDqkNyExMVE9evRQnTp1CKMAAAB5RCDNo5SUFHXq1EmdO3dWUFCQ1eUAAAC4LKbs8+Dq1au6dOmSZsyYoapVq1pdDgAAgEujQ+qghIQEdezYUfv37yeMAgAA5AMCqYPmz5+vIUOGqFmzZlaXAgAA4BaYss+l+Ph4vf322xoxYoTVpQAAALgVOqS5EB8fr44dO6pRo0ZWlwIAAOB26JDeQFJSkhITEzVy5EgCKQAAQAGgQ5qDK1euqF27drp06RJhFAAAoIAQSHMwePBgDR8+XNWqVbO6FAAAALfFlH0WLl++rG3btum9996Tr6+v1eUAAAC4NTqk17l8+bLCwsJUrFgxwigAAEAhoEN6nR9++EFjxozhnFEAAIBCQiD9P3FxcRowYIAWL14sPz8/q8sBAADwGEzZS0pMTFSHDh30wgsvEEYBAAAKmcd3SC9evKikpCQtWLBAFStWtLocAAAAj+PRHdKLFy8qLCxMf/75J2EUAADAIh4dSOfNm6fJkyfr/vvvt7oUAAAAj+WRU/YXLlzQ3LlzNWLECKtLAQAA8Hge1yE9f/68wsLCFBoaanUpAAAAkId1SBMSEpSSkqJp06apTp06VpcDAAAAeVCH9K+//tKTTz6p1NRUwigAAIAT8ZhAOmjQIL3xxhsqX7681aUAAADgGm4/ZX/u3Dnt3LlTS5cuVZEibv/lAgAAuBy37pCePXtWHTt2VIUKFQijAAAATsptA6kxRjt27NDMmTNVu3Ztq8sBAABANtwykJ45c0YdO3ZUy5YtCaMAAABOzu3msS9fvqzOnTvr7bfflo+Pj9XlAAAA4AbcKpCePn1aPj4+WrZsmcqWLWt1OQAAAMiFPE3Zz5o1S1WqVFFAQIAaNmyo7du357j/Rx99pBo1aiggIED33nuv1q5dm6dic3Lq1Cl16dJFFy5cIIwCAAC4EIcDaXR0tMLDwzVu3Djt3LlTderUUWhoqM6cOZPl/lu3blWnTp3Uu3dv7dq1S23btlXbtm31yy+/3HTx11qwYIFmz56tu+66K1/vFwAAAAXL4UA6Y8YM9e3bVz179lTNmjU1d+5cBQYGauHChVnu/9Zbb+nRRx/V0KFDdc8992jSpEm6//779e6779508enefPNNjR49WnfffXe+3ScAAAAKh0PnkCYnJ2vHjh0aMWKEfZu3t7datGihbdu2ZXnMtm3bFB4enmFbaGioVq9ene3jJCUlKSkpyX47Li5OkmSz2WSz2ez/T/f4449nuA33kdV4w/0wzp6BcXZ/jLFnyG6cb2bcHQqk586dU2pqaqZzNMuWLat9+/Zleczp06ez3P/06dPZPk5ERIQmTJiQafuGDRsUGBgoSUpMTLRvP3bsWI73B9cXExNjdQkoBIyzZ2Cc3R9j7BmuH+eEhIQ835dTXmU/YsSIDF3VuLg4VapUSa1atVJwcLCkvxe+P3PmjDZt2qQnnnhCfn5+VpWLAmSz2RQTE6OWLVvK19fX6nJQQBhnz8A4uz/G2DNkN87pM9p54VAgLV26tHx8fBQbG5the2xsrMqVK5flMeXKlXNof0ny9/eXv79/pu2+vr4ZvvCSJUsqICBAfn5+PPHd3PVjD/fEOHsGxtn9Mcae4fpxvpkxd+iiJj8/P9WrV08bN260b0tLS9PGjRvVqFGjLI9p1KhRhv2lv1u82e0PAAAAz+LwlH14eLi6d++u+vXrq0GDBpo5c6bi4+PVs2dPSVK3bt1UsWJFRURESJKef/55NWvWTNOnT1fr1q0VFRWlH3/8UfPnz8/frwQAAAAuyeFAGhYWprNnz2rs2LE6ffq06tatq3Xr1tkvXDp+/Li8vf9/4/XBBx9UZGSkRo8erZEjR+rOO+/U6tWrHXqPeWOMpMznJthsNiUkJCguLo6pATfFGHsGxtkzMM7ujzH2DNmNc3pOS89tjvAyeTmqkJ04cUKVKlWyugwAAADcwB9//KHbbrvNoWNcIpCmpaXp5MmTKl68uLy8vOzb06++/+OPP+xX38O9MMaegXH2DIyz+2OMPUN242yM0eXLl1WhQoUMs+W54ZTLPl3P29s7x6QdHBzME9/NMcaegXH2DIyz+2OMPUNW41yiRIk83ZfDbx0KAAAA5CcCKQAAACzl0oHU399f48aNy3IRfbgHxtgzMM6egXF2f4yxZyiIcXaJi5oAAADgvly6QwoAAADXRyAFAACApQikAAAAsBSBFAAAAJZy+kA6a9YsValSRQEBAWrYsKG2b9+e4/4fffSRatSooYCAAN17771au3ZtIVWKvHJkjN977z01bdpUpUqVUqlSpdSiRYsbPifgHBx9LaeLioqSl5eX2rZtW7AF4qY5OsYXL17UoEGDVL58efn7++uuu+7iZ7YLcHScZ86cqbvvvltFixZVpUqV9OKLLyoxMbGQqoWjvv76a7Vp00YVKlSQl5eXVq9efcNjNm/erPvvv1/+/v664447tHjxYscf2DixqKgo4+fnZxYuXGh+/fVX07dvX1OyZEkTGxub5f7ffvut8fHxMVOnTjW//fabGT16tPH19TU///xzIVeO3HJ0jDt37mxmzZpldu3aZfbu3Wt69OhhSpQoYU6cOFHIlcMRjo5zuqNHj5qKFSuapk2bmieffLJwikWeODrGSUlJpn79+ubxxx83W7ZsMUePHjWbN282u3fvLuTK4QhHx3nZsmXG39/fLFu2zBw9etSsX7/elC9f3rz44ouFXDlya+3atWbUqFFm1apVRpL55JNPctz/yJEjJjAw0ISHh5vffvvNvPPOO8bHx8esW7fOocd16kDaoEEDM2jQIPvt1NRUU6FCBRMREZHl/h06dDCtW7fOsK1hw4amf//+BVon8s7RMb5eSkqKKV68uPnggw8KqkTkg7yMc0pKinnwwQfN+++/b7p3704gdXKOjvGcOXNMtWrVTHJycmGViHzg6DgPGjTIPPzwwxm2hYeHm8aNGxdoncgfuQmkw4YNM7Vq1cqwLSwszISGhjr0WE47ZZ+cnKwdO3aoRYsW9m3e3t5q0aKFtm3bluUx27Zty7C/JIWGhma7P6yVlzG+XkJCgmw2m2655ZaCKhM3Ka/jPHHiRJUpU0a9e/cujDJxE/IyxmvWrFGjRo00aNAglS1bVrVr19Zrr72m1NTUwiobDsrLOD/44IPasWOHfVr/yJEjWrt2rR5//PFCqRkFL7+yV5H8LCo/nTt3TqmpqSpbtmyG7WXLltW+ffuyPOb06dNZ7n/69OkCqxN5l5cxvt4rr7yiChUqZHoxwHnkZZy3bNmiBQsWaPfu3YVQIW5WXsb4yJEj2rRpk7p06aK1a9fq0KFDGjhwoGw2m8aNG1cYZcNBeRnnzp0769y5c2rSpImMMUpJSdGAAQM0cuTIwigZhSC77BUXF6erV6+qaNGiubofp+2QAjcyZcoURUVF6ZNPPlFAQIDV5SCfXL58WV27dtV7772n0qVLW10OCkhaWprKlCmj+fPnq169egoLC9OoUaM0d+5cq0tDPtq8ebNee+01zZ49Wzt37tSqVav0xRdfaNKkSVaXBifjtB3S0qVLy8fHR7GxsRm2x8bGqly5clkeU65cOYf2h7XyMsbp3njjDU2ZMkVffvml/vGPfxRkmbhJjo7z4cOHdezYMbVp08a+LS0tTZJUpEgR7d+/X9WrVy/YouGQvLyWy5cvL19fX/n4+Ni33XPPPTp9+rSSk5Pl5+dXoDXDcXkZ5zFjxqhr167q06ePJOnee+9VfHy8+vXrp1GjRsnbm76Yq8suewUHB+e6Oyo5cYfUz89P9erV08aNG+3b0tLStHHjRjVq1CjLYxo1apRhf0mKiYnJdn9YKy9jLElTp07VpEmTtG7dOtWvX78wSsVNcHSca9SooZ9//lm7d++2f/z73//WQw89pN27d6tSpUqFWT5yIS+v5caNG+vQoUP2PzYk6cCBAypfvjxh1EnlZZwTEhIyhc70P0L+vmYGri7fspdj11sVrqioKOPv728WL15sfvvtN9OvXz9TsmRJc/r0aWOMMV27djXDhw+37//tt9+aIkWKmDfeeMPs3bvXjBs3jmWfnJyjYzxlyhTj5+dnVq5caU6dOmX/uHz5slVfAnLB0XG+HlfZOz9Hx/j48eOmePHiZvDgwWb//v3m888/N2XKlDGvvvqqVV8CcsHRcR43bpwpXry4Wb58uTly5IjZsGGDqV69uunQoYNVXwJu4PLly2bXrl1m165dRpKZMWOG2bVrl/n999+NMcYMHz7cdO3a1b5/+rJPQ4cONXv37jWzZs1yv2WfjDHmnXfeMbfffrvx8/MzDRo0MN999539c82aNTPdu3fPsP+KFSvMXXfdZfz8/EytWrXMF198UcgVw1GOjHHlypWNpEwf48aNK/zC4RBHX8vXIpC6BkfHeOvWraZhw4bG39/fVKtWzUyePNmkpKQUctVwlCPjbLPZzPjx40316tVNQECAqVSpkhk4cKC5cOFC4ReOXPnqq6+y/D2bPq7du3c3zZo1y3RM3bp1jZ+fn6lWrZpZtGiRw4/rZQw9cwAAAFjHac8hBQAAgGcgkAIAAMBSBFIAAABYikAKAAAASxFIAQAAYCkCKQAAACxFIAUAAIClCKQAAACwFIEUAAAAliKQAgAAwFIEUgAAAFiKQAoAAABL/T/n3nqbln7zrQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.plot(run_hist_supp.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
        "ax.plot(run_hist_supp.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
        "ax.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "wuZybHlzpTtf",
        "outputId": "9aa600d5-044e-4f3a-c0f2-a8fff56b65cd"
      },
      "id": "wuZybHlzpTtf",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fcb7bcb25f0>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Testing Area for different learning rates/epochs"
      ],
      "metadata": {
        "id": "Ol61iHAeps23"
      },
      "id": "Ol61iHAeps23"
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Network Structure"
      ],
      "metadata": {
        "id": "IypTlJRTqm4j"
      },
      "id": "IypTlJRTqm4j"
    },
    {
      "cell_type": "code",
      "source": [
        "# Building the model (2 hidden layers with 6 nodes (relu) each | 1 output layer with 1 node (sigmoid))\n",
        "model_test  = Sequential([\n",
        "    Dense(6, input_shape=(8,), activation=\"relu\"),\n",
        "    Dense(6, activation=\"relu\"),\n",
        "    Dense(6, activation=\"relu\"),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])"
      ],
      "metadata": {
        "id": "e8mxx3KBqhW-"
      },
      "id": "e8mxx3KBqhW-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Compilation"
      ],
      "metadata": {
        "id": "oiXjIjjIqDBT"
      },
      "id": "oiXjIjjIqDBT"
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the modle and use a learning rate of 0.003\n",
        "model_test.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Fit the model and train for 1,500 epochs\n",
        "run_hist_test = model_test.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56-8574QpzPQ",
        "outputId": "a08dd8e2-7158-4cd5-f71d-820143c23587"
      },
      "id": "56-8574QpzPQ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "18/18 [==============================] - 1s 23ms/step - loss: 0.7025 - accuracy: 0.3958 - val_loss: 0.6947 - val_accuracy: 0.5208\n",
            "Epoch 2/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.6964 - accuracy: 0.4913 - val_loss: 0.6898 - val_accuracy: 0.6094\n",
            "Epoch 3/100\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.6910 - accuracy: 0.5781 - val_loss: 0.6855 - val_accuracy: 0.6302\n",
            "Epoch 4/100\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.6862 - accuracy: 0.6111 - val_loss: 0.6817 - val_accuracy: 0.6250\n",
            "Epoch 5/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.6820 - accuracy: 0.6302 - val_loss: 0.6783 - val_accuracy: 0.6250\n",
            "Epoch 6/100\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.6782 - accuracy: 0.6458 - val_loss: 0.6754 - val_accuracy: 0.6250\n",
            "Epoch 7/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6749 - accuracy: 0.6406 - val_loss: 0.6727 - val_accuracy: 0.6458\n",
            "Epoch 8/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6719 - accuracy: 0.6424 - val_loss: 0.6703 - val_accuracy: 0.6406\n",
            "Epoch 9/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6692 - accuracy: 0.6493 - val_loss: 0.6681 - val_accuracy: 0.6458\n",
            "Epoch 10/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6668 - accuracy: 0.6510 - val_loss: 0.6662 - val_accuracy: 0.6458\n",
            "Epoch 11/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6646 - accuracy: 0.6493 - val_loss: 0.6644 - val_accuracy: 0.6406\n",
            "Epoch 12/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6626 - accuracy: 0.6493 - val_loss: 0.6629 - val_accuracy: 0.6406\n",
            "Epoch 13/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6608 - accuracy: 0.6493 - val_loss: 0.6614 - val_accuracy: 0.6406\n",
            "Epoch 14/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6592 - accuracy: 0.6510 - val_loss: 0.6601 - val_accuracy: 0.6406\n",
            "Epoch 15/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6577 - accuracy: 0.6510 - val_loss: 0.6589 - val_accuracy: 0.6406\n",
            "Epoch 16/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6563 - accuracy: 0.6510 - val_loss: 0.6578 - val_accuracy: 0.6406\n",
            "Epoch 17/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6550 - accuracy: 0.6528 - val_loss: 0.6568 - val_accuracy: 0.6406\n",
            "Epoch 18/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6539 - accuracy: 0.6545 - val_loss: 0.6559 - val_accuracy: 0.6406\n",
            "Epoch 19/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6528 - accuracy: 0.6545 - val_loss: 0.6551 - val_accuracy: 0.6406\n",
            "Epoch 20/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6519 - accuracy: 0.6545 - val_loss: 0.6543 - val_accuracy: 0.6406\n",
            "Epoch 21/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6509 - accuracy: 0.6545 - val_loss: 0.6536 - val_accuracy: 0.6406\n",
            "Epoch 22/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6501 - accuracy: 0.6545 - val_loss: 0.6529 - val_accuracy: 0.6406\n",
            "Epoch 23/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6493 - accuracy: 0.6545 - val_loss: 0.6523 - val_accuracy: 0.6406\n",
            "Epoch 24/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6486 - accuracy: 0.6545 - val_loss: 0.6518 - val_accuracy: 0.6406\n",
            "Epoch 25/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6479 - accuracy: 0.6545 - val_loss: 0.6513 - val_accuracy: 0.6406\n",
            "Epoch 26/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6473 - accuracy: 0.6545 - val_loss: 0.6508 - val_accuracy: 0.6406\n",
            "Epoch 27/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6467 - accuracy: 0.6545 - val_loss: 0.6503 - val_accuracy: 0.6406\n",
            "Epoch 28/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6462 - accuracy: 0.6545 - val_loss: 0.6499 - val_accuracy: 0.6406\n",
            "Epoch 29/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6456 - accuracy: 0.6545 - val_loss: 0.6495 - val_accuracy: 0.6406\n",
            "Epoch 30/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6451 - accuracy: 0.6545 - val_loss: 0.6491 - val_accuracy: 0.6406\n",
            "Epoch 31/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6447 - accuracy: 0.6545 - val_loss: 0.6488 - val_accuracy: 0.6406\n",
            "Epoch 32/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6442 - accuracy: 0.6545 - val_loss: 0.6484 - val_accuracy: 0.6406\n",
            "Epoch 33/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6438 - accuracy: 0.6545 - val_loss: 0.6481 - val_accuracy: 0.6406\n",
            "Epoch 34/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6434 - accuracy: 0.6545 - val_loss: 0.6478 - val_accuracy: 0.6406\n",
            "Epoch 35/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6430 - accuracy: 0.6545 - val_loss: 0.6475 - val_accuracy: 0.6406\n",
            "Epoch 36/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6427 - accuracy: 0.6545 - val_loss: 0.6472 - val_accuracy: 0.6406\n",
            "Epoch 37/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6423 - accuracy: 0.6545 - val_loss: 0.6469 - val_accuracy: 0.6406\n",
            "Epoch 38/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6420 - accuracy: 0.6545 - val_loss: 0.6466 - val_accuracy: 0.6406\n",
            "Epoch 39/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6417 - accuracy: 0.6545 - val_loss: 0.6464 - val_accuracy: 0.6406\n",
            "Epoch 40/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6414 - accuracy: 0.6545 - val_loss: 0.6461 - val_accuracy: 0.6406\n",
            "Epoch 41/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6411 - accuracy: 0.6545 - val_loss: 0.6458 - val_accuracy: 0.6406\n",
            "Epoch 42/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6408 - accuracy: 0.6545 - val_loss: 0.6456 - val_accuracy: 0.6406\n",
            "Epoch 43/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6405 - accuracy: 0.6545 - val_loss: 0.6454 - val_accuracy: 0.6406\n",
            "Epoch 44/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6402 - accuracy: 0.6545 - val_loss: 0.6452 - val_accuracy: 0.6406\n",
            "Epoch 45/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6399 - accuracy: 0.6545 - val_loss: 0.6449 - val_accuracy: 0.6406\n",
            "Epoch 46/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6396 - accuracy: 0.6545 - val_loss: 0.6447 - val_accuracy: 0.6406\n",
            "Epoch 47/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6394 - accuracy: 0.6545 - val_loss: 0.6445 - val_accuracy: 0.6406\n",
            "Epoch 48/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6391 - accuracy: 0.6545 - val_loss: 0.6443 - val_accuracy: 0.6406\n",
            "Epoch 49/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6388 - accuracy: 0.6545 - val_loss: 0.6441 - val_accuracy: 0.6406\n",
            "Epoch 50/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6385 - accuracy: 0.6545 - val_loss: 0.6438 - val_accuracy: 0.6406\n",
            "Epoch 51/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6383 - accuracy: 0.6545 - val_loss: 0.6436 - val_accuracy: 0.6406\n",
            "Epoch 52/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6380 - accuracy: 0.6545 - val_loss: 0.6433 - val_accuracy: 0.6406\n",
            "Epoch 53/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6377 - accuracy: 0.6545 - val_loss: 0.6431 - val_accuracy: 0.6406\n",
            "Epoch 54/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6374 - accuracy: 0.6545 - val_loss: 0.6428 - val_accuracy: 0.6406\n",
            "Epoch 55/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6371 - accuracy: 0.6545 - val_loss: 0.6426 - val_accuracy: 0.6406\n",
            "Epoch 56/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6369 - accuracy: 0.6545 - val_loss: 0.6423 - val_accuracy: 0.6406\n",
            "Epoch 57/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.6366 - accuracy: 0.6545 - val_loss: 0.6420 - val_accuracy: 0.6406\n",
            "Epoch 58/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6363 - accuracy: 0.6545 - val_loss: 0.6417 - val_accuracy: 0.6406\n",
            "Epoch 59/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.6360 - accuracy: 0.6545 - val_loss: 0.6414 - val_accuracy: 0.6406\n",
            "Epoch 60/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6357 - accuracy: 0.6545 - val_loss: 0.6411 - val_accuracy: 0.6406\n",
            "Epoch 61/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6354 - accuracy: 0.6545 - val_loss: 0.6408 - val_accuracy: 0.6406\n",
            "Epoch 62/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6351 - accuracy: 0.6545 - val_loss: 0.6405 - val_accuracy: 0.6406\n",
            "Epoch 63/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6348 - accuracy: 0.6545 - val_loss: 0.6401 - val_accuracy: 0.6406\n",
            "Epoch 64/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6344 - accuracy: 0.6545 - val_loss: 0.6398 - val_accuracy: 0.6406\n",
            "Epoch 65/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6341 - accuracy: 0.6545 - val_loss: 0.6395 - val_accuracy: 0.6406\n",
            "Epoch 66/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.6337 - accuracy: 0.6545 - val_loss: 0.6391 - val_accuracy: 0.6406\n",
            "Epoch 67/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6333 - accuracy: 0.6545 - val_loss: 0.6387 - val_accuracy: 0.6406\n",
            "Epoch 68/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6329 - accuracy: 0.6545 - val_loss: 0.6383 - val_accuracy: 0.6406\n",
            "Epoch 69/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6325 - accuracy: 0.6545 - val_loss: 0.6379 - val_accuracy: 0.6406\n",
            "Epoch 70/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6321 - accuracy: 0.6545 - val_loss: 0.6374 - val_accuracy: 0.6406\n",
            "Epoch 71/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6316 - accuracy: 0.6545 - val_loss: 0.6369 - val_accuracy: 0.6406\n",
            "Epoch 72/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.6311 - accuracy: 0.6545 - val_loss: 0.6365 - val_accuracy: 0.6406\n",
            "Epoch 73/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6305 - accuracy: 0.6545 - val_loss: 0.6359 - val_accuracy: 0.6406\n",
            "Epoch 74/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6299 - accuracy: 0.6545 - val_loss: 0.6354 - val_accuracy: 0.6406\n",
            "Epoch 75/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.6294 - accuracy: 0.6545 - val_loss: 0.6348 - val_accuracy: 0.6406\n",
            "Epoch 76/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.6287 - accuracy: 0.6545 - val_loss: 0.6342 - val_accuracy: 0.6406\n",
            "Epoch 77/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6281 - accuracy: 0.6528 - val_loss: 0.6336 - val_accuracy: 0.6406\n",
            "Epoch 78/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.6274 - accuracy: 0.6528 - val_loss: 0.6329 - val_accuracy: 0.6406\n",
            "Epoch 79/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6267 - accuracy: 0.6528 - val_loss: 0.6322 - val_accuracy: 0.6406\n",
            "Epoch 80/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6259 - accuracy: 0.6528 - val_loss: 0.6314 - val_accuracy: 0.6406\n",
            "Epoch 81/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6251 - accuracy: 0.6528 - val_loss: 0.6306 - val_accuracy: 0.6406\n",
            "Epoch 82/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6242 - accuracy: 0.6528 - val_loss: 0.6298 - val_accuracy: 0.6406\n",
            "Epoch 83/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6233 - accuracy: 0.6528 - val_loss: 0.6289 - val_accuracy: 0.6406\n",
            "Epoch 84/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6224 - accuracy: 0.6528 - val_loss: 0.6280 - val_accuracy: 0.6406\n",
            "Epoch 85/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6215 - accuracy: 0.6528 - val_loss: 0.6271 - val_accuracy: 0.6406\n",
            "Epoch 86/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6204 - accuracy: 0.6528 - val_loss: 0.6261 - val_accuracy: 0.6406\n",
            "Epoch 87/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6192 - accuracy: 0.6528 - val_loss: 0.6251 - val_accuracy: 0.6406\n",
            "Epoch 88/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6180 - accuracy: 0.6528 - val_loss: 0.6240 - val_accuracy: 0.6406\n",
            "Epoch 89/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6168 - accuracy: 0.6528 - val_loss: 0.6228 - val_accuracy: 0.6406\n",
            "Epoch 90/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6156 - accuracy: 0.6528 - val_loss: 0.6216 - val_accuracy: 0.6458\n",
            "Epoch 91/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6143 - accuracy: 0.6528 - val_loss: 0.6204 - val_accuracy: 0.6458\n",
            "Epoch 92/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6128 - accuracy: 0.6528 - val_loss: 0.6190 - val_accuracy: 0.6458\n",
            "Epoch 93/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6114 - accuracy: 0.6528 - val_loss: 0.6176 - val_accuracy: 0.6458\n",
            "Epoch 94/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6099 - accuracy: 0.6528 - val_loss: 0.6162 - val_accuracy: 0.6458\n",
            "Epoch 95/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6084 - accuracy: 0.6528 - val_loss: 0.6147 - val_accuracy: 0.6458\n",
            "Epoch 96/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6069 - accuracy: 0.6528 - val_loss: 0.6132 - val_accuracy: 0.6458\n",
            "Epoch 97/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6054 - accuracy: 0.6528 - val_loss: 0.6117 - val_accuracy: 0.6458\n",
            "Epoch 98/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6038 - accuracy: 0.6528 - val_loss: 0.6101 - val_accuracy: 0.6458\n",
            "Epoch 99/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6022 - accuracy: 0.6545 - val_loss: 0.6084 - val_accuracy: 0.6458\n",
            "Epoch 100/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6004 - accuracy: 0.6545 - val_loss: 0.6067 - val_accuracy: 0.6458\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Plotting"
      ],
      "metadata": {
        "id": "xatfYjF5qFNT"
      },
      "id": "xatfYjF5qFNT"
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_class_nn_test = (model_test.predict(X_test_norm) > 0.5).astype(\"int32\")\n",
        "y_pred_prob_nn_test = model_test.predict(X_test_norm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VeuQFEkFqGvn",
        "outputId": "d3a5a3e4-83c2-4f96-f22c-4eb664da362f"
      },
      "id": "VeuQFEkFqGvn",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 0s 2ms/step\n",
            "6/6 [==============================] - 0s 3ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_test)))\n",
        "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_test)))\n",
        "\n",
        "plot_roc(y_test, y_pred_prob_nn_test, 'NN')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 580
        },
        "id": "nkqzaC_MqSJ3",
        "outputId": "65abced4-14b3-4f0d-8b29-549e04491bc1"
      },
      "id": "nkqzaC_MqSJ3",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy is 0.646\n",
            "roc-auc is 0.749\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.plot(run_hist_test.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
        "ax.plot(run_hist_test.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
        "ax.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "bp18u5zyqbWe",
        "outputId": "ff7eb804-f839-4e4e-ba06-56ba3cd38135"
      },
      "id": "bp18u5zyqbWe",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fcb79384c40>"
            ]
          },
          "metadata": {},
          "execution_count": 138
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Documentation"
      ],
      "metadata": {
        "id": "pPxEgRva__bQ"
      },
      "id": "pPxEgRva__bQ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Link for testing documentation](https://docs.google.com/document/d/1FdGThwWNpkHd1il9sECP0v71NzV81BCIkMgpLCpOC-c/edit?usp=sharing)"
      ],
      "metadata": {
        "id": "lOvrs4NE_tQB"
      },
      "id": "lOvrs4NE_tQB"
    },
    {
      "cell_type": "markdown",
      "id": "intimate-factory",
      "metadata": {
        "id": "intimate-factory"
      },
      "source": [
        "#### Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "broad-appointment",
      "metadata": {
        "id": "broad-appointment"
      },
      "source": [
        "# Answer\n",
        "\n",
        "From this activity, I have learned about the different factors affecting neural networks and their contribution to the model's accuracy and fitting. Based on the [documentation](https://docs.google.com/document/d/1FdGThwWNpkHd1il9sECP0v71NzV81BCIkMgpLCpOC-c/edit?usp=sharing), I have noticed that the learning rate of `0.006` does not provide a good model and often results in overfitting with the validation loss being significantly higher than training loss. This is also true when implementing a network structure consisting of 12 neurons, regardless of number of layers.\n",
        "\n",
        "This might be because implementing a high learning rate encourages the model to overfit by adjusting its weights accordingly to 'learn' the training data, but when presented with the testing dataset, the model cannot generalize its 'learnings'. As for the neuron count, overfitting might have occured due to the complexity of the system trying to solve a simpler problem.\n",
        "\n",
        "Upon testing, the most well-fit model created is by using a learning rate of `0.003`, `2 hidden layers` consisting of `6 neurons` each with the `relu` activation function, `1 output layer` consisting of `1 neuron` with the `sigmoid` activation function, and `100 epochs`. This allows the model to learn and generalize information from the training dataset and trains the model just long enough before it starts to overfit the data. Although this model only yields roughly 60% accuracy, other models that reached a higher accuracy score are either overfitted or underfitted."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "oiXjIjjIqDBT"
      ],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}